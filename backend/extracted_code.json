{
  "extraction_protocol_version": "1.0",
  "extraction_timestamp": "2026-01-05T22:24:31.735212+00:00Z",
  "total_targets": 7,
  "targets": [
    {
      "id": 1,
      "name": "async_exchange_connector",
      "source_repo": "freqtrade/freqtrade",
      "files": [
        {
          "path": "freqtrade/exchange/exchange.py",
          "url": "https://github.com/freqtrade/freqtrade/blob/develop/freqtrade/exchange/exchange.py",
          "lines": "1-4099",
          "code": "# pragma pylint: disable=W0603\n\"\"\"\nCryptocurrency Exchanges support\n\"\"\"\n\nimport asyncio\nimport inspect\nimport logging\nimport signal\nfrom collections.abc import Coroutine, Generator\nfrom copy import deepcopy\nfrom datetime import UTC, datetime, timedelta\nfrom math import floor, isnan\nfrom threading import Lock\nfrom typing import Any, Literal, TypeGuard, TypeVar\n\nimport ccxt\nimport ccxt.pro as ccxt_pro\nfrom ccxt import TICK_SIZE\nfrom dateutil import parser\nfrom pandas import DataFrame, concat\n\nfrom freqtrade.configuration import remove_exchange_credentials\nfrom freqtrade.constants import (\n    DEFAULT_AMOUNT_RESERVE_PERCENT,\n    DEFAULT_TRADES_COLUMNS,\n    NON_OPEN_EXCHANGE_STATES,\n    BidAsk,\n    BuySell,\n    Config,\n    EntryExit,\n    ExchangeConfig,\n    ListPairsWithTimeframes,\n    MakerTaker,\n    OBLiteral,\n    PairWithTimeframe,\n)\nfrom freqtrade.data.converter import (\n    clean_ohlcv_dataframe,\n    ohlcv_to_dataframe,\n    trades_df_remove_duplicates,\n    trades_dict_to_list,\n    trades_list_to_df,\n)\nfrom freqtrade.enums import (\n    OPTIMIZE_MODES,\n    TRADE_MODES,\n    CandleType,\n    MarginMode,\n    PriceType,\n    RunMode,\n    TradingMode,\n)\nfrom freqtrade.exceptions import (\n    ConfigurationError,\n    DDosProtection,\n    ExchangeError,\n    InsufficientFundsError,\n    InvalidOrderException,\n    OperationalException,\n    PricingError,\n    RetryableOrderError,\n    TemporaryError,\n)\nfrom freqtrade.exchange.common import (\n    API_FETCH_ORDER_RETRY_COUNT,\n    retrier,\n    retrier_async,\n)\nfrom freqtrade.exchange.exchange_types import (\n    CcxtBalances,\n    CcxtOrder,\n    CcxtPosition,\n    FtHas,\n    FundingRate,\n    OHLCVResponse,\n    OrderBook,\n    Ticker,\n    Tickers,\n)\nfrom freqtrade.exchange.exchange_utils import (\n    ROUND,\n    ROUND_DOWN,\n    ROUND_UP,\n    amount_to_contract_precision,\n    amount_to_contracts,\n    amount_to_precision,\n    contracts_to_amount,\n    date_minus_candles,\n    is_exchange_known_ccxt,\n    market_is_active,\n    price_to_precision,\n)\nfrom freqtrade.exchange.exchange_utils_timeframe import (\n    timeframe_to_minutes,\n    timeframe_to_msecs,\n    timeframe_to_next_date,\n    timeframe_to_prev_date,\n    timeframe_to_seconds,\n)\nfrom freqtrade.exchange.exchange_ws import ExchangeWS\nfrom freqtrade.misc import (\n    chunks,\n    deep_merge_dicts,\n    file_dump_json,\n    file_load_json,\n    safe_value_fallback,\n)\nfrom freqtrade.util import FtTTLCache, PeriodicCache, dt_from_ts, dt_now\nfrom freqtrade.util.datetime_helpers import dt_humanize_delta, dt_ts, format_ms_time\n\n\nlogger = logging.getLogger(__name__)\n\nT = TypeVar(\"T\")\n\n\nclass Exchange:\n    # Parameters to add directly to buy/sell calls (like agreeing to trading agreement)\n    _params: dict = {}\n\n    # Additional parameters - added to the ccxt object\n    _ccxt_params: dict = {}\n\n    # Dict to specify which options each exchange implements\n    # This defines defaults, which can be selectively overridden by subclasses using _ft_has\n    # or by specifying them in the configuration.\n    _ft_has_default: FtHas = {\n        \"stoploss_on_exchange\": False,\n        \"stop_price_param\": \"stopLossPrice\",  # Used for stoploss_on_exchange request\n        \"stop_price_prop\": \"stopLossPrice\",  # Used for stoploss_on_exchange response parsing\n        \"stoploss_order_types\": {},\n        \"stoploss_blocks_assets\": True,  # By default stoploss orders block assets\n        \"stoploss_query_requires_stop_flag\": False,  # Require \"stop\": True\" to fetch stop orders\n        \"order_time_in_force\": [\"GTC\"],\n        \"ohlcv_params\": {},\n        \"ohlcv_has_history\": True,  # Some exchanges (Kraken) don't provide history via ohlcv\n        \"ohlcv_partial_candle\": True,\n        \"ohlcv_require_since\": False,\n        \"download_data_parallel_quick\": True,\n        \"always_require_api_keys\": False,  # purge API keys for Dry-run. Must default to false.\n        # Check https://github.com/ccxt/ccxt/issues/10767 for removal of ohlcv_volume_currency\n        \"ohlcv_volume_currency\": \"base\",  # \"base\" or \"quote\"\n        \"tickers_have_quoteVolume\": True,\n        \"tickers_have_percentage\": True,\n        \"tickers_have_bid_ask\": True,  # bid / ask empty for fetch_tickers\n        \"tickers_have_price\": True,\n        \"trades_limit\": 1000,  # Limit for 1 call to fetch_trades\n        \"trades_pagination\": \"time\",  # Possible are \"time\" or \"id\"\n        \"trades_pagination_arg\": \"since\",\n        \"trades_has_history\": False,\n        \"l2_limit_range\": None,\n        \"l2_limit_range_required\": True,  # Allow Empty L2 limit (kucoin)\n        \"l2_limit_upper\": None,  # Upper limit for L2 limit\n        \"mark_ohlcv_price\": \"mark\",\n        \"mark_ohlcv_timeframe\": \"1h\",\n        \"funding_fee_timeframe\": \"1h\",\n        \"ccxt_futures_name\": \"swap\",\n        \"needs_trading_fees\": False,  # use fetch_trading_fees to cache fees\n        \"order_props_in_contracts\": [\"amount\", \"filled\", \"remaining\"],\n        \"fetch_orders_limit_minutes\": None,  # \"fetch_orders\" is not time-limited by default\n        # Override createMarketBuyOrderRequiresPrice where ccxt has it wrong\n        \"marketOrderRequiresPrice\": False,\n        \"exchange_has_overrides\": {},  # Dictionary overriding ccxt's \"has\".\n        \"proxy_coin_mapping\": {},  # Mapping for proxy coins\n        # Expected to be in the format {\"fetchOHLCV\": True} or {\"fetchOHLCV\": False}\n        \"ws_enabled\": False,  # Set to true for exchanges with tested websocket support\n        \"has_delisting\": False,  # Set to true for exchanges that have delisting pair checks\n    }\n    _ft_has: FtHas = {}\n    _ft_has_futures: FtHas = {}\n\n    _supported_trading_mode_margin_pairs: list[tuple[TradingMode, MarginMode]] = [\n        # Non-defined exchanges only support spot mode.\n        (TradingMode.SPOT, MarginMode.NONE),\n    ]\n\n    def __init__(\n        self,\n        config: Config,\n        *,\n        exchange_config: ExchangeConfig | None = None,\n        validate: bool = True,\n        load_leverage_tiers: bool = False,\n    ) -> None:\n        \"\"\"\n        Initializes this module with the given config,\n        it does basic validation whether the specified exchange and pairs are valid.\n        :return: None\n        \"\"\"\n        self._api: ccxt.Exchange\n        self._api_async: ccxt_pro.Exchange\n        self._ws_async: ccxt_pro.Exchange = None\n        self._exchange_ws: ExchangeWS | None = None\n        self._markets: dict = {}\n        self._trading_fees: dict[str, Any] = {}\n        self._leverage_tiers: dict[str, list[dict]] = {}\n        # Lock event loop. This is necessary to avoid race-conditions when using force* commands\n        # Due to funding fee fetching.\n        self._loop_lock = Lock()\n        self.loop = self._init_async_loop()\n        self._config: Config = {}\n\n        # Leverage properties\n        self.trading_mode: TradingMode = TradingMode(\n            config.get(\"trading_mode\", self._supported_trading_mode_margin_pairs[0][0])\n        )\n        self.margin_mode: MarginMode = MarginMode(\n            MarginMode(config.get(\"margin_mode\"))\n            if config.get(\"margin_mode\")\n            else self._supported_trading_mode_margin_pairs[0][1]\n        )\n        config[\"trading_mode\"] = self.trading_mode\n        config[\"margin_mode\"] = self.margin_mode\n        config[\"candle_type_def\"] = CandleType.get_default(self.trading_mode)\n        self._config.update(config)\n        self.liquidation_buffer = config.get(\"liquidation_buffer\", 0.05)\n\n        exchange_conf: ExchangeConfig = exchange_config if exchange_config else config[\"exchange\"]\n\n        # Deep merge ft_has with default ft_has options\n        # Must be called before ft_has is used.\n        self.build_ft_has(exchange_conf)\n\n        # Holds last candle refreshed time of each pair\n        self._pairs_last_refresh_time: dict[PairWithTimeframe, int] = {}\n        # Timestamp of last markets refresh\n        self._last_markets_refresh: int = 0\n\n        self._cache_lock = Lock()\n        # Cache for 10 minutes ...\n        self._fetch_tickers_cache: FtTTLCache = FtTTLCache(maxsize=4, ttl=60 * 10)\n        # Cache values for 300 to avoid frequent polling of the exchange for prices\n        # Caching only applies to RPC methods, so prices for open trades are still\n        # refreshed once every iteration.\n        # Shouldn't be too high either, as it'll freeze UI updates in case of open orders.\n        self._exit_rate_cache: FtTTLCache = FtTTLCache(maxsize=100, ttl=300)\n        self._entry_rate_cache: FtTTLCache = FtTTLCache(maxsize=100, ttl=300)\n\n        # Holds candles\n        self._klines: dict[PairWithTimeframe, DataFrame] = {}\n        self._expiring_candle_cache: dict[tuple[str, int], PeriodicCache] = {}\n\n        # Holds public_trades\n        self._trades: dict[PairWithTimeframe, DataFrame] = {}\n\n        # Holds all open sell orders for dry_run\n        self._dry_run_open_orders: dict[str, Any] = {}\n\n        if config[\"dry_run\"]:\n            logger.info(\"Instance is running with dry_run enabled\")\n        logger.info(f\"Using CCXT {ccxt.__version__}\")\n\n        # Don't remove exchange credentials for dry-run or if always_require_api_keys is set\n        remove_exchange_credentials(\n            exchange_conf,\n            not self._ft_has[\"always_require_api_keys\"] and config.get(\"dry_run\", False),\n        )\n        self.log_responses = exchange_conf.get(\"log_responses\", False)\n\n        # Assign this directly for easy access\n        self._ohlcv_partial_candle = self._ft_has[\"ohlcv_partial_candle\"]\n\n        # Initialize ccxt objects\n        ccxt_config = self._ccxt_config\n        ccxt_config = deep_merge_dicts(exchange_conf.get(\"ccxt_config\", {}), ccxt_config)\n        ccxt_config = deep_merge_dicts(exchange_conf.get(\"ccxt_sync_config\", {}), ccxt_config)\n\n        self._api = self._init_ccxt(exchange_conf, True, ccxt_config)\n\n        ccxt_async_config = self._ccxt_config\n        ccxt_async_config = deep_merge_dicts(\n            exchange_conf.get(\"ccxt_config\", {}), ccxt_async_config\n        )\n        ccxt_async_config = deep_merge_dicts(\n            exchange_conf.get(\"ccxt_async_config\", {}), ccxt_async_config\n        )\n        self._api_async = self._init_ccxt(exchange_conf, False, ccxt_async_config)\n        _has_watch_ohlcv = self.exchange_has(\"watchOHLCV\") and self._ft_has[\"ws_enabled\"]\n        if (\n            self._config[\"runmode\"] in TRADE_MODES\n            and exchange_conf.get(\"enable_ws\", True)\n            and _has_watch_ohlcv\n        ):\n            self._ws_async = self._init_ccxt(exchange_conf, False, ccxt_async_config)\n            self._exchange_ws = ExchangeWS(self._config, self._ws_async)\n\n        logger.info(f'Using Exchange \"{self.name}\"')\n        self.required_candle_call_count = 1\n        # Converts the interval provided in minutes in config to seconds\n        self.markets_refresh_interval: int = (\n            exchange_conf.get(\"markets_refresh_interval\", 60) * 60 * 1000\n        )\n\n        if validate:\n            # Initial markets load\n            self.reload_markets(True, load_leverage_tiers=False)\n            self.validate_config(config)\n\n        if self.trading_mode != TradingMode.SPOT and load_leverage_tiers:\n            self.fill_leverage_tiers()\n        self.ft_additional_exchange_init()\n\n    def __del__(self):\n        \"\"\"\n        Destructor - clean up async stuff\n        \"\"\"\n        self.close()\n\n    def close(self):\n        if self._exchange_ws:\n            self._exchange_ws.cleanup()\n        logger.debug(\"Exchange object destroyed, closing async loop\")\n        if (\n            getattr(self, \"_api_async\", None)\n            and inspect.iscoroutinefunction(self._api_async.close)\n            and self._api_async.session\n        ):\n            logger.debug(\"Closing async ccxt session.\")\n            self.loop.run_until_complete(self._api_async.close())\n        if (\n            self._ws_async\n            and inspect.iscoroutinefunction(self._ws_async.close)\n            and self._ws_async.session\n        ):\n            logger.debug(\"Closing ws ccxt session.\")\n            self.loop.run_until_complete(self._ws_async.close())\n\n        if self.loop and not self.loop.is_closed():\n            self.loop.close()\n\n    def _init_async_loop(self) -> asyncio.AbstractEventLoop:\n        loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(loop)\n        return loop\n\n    def _set_startup_candle_count(self, config: Config) -> None:\n        self._startup_candle_count: int = config.get(\"startup_candle_count\", 0)\n        self.required_candle_call_count = self.validate_required_startup_candles(\n            self._startup_candle_count, config.get(\"timeframe\", \"\")\n        )\n\n    def validate_config(self, config: Config) -> None:\n        # Check if timeframe is available\n        self.validate_timeframes(config.get(\"timeframe\"))\n\n        # Check if all pairs are available\n        self.validate_stakecurrency(config[\"stake_currency\"])\n        self.validate_ordertypes(config.get(\"order_types\", {}))\n        self.validate_order_time_in_force(config.get(\"order_time_in_force\", {}))\n        self.validate_trading_mode_and_margin_mode(self.trading_mode, self.margin_mode)\n        self.validate_pricing(config[\"exit_pricing\"])\n        self.validate_pricing(config[\"entry_pricing\"])\n        self.validate_orderflow(config[\"exchange\"])\n        self.validate_freqai(config)\n\n        self._set_startup_candle_count(config)\n\n    def _init_ccxt(\n        self, exchange_config: dict[str, Any], sync: bool, ccxt_kwargs: dict[str, Any]\n    ) -> ccxt.Exchange:\n        \"\"\"\n        Initialize ccxt with given config and return valid ccxt instance.\n        \"\"\"\n        # Find matching class for the given exchange name\n        name = exchange_config[\"name\"]\n        if sync:\n            ccxt_module = ccxt\n        else:\n            ccxt_module = ccxt_pro\n            if not is_exchange_known_ccxt(name, ccxt_module):\n                # Fall back to async if pro doesn't support this exchange\n                import ccxt.async_support as ccxt_async\n\n                ccxt_module = ccxt_async\n\n        if not is_exchange_known_ccxt(name, ccxt_module):\n            raise OperationalException(f\"Exchange {name} is not supported by ccxt\")\n\n        ex_config = {\n            \"apiKey\": exchange_config.get(\n                \"api_key\", exchange_config.get(\"apiKey\", exchange_config.get(\"key\"))\n            ),\n            \"secret\": exchange_config.get(\"secret\"),\n            \"password\": exchange_config.get(\"password\"),\n            \"uid\": exchange_config.get(\"uid\", \"\"),\n            \"accountId\": exchange_config.get(\"account_id\", exchange_config.get(\"accountId\", \"\")),\n            # DEX attributes:\n            \"walletAddress\": exchange_config.get(\n                \"wallet_address\", exchange_config.get(\"walletAddress\")\n            ),\n            \"privateKey\": exchange_config.get(\"private_key\", exchange_config.get(\"privateKey\")),\n        }\n        if ccxt_kwargs:\n            logger.info(\"Applying additional ccxt config: %s\", ccxt_kwargs)\n        if self._ccxt_params:\n            # Inject static options after the above output to not confuse users.\n            ccxt_kwargs = deep_merge_dicts(self._ccxt_params, deepcopy(ccxt_kwargs))\n        if ccxt_kwargs:\n            ex_config.update(ccxt_kwargs)\n        try:\n            api = getattr(ccxt_module, name.lower())(ex_config)\n        except (KeyError, AttributeError) as e:\n            raise OperationalException(f\"Exchange {name} is not supported\") from e\n        except ccxt.BaseError as e:\n            raise OperationalException(f\"Initialization of ccxt failed. Reason: {e}\") from e\n\n        return api\n\n    @property\n    def _ccxt_config(self) -> dict:\n        # Parameters to add directly to ccxt sync/async initialization.\n        if self.trading_mode == TradingMode.MARGIN:\n            return {\"options\": {\"defaultType\": \"margin\"}}\n        elif self.trading_mode == TradingMode.FUTURES:\n            return {\"options\": {\"defaultType\": self._ft_has[\"ccxt_futures_name\"]}}\n        else:\n            return {}\n\n    @property\n    def name(self) -> str:\n        \"\"\"exchange Name (from ccxt)\"\"\"\n        return self._api.name\n\n    @property\n    def id(self) -> str:\n        \"\"\"exchange ccxt id\"\"\"\n        return self._api.id\n\n    @property\n    def timeframes(self) -> list[str]:\n        market_type = (\n            \"spot\"\n            if self.trading_mode != TradingMode.FUTURES\n            else self._ft_has[\"ccxt_futures_name\"]\n        )\n        timeframes = self._api.options.get(\"timeframes\", {}).get(market_type)\n        if timeframes is None:\n            timeframes = self._api.timeframes\n        return list((timeframes or {}).keys())\n\n    @property\n    def markets(self) -> dict[str, Any]:\n        \"\"\"exchange ccxt markets\"\"\"\n        if not self._markets:\n            logger.info(\"Markets were not loaded. Loading them now..\")\n            self.reload_markets(True)\n        return self._markets\n\n    @property\n    def precisionMode(self) -> int:\n        \"\"\"Exchange ccxt precisionMode\"\"\"\n        return self._api.precisionMode\n\n    @property\n    def precision_mode_price(self) -> int:\n        \"\"\"\n        Exchange ccxt precisionMode used for price\n        Workaround for ccxt limitation to not have precisionMode for price\n        if it differs for an exchange\n        Might need to be updated if https://github.com/ccxt/ccxt/issues/20408 is fixed.\n        \"\"\"\n        return self._api.precisionMode\n\n    def ft_additional_exchange_init(self) -> None:\n        \"\"\"\n        Wrapper around additional_exchange_init to simplify testing\n        \"\"\"\n        self.additional_exchange_init()\n\n    def additional_exchange_init(self) -> None:\n        \"\"\"\n        Additional exchange initialization logic.\n        .api will be available at this point.\n        Must be overridden in child methods if required.\n        \"\"\"\n        pass\n\n    def _log_exchange_response(self, endpoint: str, response, *, add_info=None) -> None:\n        \"\"\"Log exchange responses\"\"\"\n        if self.log_responses:\n            add_info_str = \"\" if add_info is None else f\"{add_info}: \"\n            logger.info(f\"API {endpoint}: {add_info_str}{response}\")\n\n    def ohlcv_candle_limit(\n        self, timeframe: str, candle_type: CandleType, since_ms: int | None = None\n    ) -> int:\n        \"\"\"\n        Exchange ohlcv candle limit\n        Uses ohlcv_candle_limit_per_timeframe if the exchange has different limits\n        per timeframe (e.g. bittrex), otherwise falls back to ohlcv_candle_limit\n        :param timeframe: Timeframe to check\n        :param candle_type: Candle-type\n        :param since_ms: Starting timestamp\n        :return: Candle limit as integer\n        \"\"\"\n\n        ccxt_val = self.features(\n            \"spot\" if candle_type == CandleType.SPOT else \"futures\", \"fetchOHLCV\", \"limit\", 500\n        )\n        if not isinstance(ccxt_val, float | int):\n            ccxt_val = 500\n        fallback_val = self._ft_has.get(\"ohlcv_candle_limit\", ccxt_val)\n        if candle_type == CandleType.FUNDING_RATE:\n            fallback_val = self._ft_has.get(\"funding_fee_candle_limit\", fallback_val)\n        return int(\n            self._ft_has.get(\"ohlcv_candle_limit_per_timeframe\", {}).get(\n                timeframe, str(fallback_val)\n            )\n        )\n\n    def get_markets(\n        self,\n        base_currencies: list[str] | None = None,\n        quote_currencies: list[str] | None = None,\n        spot_only: bool = False,\n        margin_only: bool = False,\n        futures_only: bool = False,\n        tradable_only: bool = True,\n        active_only: bool = False,\n    ) -> dict[str, Any]:\n        \"\"\"\n        Return exchange ccxt markets, filtered out by base currency and quote currency\n        if this was requested in parameters.\n        \"\"\"\n        markets = self.markets\n        if not markets:\n            raise OperationalException(\"Markets were not loaded.\")\n\n        if base_currencies:\n            markets = {k: v for k, v in markets.items() if v[\"base\"] in base_currencies}\n        if quote_currencies:\n            markets = {k: v for k, v in markets.items() if v[\"quote\"] in quote_currencies}\n        if tradable_only:\n            markets = {k: v for k, v in markets.items() if self.market_is_tradable(v)}\n        if spot_only:\n            markets = {k: v for k, v in markets.items() if self.market_is_spot(v)}\n        if margin_only:\n            markets = {k: v for k, v in markets.items() if self.market_is_margin(v)}\n        if futures_only:\n            markets = {k: v for k, v in markets.items() if self.market_is_future(v)}\n        if active_only:\n            markets = {k: v for k, v in markets.items() if market_is_active(v)}\n        return markets\n\n    def get_quote_currencies(self) -> list[str]:\n        \"\"\"\n        Return a list of supported quote currencies\n        \"\"\"\n        markets = self.markets\n        return sorted(set([x[\"quote\"] for _, x in markets.items()]))\n\n    def get_pair_quote_currency(self, pair: str) -> str:\n        \"\"\"Return a pair's quote currency (base/quote:settlement)\"\"\"\n        return self.markets.get(pair, {}).get(\"quote\", \"\")\n\n    def get_pair_base_currency(self, pair: str) -> str:\n        \"\"\"Return a pair's base currency (base/quote:settlement)\"\"\"\n        return self.markets.get(pair, {}).get(\"base\", \"\")\n\n    def market_is_future(self, market: dict[str, Any]) -> bool:\n        return (\n            market.get(self._ft_has[\"ccxt_futures_name\"], False) is True\n            and market.get(\"type\", False) == \"swap\"\n            and market.get(\"linear\", False) is True\n        )\n\n    def market_is_spot(self, market: dict[str, Any]) -> bool:\n        return market.get(\"spot\", False) is True\n\n    def market_is_margin(self, market: dict[str, Any]) -> bool:\n        return market.get(\"margin\", False) is True\n\n    def market_is_tradable(self, market: dict[str, Any]) -> bool:\n        \"\"\"\n        Check if the market symbol is tradable by Freqtrade.\n        Ensures that Configured mode aligns to\n        \"\"\"\n        return (\n            market.get(\"quote\", None) is not None\n            and market.get(\"base\", None) is not None\n            and (\n                self.precisionMode != TICK_SIZE\n                # Too low precision will falsify calculations\n                or market.get(\"precision\", {}).get(\"price\") is None\n                or market.get(\"precision\", {}).get(\"price\") > 1e-11\n            )\n            and (\n                (self.trading_mode == TradingMode.SPOT and self.market_is_spot(market))\n                or (self.trading_mode == TradingMode.MARGIN and self.market_is_margin(market))\n                or (self.trading_mode == TradingMode.FUTURES and self.market_is_future(market))\n            )\n        )\n\n    def klines(self, pair_interval: PairWithTimeframe, copy: bool = True) -> DataFrame:\n        if pair_interval in self._klines:\n            return self._klines[pair_interval].copy() if copy else self._klines[pair_interval]\n        else:\n            return DataFrame()\n\n    def trades(self, pair_interval: PairWithTimeframe, copy: bool = True) -> DataFrame:\n        if pair_interval in self._trades:\n            if copy:\n                return self._trades[pair_interval].copy()\n            else:\n                return self._trades[pair_interval]\n        else:\n            return DataFrame(columns=DEFAULT_TRADES_COLUMNS)\n\n    def get_contract_size(self, pair: str) -> float | None:\n        if self.trading_mode == TradingMode.FUTURES:\n            market = self.markets.get(pair, {})\n            contract_size: float = 1.0\n            if not market:\n                return None\n            if market.get(\"contractSize\") is not None:\n                # ccxt has contractSize in markets as string\n                contract_size = float(market[\"contractSize\"])\n            return contract_size\n        else:\n            return 1\n\n    def _trades_contracts_to_amount(self, trades: list) -> list:\n        if len(trades) > 0 and \"symbol\" in trades[0]:\n            contract_size = self.get_contract_size(trades[0][\"symbol\"])\n            if contract_size != 1:\n                for trade in trades:\n                    trade[\"amount\"] = trade[\"amount\"] * contract_size\n        return trades\n\n    def _order_contracts_to_amount(self, order: CcxtOrder) -> CcxtOrder:\n        if \"symbol\" in order and order[\"symbol\"] is not None:\n            contract_size = self.get_contract_size(order[\"symbol\"])\n            if contract_size != 1:\n                for prop in self._ft_has.get(\"order_props_in_contracts\", []):\n                    if prop in order and order[prop] is not None:\n                        order[prop] = order[prop] * contract_size\n        return order\n\n    def _amount_to_contracts(self, pair: str, amount: float) -> float:\n        contract_size = self.get_contract_size(pair)\n        return amount_to_contracts(amount, contract_size)\n\n    def _contracts_to_amount(self, pair: str, num_contracts: float) -> float:\n        contract_size = self.get_contract_size(pair)\n        return contracts_to_amount(num_contracts, contract_size)\n\n    def amount_to_contract_precision(self, pair: str, amount: float) -> float:\n        \"\"\"\n        Helper wrapper around amount_to_contract_precision\n        \"\"\"\n        contract_size = self.get_contract_size(pair)\n\n        return amount_to_contract_precision(\n            amount, self.get_precision_amount(pair), self.precisionMode, contract_size\n        )\n\n    def ws_connection_reset(self):\n        \"\"\"\n        called at regular intervals to reset the websocket connection\n        \"\"\"\n        if self._exchange_ws:\n            self._exchange_ws.reset_connections()\n\n    async def _api_reload_markets(self, reload: bool = False) -> None:\n        try:\n            await self._api_async.load_markets(reload=reload, params={})\n        except ccxt.DDoSProtection as e:\n            raise DDosProtection(e) from e\n        except (ccxt.OperationFailed, ccxt.ExchangeError) as e:\n            raise TemporaryError(\n                f\"Error in reload_markets due to {e.__class__.__name__}. Message: {e}\"\n            ) from e\n        except ccxt.BaseError as e:\n            raise TemporaryError(e) from e\n\n    def _load_async_markets(self, reload: bool = False) -> None:\n        try:\n            with self._loop_lock:\n                markets = self.loop.run_until_complete(self._api_reload_markets(reload=reload))\n\n            if isinstance(markets, Exception):\n                raise markets\n            return None\n        except TimeoutError as e:\n            logger.warning(\"Could not load markets. Reason: %s\", e)\n            raise TemporaryError from e\n\n    def reload_markets(self, force: bool = False, *, load_leverage_tiers: bool = True) -> None:\n        \"\"\"\n        Reload / Initialize markets both sync and async if refresh interval has passed\n\n        \"\"\"\n        # Check whether markets have to be reloaded\n        is_initial = self._last_markets_refresh == 0\n        if (\n            not force\n            and self._last_markets_refresh > 0\n            and (self._last_markets_refresh + self.markets_refresh_interval > dt_ts())\n        ):\n            return None\n        logger.debug(\"Performing scheduled market reload..\")\n        try:\n            # on initial load, we retry 3 times to ensure we get the markets\n            retries: int = 3 if force else 0\n            # Reload async markets, then assign them to sync api\n            retrier(self._load_async_markets, retries=retries)(reload=True)\n            self._markets = self._api_async.markets\n            self._api.set_markets_from_exchange(self._api_async)\n            # Assign options array, as it contains some temporary information from the exchange.\n            # ccxt does not implicitly copy options over in set_markets_from_exchange\n            self._api.options = self._api_async.options\n            if self._exchange_ws:\n                # Set markets to avoid reloading on websocket api\n                self._ws_async.set_markets_from_exchange(self._api_async)\n                self._ws_async.options = self._api.options\n            self._last_markets_refresh = dt_ts()\n\n            if is_initial and self._ft_has[\"needs_trading_fees\"]:\n                self._trading_fees = self.fetch_trading_fees()\n\n            if load_leverage_tiers and self.trading_mode == TradingMode.FUTURES:\n                self.fill_leverage_tiers()\n        except (ccxt.BaseError, TemporaryError):\n            logger.exception(\"Could not load markets.\")\n\n    def validate_stakecurrency(self, stake_currency: str) -> None:\n        \"\"\"\n        Checks stake-currency against available currencies on the exchange.\n        Only runs on startup. If markets have not been loaded, there's been a problem with\n        the connection to the exchange.\n        :param stake_currency: Stake-currency to validate\n        :raise: OperationalException if stake-currency is not available.\n        \"\"\"\n        if not self._markets:\n            raise OperationalException(\n                \"Could not load markets, therefore cannot start. \"\n                \"Please investigate the above error for more details.\"\n            )\n        quote_currencies = self.get_quote_currencies()\n        if stake_currency not in quote_currencies:\n            raise ConfigurationError(\n                f\"{stake_currency} is not available as stake on {self.name}. \"\n                f\"Available currencies are: {', '.join(quote_currencies)}\"\n            )\n\n    def get_valid_pair_combination(self, curr_1: str, curr_2: str) -> Generator[str, None, None]:\n        \"\"\"\n        Get valid pair combination of curr_1 and curr_2 by trying both combinations.\n        \"\"\"\n        yielded = False\n        for pair in (\n            f\"{curr_1}/{curr_2}\",\n            f\"{curr_2}/{curr_1}\",\n            f\"{curr_1}/{curr_2}:{curr_2}\",\n            f\"{curr_2}/{curr_1}:{curr_1}\",\n        ):\n            if pair in self.markets and self.markets[pair].get(\"active\"):\n                yielded = True\n                yield pair\n        if not yielded:\n            raise ValueError(f\"Could not combine {curr_1} and {curr_2} to get a valid pair.\")\n\n    def validate_timeframes(self, timeframe: str | None) -> None:\n        \"\"\"\n        Check if timeframe from config is a supported timeframe on the exchange\n        \"\"\"\n        if not hasattr(self._api, \"timeframes\") or self._api.timeframes is None:\n            # If timeframes attribute is missing (or is None), the exchange probably\n            # has no fetchOHLCV method.\n            # Therefore we also show that.\n            raise OperationalException(\n                f\"The ccxt library does not provide the list of timeframes \"\n                f\"for the exchange {self.name} and this exchange \"\n                f\"is therefore not supported. ccxt fetchOHLCV: {self.exchange_has('fetchOHLCV')}\"\n            )\n\n        if timeframe and (timeframe not in self.timeframes):\n            raise ConfigurationError(\n                f\"Invalid timeframe '{timeframe}'. This exchange supports: {self.timeframes}\"\n            )\n\n        if (\n            timeframe\n            and self._config[\"runmode\"] != RunMode.UTIL_EXCHANGE\n            and timeframe_to_minutes(timeframe) < 1\n        ):\n            raise ConfigurationError(\"Timeframes < 1m are currently not supported by Freqtrade.\")\n\n    def validate_ordertypes(self, order_types: dict) -> None:\n        \"\"\"\n        Checks if order-types configured in strategy/config are supported\n        \"\"\"\n        if any(v == \"market\" for k, v in order_types.items()):\n            if not self.exchange_has(\"createMarketOrder\"):\n                raise ConfigurationError(f\"Exchange {self.name} does not support market orders.\")\n        self.validate_stop_ordertypes(order_types)\n\n    def validate_stop_ordertypes(self, order_types: dict) -> None:\n        \"\"\"\n        Validate stoploss order types\n        \"\"\"\n        if order_types.get(\"stoploss_on_exchange\") and not self._ft_has.get(\n            \"stoploss_on_exchange\", False\n        ):\n            raise ConfigurationError(f\"On exchange stoploss is not supported for {self.name}.\")\n        if self.trading_mode == TradingMode.FUTURES:\n            price_mapping = self._ft_has.get(\"stop_price_type_value_mapping\", {}).keys()\n            if (\n                order_types.get(\"stoploss_on_exchange\", False) is True\n                and \"stoploss_price_type\" in order_types\n                and order_types[\"stoploss_price_type\"] not in price_mapping\n            ):\n                raise ConfigurationError(\n                    f\"On exchange stoploss price type is not supported for {self.name}.\"\n                )\n\n    def validate_pricing(self, pricing: dict) -> None:\n        if pricing.get(\"use_order_book\", False) and not self.exchange_has(\"fetchL2OrderBook\"):\n            raise ConfigurationError(f\"Orderbook not available for {self.name}.\")\n        if not pricing.get(\"use_order_book\", False) and (\n            not self.exchange_has(\"fetchTicker\") or not self._ft_has[\"tickers_have_price\"]\n        ):\n            raise ConfigurationError(f\"Ticker pricing not available for {self.name}.\")\n\n    def validate_order_time_in_force(self, order_time_in_force: dict) -> None:\n        \"\"\"\n        Checks if order time in force configured in strategy/config are supported\n        \"\"\"\n        if any(\n            v.upper() not in self._ft_has[\"order_time_in_force\"]\n            for k, v in order_time_in_force.items()\n        ):\n            raise ConfigurationError(\n                f\"Time in force policies are not supported for {self.name} yet.\"\n            )\n\n    def validate_orderflow(self, exchange: dict) -> None:\n        if exchange.get(\"use_public_trades\", False) and (\n            not self.exchange_has(\"fetchTrades\") or not self._ft_has[\"trades_has_history\"]\n        ):\n            raise ConfigurationError(\n                f\"Trade data not available for {self.name}. Can't use orderflow feature.\"\n            )\n\n    def validate_freqai(self, config: Config) -> None:\n        freqai_enabled = config.get(\"freqai\", {}).get(\"enabled\", False)\n        override = config.get(\"freqai\", {}).get(\"override_exchange_checks\", False)\n        if not override and freqai_enabled and not self._ft_has[\"ohlcv_has_history\"]:\n            raise ConfigurationError(\n                f\"Historic OHLCV data not available for {self.name}. Can't use freqAI.\"\n            )\n        elif override and freqai_enabled and not self._ft_has[\"ohlcv_has_history\"]:\n            logger.warning(\n                \"Overriding exchange checks for freqAI. Make sure that your exchange supports \"\n                \"fetching historic OHLCV data, otherwise freqAI will not work.\"\n            )\n\n    def validate_required_startup_candles(self, startup_candles: int, timeframe: str) -> int:\n        \"\"\"\n        Checks if required startup_candles is more than ohlcv_candle_limit().\n        Requires a grace-period of 5 candles - so a startup-period up to 494 is allowed by default.\n        \"\"\"\n\n        candle_limit = self.ohlcv_candle_limit(\n            timeframe,\n            self._config[\"candle_type_def\"],\n            dt_ts(date_minus_candles(timeframe, startup_candles)) if timeframe else None,\n        )\n        # Require one more candle - to account for the still open candle.\n        candle_count = startup_candles + 1\n        # Allow 5 calls to the exchange per pair\n        required_candle_call_count = int(\n            (candle_count / candle_limit) + (0 if candle_count % candle_limit == 0 else 1)\n        )\n        if self._ft_has[\"ohlcv_has_history\"]:\n            if required_candle_call_count > 5:\n                # Only allow 5 calls per pair to somewhat limit the impact\n                raise ConfigurationError(\n                    f\"This strategy requires {startup_candles} candles to start, \"\n                    f\"which is more than 5x ({candle_limit * 5 - 1} candles) \"\n                    f\"the amount of candles {self.name} provides for {timeframe}.\"\n                )\n        elif required_candle_call_count > 1:\n            raise ConfigurationError(\n                f\"This strategy requires {startup_candles} candles to start, \"\n                f\"which is more than ({candle_limit - 1} candles) \"\n                f\"the amount of candles {self.name} provides for {timeframe}.\"\n            )\n        if required_candle_call_count > 1:\n            logger.warning(\n                f\"Using {required_candle_call_count} calls to get OHLCV. \"\n                f\"This can result in slower operations for the bot. Please check \"\n                f\"if you really need {startup_candles} candles for your strategy.\"\n            )\n        return required_candle_call_count\n\n    def validate_trading_mode_and_margin_mode(\n        self,\n        trading_mode: TradingMode,\n        margin_mode: MarginMode | None,  # Only None when trading_mode = TradingMode.SPOT\n        allow_none_margin_mode: bool = False,\n    ):\n        \"\"\"\n        Checks if freqtrade can perform trades using the configured\n        trading mode(Margin, Futures) and MarginMode(Cross, Isolated)\n        Throws OperationalException:\n            If the trading_mode/margin_mode type are not supported by freqtrade on this exchange\n        \"\"\"\n        if trading_mode == TradingMode.SPOT:\n            return\n        if allow_none_margin_mode and margin_mode is None:\n            # Verify trading mode independent of margin mode\n            if not any(\n                trading_mode == pair[0] for pair in self._supported_trading_mode_margin_pairs\n            ):\n                raise ConfigurationError(\n                    f\"Freqtrade does not support '{trading_mode}' on {self.name}.\"\n                )\n\n        if not allow_none_margin_mode and (\n            (trading_mode, margin_mode) not in self._supported_trading_mode_margin_pairs\n        ):\n            mm_value = margin_mode and margin_mode.value\n            raise ConfigurationError(\n                f\"Freqtrade does not support '{mm_value}' '{trading_mode}' on {self.name}.\"\n            )\n\n    @classmethod\n    def combine_ft_has(cls, include_futures: bool) -> FtHas:\n        \"\"\"\n        Combine all ft_has options from the class hierarchy.\n        Child classes override parent classes.\n        Doesn't apply overrides from the configuration.\n        \"\"\"\n        _ft_has = deep_merge_dicts(cls._ft_has, deepcopy(cls._ft_has_default))\n\n        if include_futures:\n            _ft_has = deep_merge_dicts(cls._ft_has_futures, _ft_has)\n        return _ft_has\n\n    def build_ft_has(self, exchange_conf: ExchangeConfig) -> None:\n        \"\"\"\n        Deep merge ft_has with default ft_has options\n        and with exchange_conf._ft_has_params if available.\n        This is called on initialization of the exchange object.\n        It must be called before ft_has is used.\n        \"\"\"\n        self._ft_has = self.combine_ft_has(include_futures=self.trading_mode == TradingMode.FUTURES)\n\n        if exchange_conf.get(\"_ft_has_params\"):\n            self._ft_has = deep_merge_dicts(exchange_conf.get(\"_ft_has_params\"), self._ft_has)\n            logger.info(\"Overriding exchange._ft_has with config params, result: %s\", self._ft_has)\n\n    def get_option(self, param: str, default: Any | None = None) -> Any:\n        \"\"\"\n        Get parameter value from _ft_has\n        \"\"\"\n        return self._ft_has.get(param, default)\n\n    def exchange_has(self, endpoint: str) -> bool:\n        \"\"\"\n        Checks if exchange implements a specific API endpoint.\n        Wrapper around ccxt 'has' attribute\n        :param endpoint: Name of endpoint (e.g. 'fetchOHLCV', 'fetchTickers')\n        :return: bool\n        \"\"\"\n        if endpoint in self._ft_has.get(\"exchange_has_overrides\", {}):\n            return self._ft_has[\"exchange_has_overrides\"][endpoint]\n        return endpoint in self._api_async.has and self._api_async.has[endpoint]\n\n    def features(\n        self, market_type: Literal[\"spot\", \"futures\"], endpoint, attribute, default: T\n    ) -> T:\n        \"\"\"\n        Returns the exchange features for the given markettype\n        https://docs.ccxt.com/#/README?id=features\n        attributes are in a nested dict, with spot and swap.linear\n        e.g. spot.fetchOHLCV.limit\n             swap.linear.fetchOHLCV.limit\n        \"\"\"\n        feat = (\n            self._api_async.features.get(\"spot\", {})\n            if market_type == \"spot\"\n            else self._api_async.features.get(\"swap\", {}).get(\"linear\", {})\n        )\n\n        return feat.get(endpoint, {}).get(attribute, default)\n\n    def get_precision_amount(self, pair: str) -> float | None:\n        \"\"\"\n        Returns the amount precision of the exchange.\n        :param pair: Pair to get precision for\n        :return: precision for amount or None. Must be used in combination with precisionMode\n        \"\"\"\n        return self.markets.get(pair, {}).get(\"precision\", {}).get(\"amount\", None)\n\n    def get_precision_price(self, pair: str) -> float | None:\n        \"\"\"\n        Returns the price precision of the exchange.\n        :param pair: Pair to get precision for\n        :return: precision for price or None. Must be used in combination with precisionMode\n        \"\"\"\n        return self.markets.get(pair, {}).get(\"precision\", {}).get(\"price\", None)\n\n    def amount_to_precision(self, pair: str, amount: float) -> float:\n        \"\"\"\n        Returns the amount to buy or sell to a precision the Exchange accepts\n\n        \"\"\"\n        return amount_to_precision(amount, self.get_precision_amount(pair), self.precisionMode)\n\n    def price_to_precision(self, pair: str, price: float, *, rounding_mode: int = ROUND) -> float:\n        \"\"\"\n        Returns the price rounded to the precision the Exchange accepts.\n        The default price_rounding_mode in conf is ROUND.\n        For stoploss calculations, must use ROUND_UP for longs, and ROUND_DOWN for shorts.\n        \"\"\"\n        return price_to_precision(\n            price,\n            self.get_precision_price(pair),\n            self.precision_mode_price,\n            rounding_mode=rounding_mode,\n        )\n\n    def price_get_one_pip(self, pair: str, price: float) -> float:\n        \"\"\"\n        Gets the \"1 pip\" value for this pair.\n        Used in PriceFilter to calculate the 1pip movements.\n        \"\"\"\n        precision = self.markets[pair][\"precision\"][\"price\"]\n        if self.precisionMode == TICK_SIZE:\n            return precision\n        else:\n            return 1 / pow(10, precision)\n\n    def get_min_pair_stake_amount(\n        self, pair: str, price: float, stoploss: float, leverage: float = 1.0\n    ) -> float | None:\n        return self._get_stake_amount_limit(pair, price, stoploss, \"min\", leverage)\n\n    def get_max_pair_stake_amount(self, pair: str, price: float, leverage: float = 1.0) -> float:\n        max_stake_amount = self._get_stake_amount_limit(pair, price, 0.0, \"max\", leverage)\n        if max_stake_amount is None:\n            # * Should never be executed\n            raise OperationalException(\n                f\"{self.name}.get_max_pair_stake_amount should never set max_stake_amount to None\"\n            )\n        return max_stake_amount\n\n    def _get_stake_amount_limit(\n        self,\n        pair: str,\n        price: float,\n        stoploss: float,\n        limit: Literal[\"min\", \"max\"],\n        leverage: float = 1.0,\n    ) -> float | None:\n        isMin = limit == \"min\"\n\n        try:\n            market = self.markets[pair]\n        except KeyError:\n            raise ValueError(f\"Can't get market information for symbol {pair}\")\n\n        stake_limits = []\n        limits = market[\"limits\"]\n        if isMin:\n            # reserve some percent defined in config (5% default) + stoploss\n            margin_reserve: float = 1.0 + self._config.get(\n                \"amount_reserve_percent\", DEFAULT_AMOUNT_RESERVE_PERCENT\n            )\n            stoploss_reserve = margin_reserve / (1 - abs(stoploss)) if abs(stoploss) != 1 else 1.5\n            # it should not be more than 50%\n            stoploss_reserve = max(min(stoploss_reserve, 1.5), 1)\n        else:\n            # is_max\n            margin_reserve = 1.0\n            stoploss_reserve = 1.0\n            if max_from_tiers := self._get_max_notional_from_tiers(pair, leverage=leverage):\n                stake_limits.append(max_from_tiers)\n\n        if limits[\"cost\"][limit] is not None:\n            stake_limits.append(\n                self._contracts_to_amount(pair, limits[\"cost\"][limit]) * stoploss_reserve\n            )\n\n        if limits[\"amount\"][limit] is not None:\n            stake_limits.append(\n                self._contracts_to_amount(pair, limits[\"amount\"][limit]) * price * margin_reserve\n            )\n\n        if not stake_limits:\n            return None if isMin else float(\"inf\")\n\n        # The value returned should satisfy both limits: for amount (base currency) and\n        # for cost (quote, stake currency), so max() is used here.\n        # See also #2575 at github.\n        return self._get_stake_amount_considering_leverage(\n            max(stake_limits) if isMin else min(stake_limits), leverage or 1.0\n        )\n\n    def _get_stake_amount_considering_leverage(self, stake_amount: float, leverage: float) -> float:\n        \"\"\"\n        Takes the minimum stake amount for a pair with no leverage and returns the minimum\n        stake amount when leverage is considered\n        :param stake_amount: The stake amount for a pair before leverage is considered\n        :param leverage: The amount of leverage being used on the current trade\n        \"\"\"\n        return stake_amount / leverage\n\n    # Dry-run methods\n\n    def create_dry_run_order(\n        self,\n        pair: str,\n        ordertype: str,\n        side: BuySell,\n        amount: float,\n        rate: float,\n        leverage: float,\n        params: dict | None = None,\n        stop_loss: bool = False,\n        stop_price: float | None = None,\n    ) -> CcxtOrder:\n        now = dt_now()\n        order_id = f\"dry_run_{side}_{pair}_{now.timestamp()}\"\n        # Rounding here must respect to contract sizes\n        _amount = self._contracts_to_amount(\n            pair, self.amount_to_precision(pair, self._amount_to_contracts(pair, amount))\n        )\n        dry_order: CcxtOrder = {\n            \"id\": order_id,\n            \"symbol\": pair,\n            \"price\": rate,\n            \"average\": rate,\n            \"amount\": _amount,\n            \"cost\": _amount * rate,\n            \"type\": ordertype,\n            \"side\": side,\n            \"filled\": 0,\n            \"remaining\": _amount,\n            \"datetime\": now.strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\"),\n            \"timestamp\": dt_ts(now),\n            \"status\": \"open\",\n            \"fee\": None,\n            \"info\": {},\n        }\n        if stop_loss:\n            dry_order[\"info\"] = {\"stopPrice\": dry_order[\"price\"]}\n            dry_order[self._ft_has[\"stop_price_prop\"]] = stop_price or dry_order[\"price\"]\n            # Workaround to avoid filling stoploss orders immediately\n            dry_order[\"ft_order_type\"] = \"stoploss\"\n        orderbook: OrderBook | None = None\n        if self.exchange_has(\"fetchL2OrderBook\"):\n            orderbook = self.fetch_l2_order_book(pair, 20)\n        if ordertype == \"limit\" and orderbook:\n            # Allow a 1% price difference\n            allowed_diff = 0.01\n            if self._dry_is_price_crossed(pair, side, rate, orderbook, allowed_diff):\n                logger.info(\n                    f\"Converted order {pair} to market order due to price {rate} crossing spread \"\n                    f\"by more than {allowed_diff:.2%}.\"\n                )\n                dry_order[\"type\"] = \"market\"\n\n        if dry_order[\"type\"] == \"market\" and not dry_order.get(\"ft_order_type\"):\n            # Update market order pricing\n            slippage = 0.05\n            worst_rate = rate * ((1 + slippage) if side == \"buy\" else (1 - slippage))\n            average = self.get_dry_market_fill_price(\n                pair, side, amount, rate, worst_rate, orderbook\n            )\n            dry_order.update(\n                {\n                    \"average\": average,\n                    \"filled\": _amount,\n                    \"remaining\": 0.0,\n                    \"status\": \"closed\",\n                    \"cost\": (_amount * average),\n                }\n            )\n            # market orders will always incurr taker fees\n            dry_order = self.add_dry_order_fee(pair, dry_order, \"taker\")\n\n        dry_order = self.check_dry_limit_order_filled(\n            dry_order, immediate=True, orderbook=orderbook\n        )\n\n        self._dry_run_open_orders[dry_order[\"id\"]] = dry_order\n        # Copy order and close it - so the returned order is open unless it's a market order\n        return dry_order\n\n    def add_dry_order_fee(\n        self,\n        pair: str,\n        dry_order: CcxtOrder,\n        taker_or_maker: MakerTaker,\n    ) -> CcxtOrder:\n        fee = self.get_fee(pair, taker_or_maker=taker_or_maker)\n        dry_order.update(\n            {\n                \"fee\": {\n                    \"currency\": self.get_pair_quote_currency(pair),\n                    \"cost\": dry_order[\"cost\"] * fee,\n                    \"rate\": fee,\n                }\n            }\n        )\n        return dry_order\n\n    def get_dry_market_fill_price(\n        self,\n        pair: str,\n        side: str,\n        amount: float,\n        rate: float,\n        worst_rate: float,\n        orderbook: OrderBook | None,\n    ) -> float:\n        \"\"\"\n        Get the market order fill price based on orderbook interpolation\n        \"\"\"\n        if self.exchange_has(\"fetchL2OrderBook\"):\n            if not orderbook:\n                orderbook = self.fetch_l2_order_book(pair, 20)\n            ob_type: OBLiteral = \"asks\" if side == \"buy\" else \"bids\"\n\n            remaining_amount = amount\n            filled_value = 0.0\n            book_entry_price = 0.0\n            for book_entry in orderbook[ob_type]:\n                book_entry_price = book_entry[0]\n                book_entry_coin_volume = book_entry[1]\n                if remaining_amount > 0:\n                    if remaining_amount < book_entry_coin_volume:\n                        # Orderbook at this slot bigger than remaining amount\n                        filled_value += remaining_amount * book_entry_price\n                        break\n                    else:\n                        filled_value += book_entry_coin_volume * book_entry_price\n                    remaining_amount -= book_entry_coin_volume\n                else:\n                    break\n            else:\n                # If remaining_amount wasn't consumed completely (break was not called)\n                filled_value += remaining_amount * book_entry_price\n            forecast_avg_filled_price = max(filled_value, 0) / amount\n            # Limit max. slippage to specified value\n            if side == \"buy\":\n                forecast_avg_filled_price = min(forecast_avg_filled_price, worst_rate)\n\n            else:\n                forecast_avg_filled_price = max(forecast_avg_filled_price, worst_rate)\n            return self.price_to_precision(pair, forecast_avg_filled_price)\n\n        return rate\n\n    def _dry_is_price_crossed(\n        self,\n        pair: str,\n        side: str,\n        limit: float,\n        orderbook: OrderBook | None = None,\n        offset: float = 0.0,\n        is_stop: bool = False,\n    ) -> bool:\n        if not self.exchange_has(\"fetchL2OrderBook\"):\n            # True unless checking a stoploss order\n            return not is_stop\n        if not orderbook:\n            orderbook = self.fetch_l2_order_book(pair, 1)\n        try:\n            if (side == \"buy\" and not is_stop) or (side == \"sell\" and is_stop):\n                price = orderbook[\"asks\"][0][0]\n                if limit * (1 - offset) >= price:\n                    return True\n            else:\n                price = orderbook[\"bids\"][0][0]\n                if limit * (1 + offset) <= price:\n                    return True\n        except IndexError:\n            # Ignore empty orderbooks when filling - can be filled with the next iteration.\n            pass\n        return False\n\n    def check_dry_limit_order_filled(\n        self, order: CcxtOrder, immediate: bool = False, orderbook: OrderBook | None = None\n    ) -> CcxtOrder:\n        \"\"\"\n        Check dry-run limit order fill and update fee (if it filled).\n        \"\"\"\n        if order[\"status\"] != \"closed\" and order.get(\"ft_order_type\") == \"stoploss\":\n            pair = order[\"symbol\"]\n            if not orderbook and self.exchange_has(\"fetchL2OrderBook\"):\n                orderbook = self.fetch_l2_order_book(pair, 20)\n            price = safe_value_fallback(order, self._ft_has[\"stop_price_prop\"], \"price\")\n            crossed = self._dry_is_price_crossed(\n                pair, order[\"side\"], price, orderbook, is_stop=True\n            )\n            if crossed:\n                average = self.get_dry_market_fill_price(\n                    pair,\n                    order[\"side\"],\n                    order[\"amount\"],\n                    price,\n                    worst_rate=order[\"price\"],\n                    orderbook=orderbook,\n                )\n                order.update(\n                    {\n                        \"status\": \"closed\",\n                        \"filled\": order[\"amount\"],\n                        \"remaining\": 0,\n                        \"average\": average,\n                        \"cost\": order[\"amount\"] * average,\n                    }\n                )\n                self.add_dry_order_fee(\n                    pair,\n                    order,\n                    \"taker\" if immediate else \"maker\",\n                )\n            return order\n        if (\n            order[\"status\"] != \"closed\"\n            and order[\"type\"] in [\"limit\"]\n            and not order.get(\"ft_order_type\")\n        ):\n            pair = order[\"symbol\"]\n            if self._dry_is_price_crossed(pair, order[\"side\"], order[\"price\"], orderbook):\n                order.update(\n                    {\n                        \"status\": \"closed\",\n                        \"filled\": order[\"amount\"],\n                        \"remaining\": 0,\n                    }\n                )\n\n                self.add_dry_order_fee(\n                    pair,\n                    order,\n                    \"taker\" if immediate else \"maker\",\n                )\n\n        return order\n\n    def fetch_dry_run_order(self, order_id: str) -> CcxtOrder:\n        \"\"\"\n        Return dry-run order\n        Only call if running in dry-run mode.\n        \"\"\"\n        try:\n            order = self._dry_run_open_orders[order_id]\n            order = self.check_dry_limit_order_filled(order)\n            return order\n        except KeyError as e:\n            from freqtrade.persistence import Order\n\n            order_obj = Order.order_by_id(order_id)\n            if order_obj:\n                order = order_obj.to_ccxt_object(self._ft_has[\"stop_price_prop\"])\n                order = self.check_dry_limit_order_filled(order)\n                self._dry_run_open_orders[order_id] = order\n                return order\n            # Gracefully handle errors with dry-run orders.\n            raise InvalidOrderException(\n                f\"Tried to get an invalid dry-run-order (id: {order_id}). Message: {e}\"\n            ) from e\n\n    # Order handling\n\n    def _lev_prep(self, pair: str, leverage: float, side: BuySell, accept_fail: bool = False):\n        if self.trading_mode != TradingMode.SPOT:\n            self.set_margin_mode(pair, self.margin_mode, accept_fail)\n            self._set_leverage(leverage, pair, accept_fail)\n\n    def _get_params(\n        self,\n        side: BuySell,\n        ordertype: str,\n        leverage: float,\n        reduceOnly: bool,\n        time_in_force: str = \"GTC\",\n    ) -> dict:\n        params = self._params.copy()\n        if time_in_force != \"GTC\" and ordertype != \"market\":\n            params.update({\"timeInForce\": time_in_force.upper()})\n        if reduceOnly:\n            params.update({\"reduceOnly\": True})\n        return params\n\n    def _order_needs_price(self, side: BuySell, ordertype: str) -> bool:\n        return (\n            ordertype != \"market\"\n            or (side == \"buy\" and self._api.options.get(\"createMarketBuyOrderRequiresPrice\", False))\n            or self._ft_has.get(\"marketOrderRequiresPrice\", False)\n        )\n\n    def create_order(\n        self,\n        *,\n        pair: str,\n        ordertype: str,\n        side: BuySell,\n        amount: float,\n        rate: float,\n        leverage: float,\n        time_in_force: str = \"GTC\",\n        reduceOnly: bool = False,\n        initial_order: bool = True,\n    ) -> CcxtOrder:\n        if self._config[\"dry_run\"]:\n            dry_order = self.create_dry_run_order(\n                pair, ordertype, side, amount, self.price_to_precision(pair, rate), leverage\n            )\n            return dry_order\n\n        params = self._get_params(side, ordertype, leverage, reduceOnly, time_in_force)\n\n        try:\n            # Set the precision for amount and price(rate) as accepted by the exchange\n            amount = self.amount_to_precision(pair, self._amount_to_contracts(pair, amount))\n            needs_price = self._order_needs_price(side, ordertype)\n            rate_for_order = self.price_to_precision(pair, rate) if needs_price else None\n\n            if not reduceOnly:\n                self._lev_prep(pair, leverage, side, accept_fail=not initial_order)\n\n            order = self._api.create_order(\n                pair,\n                ordertype,\n                side,\n                amount,\n                rate_for_order,\n                params,\n            )\n            if order.get(\"status\") is None:\n                # Map empty status to open.\n                order[\"status\"] = \"open\"\n\n            if order.get(\"type\") is None:\n                order[\"type\"] = ordertype\n\n            self._log_exchange_response(\"create_order\", order)\n            order = self._order_contracts_to_amount(order)\n            return order\n\n        except ccxt.InsufficientFunds as e:\n            raise InsufficientFundsError(\n                f\"Insufficient funds to create {ordertype} {side} order on market {pair}. \"\n                f\"Tried to {side} amount {amount} at rate {rate}.\"\n                f\"Message: {e}\"\n            ) from e\n        except ccxt.InvalidOrder as e:\n            raise InvalidOrderException(\n                f\"Could not create {ordertype} {side} order on market {pair}. \"\n                f\"Tried to {side} amount {amount} at rate {rate}. \"\n                f\"Message: {e}\"\n            ) from e\n        except ccxt.DDoSProtection as e:\n            raise DDosProtection(e) from e\n        except (ccxt.OperationFailed, ccxt.ExchangeError) as e:\n            raise TemporaryError(\n                f\"Could not place {side} order due to {e.__class__.__name__}. Message: {e}\"\n            ) from e\n        except ccxt.BaseError as e:\n            raise OperationalException(e) from e\n\n    def stoploss_adjust(self, stop_loss: float, order: CcxtOrder, side: str) -> bool:\n        \"\"\"\n        Verify stop_loss against stoploss-order value (limit or price)\n        Returns True if adjustment is necessary.\n        \"\"\"\n        if not self._ft_has.get(\"stoploss_on_exchange\"):\n            raise OperationalException(f\"stoploss is not implemented for {self.name}.\")\n        price_param = self._ft_has[\"stop_price_prop\"]\n        return order.get(price_param, None) is None or (\n            (side == \"sell\" and stop_loss > float(order[price_param]))\n            or (side == \"buy\" and stop_loss < float(order[price_param]))\n        )\n\n    def _get_stop_order_type(self, user_order_type) -> tuple[str, str]:\n        available_order_Types: dict[str, str] = self._ft_has[\"stoploss_order_types\"]\n\n        if user_order_type in available_order_Types.keys():\n            ordertype = available_order_Types[user_order_type]\n        else:\n            # Otherwise pick only one available\n            ordertype = next(iter(available_order_Types.values()))\n            user_order_type = next(iter(available_order_Types.keys()))\n        return ordertype, user_order_type\n\n    def _get_stop_limit_rate(self, stop_price: float, order_types: dict, side: str) -> float:\n        # Limit price threshold: As limit price should always be below stop-price\n        limit_price_pct = order_types.get(\"stoploss_on_exchange_limit_ratio\", 0.99)\n        if side == \"sell\":\n            limit_rate = stop_price * limit_price_pct\n        else:\n            limit_rate = stop_price * (2 - limit_price_pct)\n\n        bad_stop_price = (stop_price < limit_rate) if side == \"sell\" else (stop_price > limit_rate)\n        # Ensure rate is less than stop price\n        if bad_stop_price:\n            # This can for example happen if the stop / liquidation price is set to 0\n            # Which is possible if a market-order closes right away.\n            # The InvalidOrderException will bubble up to exit_positions, where it will be\n            # handled gracefully.\n            raise InvalidOrderException(\n                \"In stoploss limit order, stop price should be more than limit price. \"\n                f\"Stop price: {stop_price}, Limit price: {limit_rate}, \"\n                f\"Limit Price pct: {limit_price_pct}\"\n            )\n        return limit_rate\n\n    def _get_stop_params(self, side: BuySell, ordertype: str, stop_price: float) -> dict:\n        params = self._params.copy()\n        # Verify if stopPrice works for your exchange, else configure stop_price_param\n        params.update({self._ft_has[\"stop_price_param\"]: stop_price})\n        return params\n\n    @retrier(retries=0)\n    def create_stoploss(\n        self,\n        pair: str,\n        amount: float,\n        stop_price: float,\n        order_types: dict,\n        side: BuySell,\n        leverage: float,\n    ) -> CcxtOrder:\n        \"\"\"\n        creates a stoploss order.\n        requires `_ft_has['stoploss_order_types']` to be set as a dict mapping limit and market\n            to the corresponding exchange type.\n\n        The precise ordertype is determined by the order_types dict or exchange default.\n\n        The exception below should never raise, since we disallow\n        starting the bot in validate_ordertypes()\n\n        This may work with a limited number of other exchanges, but correct working\n            needs to be tested individually.\n        WARNING: setting `stoploss_on_exchange` to True will NOT auto-enable stoploss on exchange.\n            `stoploss_adjust` must still be implemented for this to work.\n        \"\"\"\n        if not self._ft_has[\"stoploss_on_exchange\"]:\n            raise OperationalException(f\"stoploss is not implemented for {self.name}.\")\n\n        user_order_type = order_types.get(\"stoploss\", \"market\")\n        ordertype, user_order_type = self._get_stop_order_type(user_order_type)\n        round_mode = ROUND_DOWN if side == \"buy\" else ROUND_UP\n        stop_price_norm = self.price_to_precision(pair, stop_price, rounding_mode=round_mode)\n        limit_rate = None\n        if user_order_type == \"limit\":\n            limit_rate = self._get_stop_limit_rate(stop_price, order_types, side)\n            limit_rate = self.price_to_precision(pair, limit_rate, rounding_mode=round_mode)\n\n        if self._config[\"dry_run\"]:\n            dry_order = self.create_dry_run_order(\n                pair,\n                ordertype,\n                side,\n                amount,\n                limit_rate or stop_price_norm,\n                stop_loss=True,\n                stop_price=stop_price_norm,\n                leverage=leverage,\n            )\n            return dry_order\n\n        try:\n            params = self._get_stop_params(\n                side=side, ordertype=ordertype, stop_price=stop_price_norm\n            )\n            if self.trading_mode == TradingMode.FUTURES:\n                params[\"reduceOnly\"] = True\n                if \"stoploss_price_type\" in order_types and \"stop_price_type_field\" in self._ft_has:\n                    price_type = self._ft_has[\"stop_price_type_value_mapping\"][\n                        order_types.get(\"stoploss_price_type\", PriceType.LAST)\n                    ]\n                    params[self._ft_has[\"stop_price_type_field\"]] = price_type\n\n            amount = self.amount_to_precision(pair, self._amount_to_contracts(pair, amount))\n\n            self._lev_prep(pair, leverage, side, accept_fail=True)\n            order = self._api.create_order(\n                symbol=pair,\n                type=ordertype,\n                side=side,\n                amount=amount,\n                price=limit_rate,\n                params=params,\n            )\n            self._log_exchange_response(\"create_stoploss_order\", order)\n            order = self._order_contracts_to_amount(order)\n            logger.info(\n                f\"stoploss {user_order_type} order added for {pair}. \"\n                f\"stop price: {stop_price}. limit: {limit_rate}\"\n            )\n            return order\n        except ccxt.InsufficientFunds as e:\n            raise InsufficientFundsError(\n                f\"Insufficient funds to create {ordertype} {side} order on market {pair}. \"\n                f\"Tried to {side} amount {amount} at rate {limit_rate} with \"\n                f\"stop-price {stop_price_norm}. Message: {e}\"\n            ) from e\n        except (ccxt.InvalidOrder, ccxt.BadRequest, ccxt.OperationRejected) as e:\n            # Errors:\n            # `Order would trigger immediately.`\n            raise InvalidOrderException(\n                f\"Could not create {ordertype} {side} order on market {pair}. \"\n                f\"Tried to {side} amount {amount} at rate {limit_rate} with \"\n                f\"stop-price {stop_price_norm}. Message: {e}\"\n            ) from e\n        except ccxt.DDoSProtection as e:\n            raise DDosProtection(e) from e\n        except (ccxt.OperationFailed, ccxt.ExchangeError) as e:\n            raise TemporaryError(\n                f\"Could not place stoploss order due to {e.__class__.__name__}. Message: {e}\"\n            ) from e\n        except ccxt.BaseError as e:\n            raise OperationalException(e) from e\n\n    def fetch_order_emulated(self, order_id: str, pair: str, params: dict) -> CcxtOrder:\n        \"\"\"\n        Emulated fetch_order if the exchange doesn't support fetch_order, but requires separate\n        calls for open and closed orders.\n        \"\"\"\n        try:\n            order = self._api.fetch_open_order(order_id, pair, params=params)\n            self._log_exchange_response(\"fetch_open_order\", order)\n            order = self._order_contracts_to_amount(order)\n            return order\n        except ccxt.OrderNotFound:\n            try:\n                order = self._api.fetch_closed_order(order_id, pair, params=params)\n                self._log_exchange_response(\"fetch_closed_order\", order)\n                order = self._order_contracts_to_amount(order)\n                return order\n            except ccxt.OrderNotFound as e:\n                raise RetryableOrderError(\n                    f\"Order not found (pair: {pair} id: {order_id}). Message: {e}\"\n                ) from e\n        except ccxt.InvalidOrder as e:\n            raise InvalidOrderException(\n                f\"Tried to get an invalid order (pair: {pair} id: {order_id}). Message: {e}\"\n            ) from e\n        except ccxt.DDoSProtection as e:\n            raise DDosProtection(e) from e\n        except (ccxt.OperationFailed, ccxt.ExchangeError) as e:\n            raise TemporaryError(\n                f\"Could not get order due to {e.__class__.__name__}. Message: {e}\"\n            ) from e\n        except ccxt.BaseError as e:\n            raise OperationalException(e) from e\n\n    @retrier(retries=API_FETCH_ORDER_RETRY_COUNT)\n    def fetch_order(self, order_id: str, pair: str, params: dict | None = None) -> CcxtOrder:\n        if self._config[\"dry_run\"]:\n            return self.fetch_dry_run_order(order_id)\n        if params is None:\n            params = {}\n        try:\n            if not self.exchange_has(\"fetchOrder\"):\n                return self.fetch_order_emulated(order_id, pair, params)\n            order = self._api.fetch_order(order_id, pair, params=params)\n            self._log_exchange_response(\"fetch_order\", order)\n            order = self._order_contracts_to_amount(order)\n            return order\n        except ccxt.OrderNotFound as e:\n            raise RetryableOrderError(\n                f\"Order not found (pair: {pair} id: {order_id}). Message: {e}\"\n            ) from e\n        except ccxt.InvalidOrder as e:\n            raise InvalidOrderException(\n                f\"Tried to get an invalid order (pair: {pair} id: {order_id}). Message: {e}\"\n            ) from e\n        except ccxt.DDoSProtection as e:\n            raise DDosProtection(e) from e\n        except (ccxt.OperationFailed, ccxt.ExchangeError) as e:\n            raise TemporaryError(\n                f\"Could not get order due to {e.__class__.__name__}. Message: {e}\"\n            ) from e\n        except ccxt.BaseError as e:\n            raise OperationalException(e) from e\n\n    def fetch_stoploss_order(\n        self, order_id: str, pair: str, params: dict | None = None\n    ) -> CcxtOrder:\n        if self.get_option(\"stoploss_query_requires_stop_flag\"):\n            params = params or {}\n            params[\"stop\"] = True\n        order = self.fetch_order(order_id, pair, params)\n        val = self.get_option(\"stoploss_algo_order_info_id\")\n        if val and order.get(\"status\", \"open\") == \"closed\":\n            if new_orderid := order.get(\"info\", {}).get(val):\n                # Fetch real order, which was placed by the algo order.\n                actual_order = self.fetch_order(order_id=new_orderid, pair=pair, params=None)\n                actual_order[\"id_stop\"] = actual_order[\"id\"]\n                actual_order[\"id\"] = order_id\n                actual_order[\"type\"] = \"stoploss\"\n                actual_order[\"stopPrice\"] = order.get(\"stopPrice\")\n                actual_order[\"status_stop\"] = \"triggered\"\n\n                return actual_order\n\n        return order\n\n    def fetch_order_or_stoploss_order(\n        self, order_id: str, pair: str, stoploss_order: bool = False\n    ) -> CcxtOrder:\n        \"\"\"\n        Simple wrapper calling either fetch_order or fetch_stoploss_order depending on\n        the stoploss_order parameter\n        :param order_id: OrderId to fetch order\n        :param pair: Pair corresponding to order_id\n        :param stoploss_order: If true, uses fetch_stoploss_order, otherwise fetch_order.\n        \"\"\"\n        if stoploss_order:\n            return self.fetch_stoploss_order(order_id, pair)\n        return self.fetch_order(order_id, pair)\n\n    def check_order_canceled_empty(self, order: CcxtOrder) -> bool:\n        \"\"\"\n        Verify if an order has been cancelled without being partially filled\n        :param order: Order dict as returned from fetch_order()\n        :return: True if order has been cancelled without being filled, False otherwise.\n        \"\"\"\n        return order.get(\"status\") in NON_OPEN_EXCHANGE_STATES and order.get(\"filled\") == 0.0\n\n    @retrier\n    def cancel_order(self, order_id: str, pair: str, params: dict | None = None) -> dict[str, Any]:\n        if self._config[\"dry_run\"]:\n            try:\n                order = self.fetch_dry_run_order(order_id)\n\n                order.update({\"status\": \"canceled\", \"filled\": 0.0, \"remaining\": order[\"amount\"]})\n                return order\n            except InvalidOrderException:\n                return {}\n\n        if params is None:\n            params = {}\n        try:\n            order = self._api.cancel_order(order_id, pair, params=params)\n            self._log_exchange_response(\"cancel_order\", order)\n            order = self._order_contracts_to_amount(order)\n            return order\n        except ccxt.InvalidOrder as e:\n            raise InvalidOrderException(f\"Could not cancel order. Message: {e}\") from e\n        except ccxt.DDoSProtection as e:\n            raise DDosProtection(e) from e\n        except (ccxt.OperationFailed, ccxt.ExchangeError) as e:\n            raise TemporaryError(\n                f\"Could not cancel order due to {e.__class__.__name__}. Message: {e}\"\n            ) from e\n        except ccxt.BaseError as e:\n            raise OperationalException(e) from e\n\n    def cancel_stoploss_order(self, order_id: str, pair: str, params: dict | None = None) -> dict:\n        if self.get_option(\"stoploss_query_requires_stop_flag\"):\n            params = params or {}\n            params[\"stop\"] = True\n        return self.cancel_order(order_id, pair, params)\n\n    def is_cancel_order_result_suitable(self, corder) -> TypeGuard[CcxtOrder]:\n        if not isinstance(corder, dict):\n            return False\n\n        required = (\"fee\", \"status\", \"amount\")\n        return all(corder.get(k, None) is not None for k in required)\n\n    def cancel_order_with_result(self, order_id: str, pair: str, amount: float) -> CcxtOrder:\n        \"\"\"\n        Cancel order returning a result.\n        Creates a fake result if cancel order returns a non-usable result\n        and fetch_order does not work (certain exchanges don't return cancelled orders)\n        :param order_id: Orderid to cancel\n        :param pair: Pair corresponding to order_id\n        :param amount: Amount to use for fake response\n        :return: Result from either cancel_order if usable, or fetch_order\n        \"\"\"\n        try:\n            corder = self.cancel_order(order_id, pair)\n            if self.is_cancel_order_result_suitable(corder):\n                return corder\n        except InvalidOrderException:\n            logger.warning(f\"Could not cancel order {order_id} for {pair}.\")\n        try:\n            order = self.fetch_order(order_id, pair)\n        except InvalidOrderException:\n            logger.warning(f\"Could not fetch cancelled order {order_id}.\")\n            order = {\n                \"id\": order_id,\n                \"status\": \"canceled\",\n                \"amount\": amount,\n                \"filled\": 0.0,\n                \"fee\": {},\n                \"info\": {},\n            }\n\n        return order\n\n    def cancel_stoploss_order_with_result(\n        self, order_id: str, pair: str, amount: float\n    ) -> CcxtOrder:\n        \"\"\"\n        Cancel stoploss order returning a result.\n        Creates a fake result if cancel order returns a non-usable result\n        and fetch_order does not work (certain exchanges don't return cancelled orders)\n        :param order_id: stoploss-order-id to cancel\n        :param pair: Pair corresponding to order_id\n        :param amount: Amount to use for fake response\n        :return: Result from either cancel_order if usable, or fetch_order\n        \"\"\"\n        corder = self.cancel_stoploss_order(order_id, pair)\n        if self.is_cancel_order_result_suitable(corder):\n            return corder\n        try:\n            order = self.fetch_stoploss_order(order_id, pair)\n        except InvalidOrderException:\n            logger.warning(f\"Could not fetch cancelled stoploss order {order_id}.\")\n            order = {\"id\": order_id, \"fee\": {}, \"status\": \"canceled\", \"amount\": amount, \"info\": {}}\n\n        return order\n\n    @retrier\n    def get_balances(self, params: dict | None = None) -> CcxtBalances:\n        try:\n            balances = self._api.fetch_balance(params or {})\n            # Remove additional info from ccxt results\n            balances.pop(\"info\", None)\n            balances.pop(\"free\", None)\n            balances.pop(\"total\", None)\n            balances.pop(\"used\", None)\n\n            self._log_exchange_response(\"fetch_balance\", balances, add_info=params)\n            return balances\n        except ccxt.DDoSProtection as e:\n            raise DDosProtection(e) from e\n        except (ccxt.OperationFailed, ccxt.ExchangeError) as e:\n            raise TemporaryError(\n                f\"Could not get balance due to {e.__class__.__name__}. Message: {e}\"\n            ) from e\n        except ccxt.BaseError as e:\n            raise OperationalException(e) from e\n\n    @retrier\n    def fetch_positions(\n        self, pair: str | None = None, params: dict | None = None\n    ) -> list[CcxtPosition]:\n        \"\"\"\n        Fetch positions from the exchange.\n        If no pair is given, all positions are returned.\n        :param pair: Pair for the query\n        \"\"\"\n        if self._config[\"dry_run\"] or self.trading_mode != TradingMode.FUTURES:\n            return []\n        try:\n            symbols = None\n            if pair:\n                symbols = [pair]\n            positions: list[CcxtPosition] = self._api.fetch_positions(symbols, params=params or {})\n            self._log_exchange_response(\"fetch_positions\", positions)\n            return positions\n        except ccxt.DDoSProtection as e:\n            raise DDosProtection(e) from e\n        except (ccxt.OperationFailed, ccxt.ExchangeError) as e:\n            raise TemporaryError(\n                f\"Could not get positions due to {e.__class__.__name__}. Message: {e}\"\n            ) from e\n        except ccxt.BaseError as e:\n            raise OperationalException(e) from e\n\n    def _fetch_orders_emulate(self, pair: str, since_ms: int) -> list[CcxtOrder]:\n        orders = []\n        if self.exchange_has(\"fetchClosedOrders\"):\n            orders = self._api.fetch_closed_orders(pair, since=since_ms)\n            if self.exchange_has(\"fetchOpenOrders\"):\n                orders_open = self._api.fetch_open_orders(pair, since=since_ms)\n                orders.extend(orders_open)\n        return orders\n\n    @retrier(retries=0)\n    def _fetch_orders(\n        self, pair: str, since: datetime, params: dict | None = None\n    ) -> list[CcxtOrder]:\n        \"\"\"\n        Fetch all orders for a pair \"since\"\n        :param pair: Pair for the query\n        :param since: Starting time for the query\n        \"\"\"\n        if self._config[\"dry_run\"]:\n            return []\n\n        try:\n            since_ms = int((since.timestamp() - 10) * 1000)\n\n            if self.exchange_has(\"fetchOrders\"):\n                if not params:\n                    params = {}\n                try:\n                    orders: list[CcxtOrder] = self._api.fetch_orders(\n                        pair, since=since_ms, params=params\n                    )\n                except ccxt.NotSupported:\n                    # Some exchanges don't support fetchOrders\n                    # attempt to fetch open and closed orders separately\n                    orders = self._fetch_orders_emulate(pair, since_ms)\n            else:\n                orders = self._fetch_orders_emulate(pair, since_ms)\n            self._log_exchange_response(\"fetch_orders\", orders)\n            orders = [self._order_contracts_to_amount(o) for o in orders]\n            return orders\n        except ccxt.DDoSProtection as e:\n            raise DDosProtection(e) from e\n        except (ccxt.OperationFailed, ccxt.ExchangeError) as e:\n            raise TemporaryError(\n                f\"Could not fetch positions due to {e.__class__.__name__}. Message: {e}\"\n            ) from e\n        except ccxt.BaseError as e:\n            raise OperationalException(e) from e\n\n    def fetch_orders(\n        self, pair: str, since: datetime, params: dict | None = None\n    ) -> list[CcxtOrder]:\n        if self._config[\"dry_run\"]:\n            return []\n        if (limit := self._ft_has.get(\"fetch_orders_limit_minutes\")) is not None:\n            orders = []\n            while since < dt_now():\n                orders += self._fetch_orders(pair, since)\n                # Since with 1 minute overlap\n                since = since + timedelta(minutes=limit - 1)\n            # Ensure each order is unique based on order id\n            orders = list({order[\"id\"]: order for order in orders}.values())\n            return orders\n\n        else:\n            return self._fetch_orders(pair, since, params=params)\n\n    @retrier\n    def fetch_trading_fees(self) -> dict[str, Any]:\n        \"\"\"\n        Fetch user account trading fees\n        Can be cached, should not update often.\n        \"\"\"\n        if (\n            self._config[\"dry_run\"]\n            or self.trading_mode != TradingMode.FUTURES\n            or not self.exchange_has(\"fetchTradingFees\")\n        ):\n            return {}\n        try:\n            trading_fees: dict[str, Any] = self._api.fetch_trading_fees()\n            self._log_exchange_response(\"fetch_trading_fees\", trading_fees)\n            return trading_fees\n        except ccxt.DDoSProtection as e:\n            raise DDosProtection(e) from e\n        except (ccxt.OperationFailed, ccxt.ExchangeError) as e:\n            raise TemporaryError(\n                f\"Could not fetch trading fees due to {e.__class__.__name__}. Message: {e}\"\n            ) from e\n        except ccxt.BaseError as e:\n            raise OperationalException(e) from e\n\n    @retrier\n    def fetch_bids_asks(self, symbols: list[str] | None = None, *, cached: bool = False) -> dict:\n        \"\"\"\n        :param symbols: List of symbols to fetch\n        :param cached: Allow cached result\n        :return: fetch_bids_asks result\n        \"\"\"\n        if not self.exchange_has(\"fetchBidsAsks\"):\n            return {}\n        if cached:\n            with self._cache_lock:\n                tickers = self._fetch_tickers_cache.get(\"fetch_bids_asks\")\n            if tickers:\n                return tickers\n        try:\n            tickers = self._api.fetch_bids_asks(symbols)\n            with self._cache_lock:\n                self._fetch_tickers_cache[\"fetch_bids_asks\"] = tickers\n            return tickers\n        except ccxt.NotSupported as e:\n            raise OperationalException(\n                f\"Exchange {self._api.name} does not support fetching bids/asks in batch. \"\n                f\"Message: {e}\"\n            ) from e\n        except ccxt.DDoSProtection as e:\n            raise DDosProtection(e) from e\n        except (ccxt.OperationFailed, ccxt.ExchangeError) as e:\n            raise TemporaryError(\n                f\"Could not load bids/asks due to {e.__class__.__name__}. Message: {e}\"\n            ) from e\n        except ccxt.BaseError as e:\n            raise OperationalException(e) from e\n\n    @retrier\n    def get_tickers(\n        self,\n        symbols: list[str] | None = None,\n        *,\n        cached: bool = False,\n        market_type: TradingMode | None = None,\n    ) -> Tickers:\n        \"\"\"\n        :param symbols: List of symbols to fetch\n        :param cached: Allow cached result\n        :param market_type: Market type to fetch - either spot or futures.\n        :return: fetch_tickers result\n        \"\"\"\n        tickers: Tickers\n        if not self.exchange_has(\"fetchTickers\"):\n            return {}\n        cache_key = f\"fetch_tickers_{market_type}\" if market_type else \"fetch_tickers\"\n        if cached:\n            with self._cache_lock:\n                tickers = self._fetch_tickers_cache.get(cache_key)  # type: ignore\n            if tickers:\n                return tickers\n        try:\n            # Re-map futures to swap\n            market_types = {\n                TradingMode.FUTURES: \"swap\",\n            }\n            params = {\"type\": market_types.get(market_type, market_type)} if market_type else {}\n            tickers = self._api.fetch_tickers(symbols, params)\n            with self._cache_lock:\n                self._fetch_tickers_cache[cache_key] = tickers\n            return tickers\n        except ccxt.NotSupported as e:\n            raise OperationalException(\n                f\"Exchange {self._api.name} does not support fetching tickers in batch. \"\n                f\"Message: {e}\"\n            ) from e\n        except ccxt.BadSymbol as e:\n            logger.warning(\n                f\"Could not load tickers due to {e.__class__.__name__}. Message: {e} .\"\n                \"Reloading markets.\"\n            )\n            self.reload_markets(True)\n            # Re-raise exception to repeat the call.\n            raise TemporaryError from e\n        except ccxt.DDoSProtection as e:\n            raise DDosProtection(e) from e\n        except (ccxt.OperationFailed, ccxt.ExchangeError) as e:\n            raise TemporaryError(\n                f\"Could not load tickers due to {e.__class__.__name__}. Message: {e}\"\n            ) from e\n        except ccxt.BaseError as e:\n            raise OperationalException(e) from e\n\n    def get_proxy_coin(self) -> str:\n        \"\"\"\n        Get the proxy coin for the given coin\n        Falls back to the stake currency if no proxy coin is found\n        :return: Proxy coin or stake currency\n        \"\"\"\n        return self._config[\"stake_currency\"]\n\n    def get_conversion_rate(self, coin: str, currency: str) -> float | None:\n        \"\"\"\n        Quick and cached way to get conversion rate one currency to the other.\n        Can then be used as \"rate * amount\" to convert between currencies.\n        :param coin: Coin to convert\n        :param currency: Currency to convert to\n        :returns: Conversion rate from coin to currency\n        :raises: ExchangeErrors\n        \"\"\"\n\n        if (proxy_coin := self._ft_has[\"proxy_coin_mapping\"].get(coin, None)) is not None:\n            coin = proxy_coin\n        if (proxy_currency := self._ft_has[\"proxy_coin_mapping\"].get(currency, None)) is not None:\n            currency = proxy_currency\n        if coin == currency:\n            return 1.0\n        tickers = self.get_tickers(cached=True)\n        try:\n            for pair in self.get_valid_pair_combination(coin, currency):\n                ticker: Ticker | None = tickers.get(pair, None)\n                if not ticker:\n                    tickers_other: Tickers = self.get_tickers(\n                        cached=True,\n                        market_type=(\n                            TradingMode.SPOT\n                            if self.trading_mode != TradingMode.SPOT\n                            else TradingMode.FUTURES\n                        ),\n                    )\n                    ticker = tickers_other.get(pair, None)\n                if ticker:\n                    rate: float | None = safe_value_fallback(ticker, \"last\", \"ask\", None)\n                    if rate and pair.startswith(currency) and not pair.endswith(currency):\n                        rate = 1.0 / rate\n                    return rate\n        except ValueError:\n            return None\n        return None\n\n    @retrier\n    def fetch_ticker(self, pair: str) -> Ticker:\n        try:\n            if pair not in self.markets or self.markets[pair].get(\"active\", False) is False:\n                raise ExchangeError(f\"Pair {pair} not available\")\n            data: Ticker = self._api.fetch_ticker(pair)\n            return data\n        except ccxt.DDoSProtection as e:\n            raise DDosProtection(e) from e\n        except (ccxt.OperationFailed, ccxt.ExchangeError) as e:\n            raise TemporaryError(\n                f\"Could not load ticker due to {e.__class__.__name__}. Message: {e}\"\n            ) from e\n        except ccxt.BaseError as e:\n            raise OperationalException(e) from e\n\n    @retrier\n    def fetch_funding_rate(self, pair: str) -> FundingRate:\n        \"\"\"\n        Get current Funding rate from exchange.\n        On Futures markets, this is the interest rate for holding a position.\n        Won't work for non-futures markets\n        \"\"\"\n        try:\n            if pair not in self.markets or self.markets[pair].get(\"active\", False) is False:\n                raise ExchangeError(f\"Pair {pair} not available\")\n            return self._api.fetch_funding_rate(pair)\n        except ccxt.NotSupported as e:\n            raise OperationalException(\n                f\"Exchange {self._api.name} does not support fetching funding rate. Message: {e}\"\n            ) from e\n        except ccxt.DDoSProtection as e:\n            raise DDosProtection(e) from e\n        except (ccxt.OperationFailed, ccxt.ExchangeError) as e:\n            raise TemporaryError(\n                f\"Could not get funding rate due to {e.__class__.__name__}. Message: {e}\"\n            ) from e\n        except ccxt.BaseError as e:\n            raise OperationalException(e) from e\n\n    @staticmethod\n    def get_next_limit_in_list(\n        limit: int,\n        limit_range: list[int] | None,\n        range_required: bool = True,\n        upper_limit: int | None = None,\n    ):\n        \"\"\"\n        Get next greater value in the list.\n        Used by fetch_l2_order_book if the api only supports a limited range\n        if both limit_range and upper_limit is provided, limit_range wins.\n        \"\"\"\n        if not limit_range:\n            return min(limit, upper_limit) if upper_limit else limit\n\n        result = min([x for x in limit_range if limit <= x] + [max(limit_range)])\n        if not range_required and limit > result:\n            # Range is not required - we can use None as parameter.\n            return None\n        return result\n\n    @retrier\n    def fetch_l2_order_book(self, pair: str, limit: int = 100) -> OrderBook:\n        \"\"\"\n        Get L2 order book from exchange.\n        Can be limited to a certain amount (if supported).\n        Returns a dict in the format\n        {'asks': [price, volume], 'bids': [price, volume]}\n        \"\"\"\n        limit1 = self.get_next_limit_in_list(\n            limit,\n            self._ft_has[\"l2_limit_range\"],\n            self._ft_has[\"l2_limit_range_required\"],\n            self._ft_has[\"l2_limit_upper\"],\n        )\n        try:\n            return self._api.fetch_l2_order_book(pair, limit1)\n        except ccxt.NotSupported as e:\n            raise OperationalException(\n                f\"Exchange {self._api.name} does not support fetching order book. Message: {e}\"\n            ) from e\n        except ccxt.DDoSProtection as e:\n            raise DDosProtection(e) from e\n        except (ccxt.OperationFailed, ccxt.ExchangeError) as e:\n            raise TemporaryError(\n                f\"Could not get order book due to {e.__class__.__name__}. Message: {e}\"\n            ) from e\n        except ccxt.BaseError as e:\n            raise OperationalException(e) from e\n\n    def _get_price_side(self, side: str, is_short: bool, conf_strategy: dict) -> BidAsk:\n        price_side = conf_strategy[\"price_side\"]\n\n        if price_side in (\"same\", \"other\"):\n            price_map = {\n                (\"entry\", \"long\", \"same\"): \"bid\",\n                (\"entry\", \"long\", \"other\"): \"ask\",\n                (\"entry\", \"short\", \"same\"): \"ask\",\n                (\"entry\", \"short\", \"other\"): \"bid\",\n                (\"exit\", \"long\", \"same\"): \"ask\",\n                (\"exit\", \"long\", \"other\"): \"bid\",\n                (\"exit\", \"short\", \"same\"): \"bid\",\n                (\"exit\", \"short\", \"other\"): \"ask\",\n            }\n            price_side = price_map[(side, \"short\" if is_short else \"long\", price_side)]\n        return price_side\n\n    def get_rate(\n        self,\n        pair: str,\n        refresh: bool,\n        side: EntryExit,\n        is_short: bool,\n        order_book: OrderBook | None = None,\n        ticker: Ticker | None = None,\n    ) -> float:\n        \"\"\"\n        Calculates bid/ask target\n        bid rate - between current ask price and last price\n        ask rate - either using ticker bid or first bid based on orderbook\n        or remain static in any other case since it's not updating.\n        :param pair: Pair to get rate for\n        :param refresh: allow cached data\n        :param side: \"buy\" or \"sell\"\n        :return: float: Price\n        :raises PricingError if orderbook price could not be determined.\n        \"\"\"\n        name = side.capitalize()\n        strat_name = \"entry_pricing\" if side == \"entry\" else \"exit_pricing\"\n\n        cache_rate: FtTTLCache = (\n            self._entry_rate_cache if side == \"entry\" else self._exit_rate_cache\n        )\n        if not refresh:\n            with self._cache_lock:\n                rate = cache_rate.get(pair)\n            # Check if cache has been invalidated\n            if rate:\n                logger.debug(f\"Using cached {side} rate for {pair}.\")\n                return rate\n\n        conf_strategy = self._config.get(strat_name, {})\n\n        price_side = self._get_price_side(side, is_short, conf_strategy)\n\n        if conf_strategy.get(\"use_order_book\", False):\n            order_book_top = conf_strategy.get(\"order_book_top\", 1)\n            if order_book is None:\n                order_book = self.fetch_l2_order_book(pair, order_book_top)\n            rate = self._get_rate_from_ob(pair, side, order_book, name, price_side, order_book_top)\n        else:\n            logger.debug(f\"Using Last {price_side.capitalize()} / Last Price\")\n            if ticker is None:\n                ticker = self.fetch_ticker(pair)\n            rate = self._get_rate_from_ticker(side, ticker, conf_strategy, price_side)\n\n        if rate is None:\n            raise PricingError(f\"{name}-Rate for {pair} was empty.\")\n        with self._cache_lock:\n            cache_rate[pair] = rate\n\n        return rate\n\n    def _get_rate_from_ticker(\n        self, side: EntryExit, ticker: Ticker, conf_strategy: dict[str, Any], price_side: BidAsk\n    ) -> float | None:\n        \"\"\"\n        Get rate from ticker.\n        \"\"\"\n        ticker_rate = ticker[price_side]\n        if ticker[\"last\"] and ticker_rate:\n            if side == \"entry\" and ticker_rate > ticker[\"last\"]:\n                balance = conf_strategy.get(\"price_last_balance\", 0.0)\n                ticker_rate = ticker_rate + balance * (ticker[\"last\"] - ticker_rate)\n            elif side == \"exit\" and ticker_rate < ticker[\"last\"]:\n                balance = conf_strategy.get(\"price_last_balance\", 0.0)\n                ticker_rate = ticker_rate - balance * (ticker_rate - ticker[\"last\"])\n        rate = ticker_rate\n        return rate\n\n    def _get_rate_from_ob(\n        self,\n        pair: str,\n        side: EntryExit,\n        order_book: OrderBook,\n        name: str,\n        price_side: BidAsk,\n        order_book_top: int,\n    ) -> float:\n        \"\"\"\n        Get rate from orderbook\n        :raises: PricingError if rate could not be determined.\n        \"\"\"\n        logger.debug(\"order_book %s\", order_book)\n        # top 1 = index 0\n        try:\n            obside: OBLiteral = \"bids\" if price_side == \"bid\" else \"asks\"\n            rate = order_book[obside][order_book_top - 1][0]\n        except (IndexError, KeyError) as e:\n            logger.warning(\n                f\"{pair} - {name} Price at location {order_book_top} from orderbook \"\n                f\"could not be determined. Orderbook: {order_book}\"\n            )\n            raise PricingError from e\n        logger.debug(\n            f\"{pair} - {name} price from orderbook {price_side.capitalize()}\"\n            f\"side - top {order_book_top} order book {side} rate {rate:.8f}\"\n        )\n        return rate\n\n    def get_rates(self, pair: str, refresh: bool, is_short: bool) -> tuple[float, float]:\n        entry_rate = None\n        exit_rate = None\n        if not refresh:\n            with self._cache_lock:\n                entry_rate = self._entry_rate_cache.get(pair)\n                exit_rate = self._exit_rate_cache.get(pair)\n            if entry_rate:\n                logger.debug(f\"Using cached buy rate for {pair}.\")\n            if exit_rate:\n                logger.debug(f\"Using cached sell rate for {pair}.\")\n\n        entry_pricing = self._config.get(\"entry_pricing\", {})\n        exit_pricing = self._config.get(\"exit_pricing\", {})\n        order_book = ticker = None\n        if not entry_rate and entry_pricing.get(\"use_order_book\", False):\n            order_book_top = max(\n                entry_pricing.get(\"order_book_top\", 1), exit_pricing.get(\"order_book_top\", 1)\n            )\n            order_book = self.fetch_l2_order_book(pair, order_book_top)\n            entry_rate = self.get_rate(pair, refresh, \"entry\", is_short, order_book=order_book)\n        elif not entry_rate:\n            ticker = self.fetch_ticker(pair)\n            entry_rate = self.get_rate(pair, refresh, \"entry\", is_short, ticker=ticker)\n        if not exit_rate:\n            exit_rate = self.get_rate(\n                pair, refresh, \"exit\", is_short, order_book=order_book, ticker=ticker\n            )\n        return entry_rate, exit_rate\n\n    # Fee handling\n\n    @retrier\n    def get_trades_for_order(\n        self, order_id: str, pair: str, since: datetime, params: dict | None = None\n    ) -> list:\n        \"\"\"\n        Fetch Orders using the \"fetch_my_trades\" endpoint and filter them by order-id.\n        The \"since\" argument passed in is coming from the database and is in UTC,\n        as timezone-native datetime object.\n        From the python documentation:\n            > Naive datetime instances are assumed to represent local time\n        Therefore, calling \"since.timestamp()\" will get the UTC timestamp, after applying the\n        transformation from local timezone to UTC.\n        This works for timezones UTC+ since then the result will contain trades from a few hours\n        instead of from the last 5 seconds, however fails for UTC- timezones,\n        since we're then asking for trades with a \"since\" argument in the future.\n\n        :param order_id order_id: Order-id as given when creating the order\n        :param pair: Pair the order is for\n        :param since: datetime object of the order creation time. Assumes object is in UTC.\n        \"\"\"\n        if self._config[\"dry_run\"]:\n            return []\n        if not self.exchange_has(\"fetchMyTrades\"):\n            return []\n        try:\n            # Allow 5s offset to catch slight time offsets (discovered in #1185)\n            # since needs to be int in milliseconds\n            _params = params if params else {}\n            my_trades = self._api.fetch_my_trades(\n                pair,\n                int((since.replace(tzinfo=UTC).timestamp() - 5) * 1000),\n                params=_params,\n            )\n            matched_trades = [trade for trade in my_trades if trade[\"order\"] == order_id]\n\n            self._log_exchange_response(\"get_trades_for_order\", matched_trades)\n\n            matched_trades = self._trades_contracts_to_amount(matched_trades)\n\n            return matched_trades\n        except ccxt.DDoSProtection as e:\n            raise DDosProtection(e) from e\n        except (ccxt.OperationFailed, ccxt.ExchangeError) as e:\n            raise TemporaryError(\n                f\"Could not get trades due to {e.__class__.__name__}. Message: {e}\"\n            ) from e\n        except ccxt.BaseError as e:\n            raise OperationalException(e) from e\n\n    def get_order_id_conditional(self, order: CcxtOrder) -> str:\n        \"\"\"\n        Return order id or id_stop (for conditional orders) based on exchange settings\n\n        :param order: ccxt order dict\n        :return: correct order id\n        \"\"\"\n        if self.get_option(\"stoploss_query_requires_stop_flag\") and (\n            order[\"type\"] in (\"stoploss\", \"stop\")\n        ):\n            return safe_value_fallback(order, \"id_stop\", \"id\")\n        return order[\"id\"]\n\n    @retrier\n    def get_fee(\n        self,\n        symbol: str,\n        order_type: str = \"\",\n        side: str = \"\",\n        amount: float = 1,\n        price: float = 1,\n        taker_or_maker: MakerTaker = \"maker\",\n    ) -> float:\n        \"\"\"\n        Retrieve fee from exchange\n        :param symbol: Pair\n        :param order_type: Type of order (market, limit, ...)\n        :param side: Side of order (buy, sell)\n        :param amount: Amount of order\n        :param price: Price of order\n        :param taker_or_maker: 'maker' or 'taker' (ignored if \"type\" is provided)\n        \"\"\"\n        if order_type and order_type == \"market\":\n            taker_or_maker = \"taker\"\n        try:\n            if self._config[\"dry_run\"] and self._config.get(\"fee\", None) is not None:\n                return self._config[\"fee\"]\n            # validate that markets are loaded before trying to get fee\n            if self._api.markets is None or len(self._api.markets) == 0:\n                self._api.load_markets(params={})\n\n            return self._api.calculate_fee(\n                symbol=symbol,\n                type=order_type,\n                side=side,\n                amount=amount,\n                price=price,\n                takerOrMaker=taker_or_maker,\n            )[\"rate\"]\n        except ccxt.DDoSProtection as e:\n            raise DDosProtection(e) from e\n        except (ccxt.OperationFailed, ccxt.ExchangeError) as e:\n            raise TemporaryError(\n                f\"Could not get fee info due to {e.__class__.__name__}. Message: {e}\"\n            ) from e\n        except ccxt.BaseError as e:\n            raise OperationalException(e) from e\n\n    @staticmethod\n    def order_has_fee(order: CcxtOrder) -> bool:\n        \"\"\"\n        Verifies if the passed in order dict has the needed keys to extract fees,\n        and that these keys (currency, cost) are not empty.\n        :param order: Order or trade (one trade) dict\n        :return: True if the fee substructure contains currency and cost, false otherwise\n        \"\"\"\n        if not isinstance(order, dict):\n            return False\n        return (\n            \"fee\" in order\n            and order[\"fee\"] is not None\n            and (order[\"fee\"].keys() >= {\"currency\", \"cost\"})\n            and order[\"fee\"][\"currency\"] is not None\n            and order[\"fee\"][\"cost\"] is not None\n        )\n\n    def calculate_fee_rate(\n        self, fee: dict, symbol: str, cost: float, amount: float\n    ) -> float | None:\n        \"\"\"\n        Calculate fee rate if it's not given by the exchange.\n        :param fee: ccxt Fee dict - must contain cost / currency / rate\n        :param symbol: Symbol of the order\n        :param cost: Total cost of the order\n        :param amount: Amount of the order\n        \"\"\"\n        if fee.get(\"rate\") is not None:\n            return fee.get(\"rate\")\n        fee_curr = fee.get(\"currency\")\n        if fee_curr is None:\n            return None\n        fee_cost = float(fee[\"cost\"])\n\n        # Calculate fee based on order details\n        if fee_curr == self.get_pair_base_currency(symbol):\n            # Base currency - divide by amount\n            return round(fee_cost / amount, 8)\n        elif fee_curr == self.get_pair_quote_currency(symbol):\n            # Quote currency - divide by cost\n            return round(fee_cost / cost, 8) if cost else None\n        else:\n            # If Fee currency is a different currency\n            if not cost:\n                # If cost is None or 0.0 -> falsy, return None\n                return None\n            try:\n                fee_to_quote_rate = self.get_conversion_rate(\n                    fee_curr, self._config[\"stake_currency\"]\n                )\n                if not fee_to_quote_rate:\n                    raise ValueError(\"Conversion rate not found.\")\n            except (ValueError, ExchangeError):\n                fee_to_quote_rate = self._config[\"exchange\"].get(\"unknown_fee_rate\", None)\n                if not fee_to_quote_rate:\n                    return None\n            return round((fee_cost * fee_to_quote_rate) / cost, 8)\n\n    def extract_cost_curr_rate(\n        self, fee: dict[str, Any], symbol: str, cost: float, amount: float\n    ) -> tuple[float, str, float | None]:\n        \"\"\"\n        Extract tuple of cost, currency, rate.\n        Requires order_has_fee to run first!\n        :param fee: ccxt Fee dict - must contain cost / currency / rate\n        :param symbol: Symbol of the order\n        :param cost: Total cost of the order\n        :param amount: Amount of the order\n        :return: Tuple with cost, currency, rate of the given fee dict\n        \"\"\"\n        return (\n            float(fee[\"cost\"]),\n            fee[\"currency\"],\n            self.calculate_fee_rate(fee, symbol, cost, amount),\n        )\n\n    # Historic data\n\n    def get_historic_ohlcv(\n        self,\n        pair: str,\n        timeframe: str,\n        since_ms: int,\n        candle_type: CandleType,\n        is_new_pair: bool = False,\n        until_ms: int | None = None,\n    ) -> DataFrame:\n        \"\"\"\n        Get candle history using asyncio and returns the list of candles.\n        Handles all async work for this.\n        Async over one pair, assuming we get `self.ohlcv_candle_limit()` candles per call.\n        :param pair: Pair to download\n        :param timeframe: Timeframe to get data for\n        :param since_ms: Timestamp in milliseconds to get history from\n        :param candle_type: '', mark, index, premiumIndex, or funding_rate\n        :param is_new_pair: used by binance subclass to allow \"fast\" new pair downloading\n        :param until_ms: Timestamp in milliseconds to get history up to\n        :return: Dataframe with candle (OHLCV) data\n        \"\"\"\n        with self._loop_lock:\n            pair, _, _, data, _ = self.loop.run_until_complete(\n                self._async_get_historic_ohlcv(\n                    pair=pair,\n                    timeframe=timeframe,\n                    since_ms=since_ms,\n                    until_ms=until_ms,\n                    candle_type=candle_type,\n                    raise_=True,\n                )\n            )\n        logger.debug(f\"Downloaded data for {pair} from ccxt with length {len(data)}.\")\n        return ohlcv_to_dataframe(data, timeframe, pair, fill_missing=False, drop_incomplete=True)\n\n    async def _async_get_historic_ohlcv(\n        self,\n        pair: str,\n        timeframe: str,\n        since_ms: int,\n        candle_type: CandleType,\n        raise_: bool = False,\n        until_ms: int | None = None,\n    ) -> OHLCVResponse:\n        \"\"\"\n        Download historic ohlcv\n        :param candle_type: Any of the enum CandleType (must match trading mode!)\n        \"\"\"\n\n        one_call = timeframe_to_msecs(timeframe) * self.ohlcv_candle_limit(\n            timeframe, candle_type, since_ms\n        )\n        logger.debug(\n            \"one_call: %s msecs (%s)\",\n            one_call,\n            dt_humanize_delta(dt_now() - timedelta(milliseconds=one_call)),\n        )\n        input_coroutines = [\n            self._async_get_candle_history(pair, timeframe, candle_type, since)\n            for since in range(since_ms, until_ms or dt_ts(), one_call)\n        ]\n\n        data: list = []\n        # Chunk requests into batches of 100 to avoid overwhelming ccxt Throttling\n        for input_coro in chunks(input_coroutines, 100):\n            results = await asyncio.gather(*input_coro, return_exceptions=True)\n            for res in results:\n                if isinstance(res, BaseException):\n                    logger.warning(f\"Async code raised an exception: {repr(res)}\")\n                    if raise_:\n                        raise res\n                    continue\n                else:\n                    # Deconstruct tuple if it's not an exception\n                    p, _, c, new_data, _ = res\n                    if p == pair and c == candle_type:\n                        data.extend(new_data)\n        # Sort data again after extending the result - above calls return in \"async order\"\n        data = sorted(data, key=lambda x: x[0])\n        return (\n            pair,\n            timeframe,\n            candle_type,\n            data,\n            # funding_rates are always complete, so never need to be dropped.\n            self._ohlcv_partial_candle if candle_type != CandleType.FUNDING_RATE else False,\n        )\n\n    def _try_build_from_websocket(\n        self, pair: str, timeframe: str, candle_type: CandleType\n    ) -> Coroutine[Any, Any, OHLCVResponse] | None:\n        \"\"\"\n        Try to build a coroutine to get data from websocket.\n        \"\"\"\n        if self._can_use_websocket(self._exchange_ws, pair, timeframe, candle_type):\n            candle_ts = dt_ts(timeframe_to_prev_date(timeframe))\n            prev_candle_ts = dt_ts(date_minus_candles(timeframe, 1))\n            candles = self._exchange_ws.ohlcvs(pair, timeframe)\n            half_candle = int(candle_ts - (candle_ts - prev_candle_ts) * 0.5)\n            last_refresh_time = int(\n                self._exchange_ws.klines_last_refresh.get((pair, timeframe, candle_type), 0)\n            )\n\n            if (\n                candles\n                and (\n                    (len(candles) > 1 and candles[-1][0] >= prev_candle_ts)\n                    # Edgecase on reconnect, where 1 candle is available but it's the current one\n                    or (len(candles) == 1 and candles[-1][0] < candle_ts)\n                )\n                and last_refresh_time >= half_candle\n            ):\n                # Usable result, candle contains the previous candle.\n                # Also, we check if the last refresh time is no more than half the candle ago.\n                logger.debug(f\"reuse watch result for {pair}, {timeframe}, {last_refresh_time}\")\n\n                return self._exchange_ws.get_ohlcv(pair, timeframe, candle_type, candle_ts)\n            logger.info(\n                f\"Couldn't reuse watch for {pair}, {timeframe}, falling back to REST api. \"\n                f\"{candle_ts < last_refresh_time}, {candle_ts}, {last_refresh_time}, \"\n                f\"{format_ms_time(candle_ts)}, {format_ms_time(last_refresh_time)} \"\n            )\n        return None\n\n    def _can_use_websocket(\n        self, exchange_ws: ExchangeWS | None, pair: str, timeframe: str, candle_type: CandleType\n    ) -> TypeGuard[ExchangeWS]:\n        \"\"\"\n        Check if we can use websocket for this pair.\n        Acts as typeguard for exchangeWs\n        \"\"\"\n        if exchange_ws and candle_type in (CandleType.SPOT, CandleType.FUTURES):\n            return True\n        return False\n\n    def _build_coroutine(\n        self,\n        pair: str,\n        timeframe: str,\n        candle_type: CandleType,\n        since_ms: int | None,\n        cache: bool,\n    ) -> Coroutine[Any, Any, OHLCVResponse]:\n        not_all_data = cache and self.required_candle_call_count > 1\n        if cache:\n            if self._can_use_websocket(self._exchange_ws, pair, timeframe, candle_type):\n                # Subscribe to websocket\n                self._exchange_ws.schedule_ohlcv(pair, timeframe, candle_type)\n\n        if cache and (pair, timeframe, candle_type) in self._klines:\n            candle_limit = self.ohlcv_candle_limit(timeframe, candle_type)\n            min_ts = dt_ts(date_minus_candles(timeframe, candle_limit - 5))\n\n            if ws_resp := self._try_build_from_websocket(pair, timeframe, candle_type):\n                # We have a usable websocket response\n                return ws_resp\n\n            # Check if 1 call can get us updated candles without hole in the data.\n            if min_ts < self._pairs_last_refresh_time.get((pair, timeframe, candle_type), 0):\n                # Cache can be used - do one-off call.\n                not_all_data = False\n            else:\n                # Time jump detected, evict cache\n                logger.info(\n                    f\"Time jump detected. Evicting cache for {pair}, {timeframe}, {candle_type}\"\n                )\n                del self._klines[(pair, timeframe, candle_type)]\n\n        if not since_ms and (self._ft_has[\"ohlcv_require_since\"] or not_all_data):\n            # Multiple calls for one pair - to get more history\n            one_call = timeframe_to_msecs(timeframe) * self.ohlcv_candle_limit(\n                timeframe, candle_type, since_ms\n            )\n            move_to = one_call * self.required_candle_call_count\n            now = timeframe_to_next_date(timeframe)\n            since_ms = dt_ts(now - timedelta(seconds=move_to // 1000))\n\n        if since_ms:\n            return self._async_get_historic_ohlcv(\n                pair, timeframe, since_ms=since_ms, raise_=True, candle_type=candle_type\n            )\n        else:\n            # One call ... \"regular\" refresh\n            return self._async_get_candle_history(\n                pair, timeframe, since_ms=since_ms, candle_type=candle_type\n            )\n\n    def _build_ohlcv_dl_jobs(\n        self, pair_list: ListPairsWithTimeframes, since_ms: int | None, cache: bool\n    ) -> tuple[list[Coroutine], list[PairWithTimeframe]]:\n        \"\"\"\n        Build Coroutines to execute as part of refresh_latest_ohlcv\n        \"\"\"\n        input_coroutines: list[Coroutine[Any, Any, OHLCVResponse]] = []\n        cached_pairs = []\n        for pair, timeframe, candle_type in set(pair_list):\n            if candle_type == CandleType.FUNDING_RATE and timeframe != (\n                ff_tf := self.get_option(\"funding_fee_timeframe\")\n            ):\n                # TODO: does this message make sense? would docs be better?\n                # if any, this should be cached to avoid log spam!\n                logger.warning(\n                    f\"Wrong funding rate timeframe {timeframe} for pair {pair}, \"\n                    f\"downloading {ff_tf} instead.\"\n                )\n                timeframe = ff_tf\n            invalid_timeframe = timeframe not in self.timeframes and candle_type in (\n                CandleType.SPOT,\n                CandleType.FUTURES,\n            )\n            if invalid_timeframe:\n                logger.warning(\n                    f\"Cannot download ({pair}, {timeframe}, {candle_type}) combination as this \"\n                    f\"timeframe is not available on {self.name}. Available timeframes are \"\n                    f\"{', '.join(self.timeframes)}.\"\n                )\n                continue\n\n            if (\n                (pair, timeframe, candle_type) not in self._klines\n                or not cache\n                or self._now_is_time_to_refresh(pair, timeframe, candle_type)\n            ):\n                input_coroutines.append(\n                    self._build_coroutine(pair, timeframe, candle_type, since_ms, cache)\n                )\n\n            else:\n                logger.debug(\n                    f\"Using cached candle (OHLCV) data for {pair}, {timeframe}, {candle_type} ...\"\n                )\n                cached_pairs.append((pair, timeframe, candle_type))\n\n        return input_coroutines, cached_pairs\n\n    def _process_ohlcv_df(\n        self,\n        pair: str,\n        timeframe: str,\n        c_type: CandleType,\n        ticks: list[list],\n        cache: bool,\n        drop_incomplete: bool,\n    ) -> DataFrame:\n        # keeping last candle time as last refreshed time of the pair\n        if ticks and cache:\n            idx = -2 if drop_incomplete and len(ticks) > 1 else -1\n            self._pairs_last_refresh_time[(pair, timeframe, c_type)] = ticks[idx][0]\n        has_cache = cache and (pair, timeframe, c_type) in self._klines\n        # in case of existing cache, fill_missing happens after concatenation\n        ohlcv_df = ohlcv_to_dataframe(\n            ticks,\n            timeframe,\n            pair=pair,\n            fill_missing=not has_cache and c_type != CandleType.FUNDING_RATE,\n            drop_incomplete=drop_incomplete,\n        )\n        # keeping parsed dataframe in cache\n        if cache:\n            if (pair, timeframe, c_type) in self._klines:\n                old = self._klines[(pair, timeframe, c_type)]\n                # Reassign so we return the updated, combined df\n                ohlcv_df = clean_ohlcv_dataframe(\n                    concat([old, ohlcv_df], axis=0),\n                    timeframe,\n                    pair,\n                    fill_missing=c_type != CandleType.FUNDING_RATE,\n                    drop_incomplete=False,\n                )\n                candle_limit = self.ohlcv_candle_limit(timeframe, self._config[\"candle_type_def\"])\n                # Age out old candles\n                ohlcv_df = ohlcv_df.tail(candle_limit + self._startup_candle_count)\n                ohlcv_df = ohlcv_df.reset_index(drop=True)\n                self._klines[(pair, timeframe, c_type)] = ohlcv_df\n            else:\n                self._klines[(pair, timeframe, c_type)] = ohlcv_df\n        return ohlcv_df\n\n    def refresh_latest_ohlcv(\n        self,\n        pair_list: ListPairsWithTimeframes,\n        *,\n        since_ms: int | None = None,\n        cache: bool = True,\n        drop_incomplete: bool | None = None,\n    ) -> dict[PairWithTimeframe, DataFrame]:\n        \"\"\"\n        Refresh in-memory OHLCV asynchronously and set `_klines` with the result\n        Loops asynchronously over pair_list and downloads all pairs async (semi-parallel).\n        Only used in the dataprovider.refresh() method.\n        :param pair_list: List of 2 element tuples containing pair, interval to refresh\n        :param since_ms: time since when to download, in milliseconds\n        :param cache: Assign result to _klines. Useful for one-off downloads like for pairlists\n        :param drop_incomplete: Control candle dropping.\n            Specifying None defaults to _ohlcv_partial_candle\n        :return: Dict of [{(pair, timeframe): Dataframe}]\n        \"\"\"\n        logger.debug(\"Refreshing candle (OHLCV) data for %d pairs\", len(pair_list))\n\n        # Gather coroutines to run\n        ohlcv_dl_jobs, cached_pairs = self._build_ohlcv_dl_jobs(pair_list, since_ms, cache)\n\n        results_df = {}\n        # Chunk requests into batches of 100 to avoid overwhelming ccxt Throttling\n        for dl_jobs_batch in chunks(ohlcv_dl_jobs, 100):\n\n            async def gather_coroutines(coro):\n                return await asyncio.gather(*coro, return_exceptions=True)\n\n            with self._loop_lock:\n                results = self.loop.run_until_complete(gather_coroutines(dl_jobs_batch))\n\n            for res in results:\n                if isinstance(res, Exception):\n                    logger.warning(f\"Async code raised an exception: {repr(res)}\")\n                    continue\n                # Deconstruct tuple (has 5 elements)\n                pair, timeframe, c_type, ticks, drop_hint = res\n                drop_incomplete_ = drop_hint if drop_incomplete is None else drop_incomplete\n                ohlcv_df = self._process_ohlcv_df(\n                    pair, timeframe, c_type, ticks, cache, drop_incomplete_\n                )\n\n                results_df[(pair, timeframe, c_type)] = ohlcv_df\n\n        # Return cached klines\n        for pair, timeframe, c_type in cached_pairs:\n            results_df[(pair, timeframe, c_type)] = self.klines(\n                (pair, timeframe, c_type), copy=False\n            )\n\n        return results_df\n\n    def refresh_ohlcv_with_cache(\n        self, pairs: list[PairWithTimeframe], since_ms: int\n    ) -> dict[PairWithTimeframe, DataFrame]:\n        \"\"\"\n        Refresh ohlcv data for all pairs in needed_pairs if necessary.\n        Caches data with expiring per timeframe.\n        Should only be used for pairlists which need \"on time\" expirarion, and no longer cache.\n        \"\"\"\n\n        timeframes = {p[1] for p in pairs}\n        for timeframe in timeframes:\n            if (timeframe, since_ms) not in self._expiring_candle_cache:\n                timeframe_in_sec = timeframe_to_seconds(timeframe)\n                # Initialise cache\n                self._expiring_candle_cache[(timeframe, since_ms)] = PeriodicCache(\n                    ttl=timeframe_in_sec, maxsize=1000\n                )\n\n        # Get candles from cache\n        candles = {\n            c: self._expiring_candle_cache[(c[1], since_ms)].get(c, None)\n            for c in pairs\n            if c in self._expiring_candle_cache[(c[1], since_ms)]\n        }\n        pairs_to_download = [p for p in pairs if p not in candles]\n        if pairs_to_download:\n            candles = self.refresh_latest_ohlcv(pairs_to_download, since_ms=since_ms, cache=False)\n            for c, val in candles.items():\n                self._expiring_candle_cache[(c[1], since_ms)][c] = val\n        return candles\n\n    def _now_is_time_to_refresh(self, pair: str, timeframe: str, candle_type: CandleType) -> bool:\n        # Timeframe in seconds\n        interval_in_sec = timeframe_to_msecs(timeframe)\n        plr = self._pairs_last_refresh_time.get((pair, timeframe, candle_type), 0) + interval_in_sec\n        # current,active candle open date\n        now = dt_ts(timeframe_to_prev_date(timeframe))\n        return plr < now\n\n    @retrier_async\n    async def _async_get_candle_history(\n        self,\n        pair: str,\n        timeframe: str,\n        candle_type: CandleType,\n        since_ms: int | None = None,\n    ) -> OHLCVResponse:\n        \"\"\"\n        Asynchronously get candle history data using fetch_ohlcv\n        :param candle_type: '', mark, index, premiumIndex, or funding_rate\n        returns tuple: (pair, timeframe, ohlcv_list)\n        \"\"\"\n        try:\n            # Fetch OHLCV asynchronously\n            s = \"(\" + dt_from_ts(since_ms).isoformat() + \") \" if since_ms is not None else \"\"\n            logger.debug(\n                \"Fetching pair %s, %s, interval %s, since %s %s...\",\n                pair,\n                candle_type,\n                timeframe,\n                since_ms,\n                s,\n            )\n            params = deepcopy(self._ft_has.get(\"ohlcv_params\", {}))\n            candle_limit = self.ohlcv_candle_limit(\n                timeframe, candle_type=candle_type, since_ms=since_ms\n            )\n\n            if candle_type != CandleType.FUNDING_RATE:\n                if candle_type and candle_type not in (CandleType.SPOT, CandleType.FUTURES):\n                    self.verify_candle_type_support(candle_type)\n                    params.update({\"price\": str(candle_type)})\n                data = await self._api_async.fetch_ohlcv(\n                    pair, timeframe=timeframe, since=since_ms, limit=candle_limit, params=params\n                )\n            else:\n                # Funding rate\n                data = await self._fetch_funding_rate_history(\n                    pair=pair,\n                    timeframe=timeframe,\n                    limit=candle_limit,\n                    since_ms=since_ms,\n                )\n            # Some exchanges sort OHLCV in ASC order and others in DESC.\n            # Only sort if necessary to save computing time\n            try:\n                if data and data[0][0] > data[-1][0]:\n                    data = sorted(data, key=lambda x: x[0])\n            except IndexError:\n                logger.exception(\"Error loading %s. Result was %s.\", pair, data)\n                return pair, timeframe, candle_type, [], self._ohlcv_partial_candle\n            logger.debug(\"Done fetching pair %s, %s interval %s...\", pair, candle_type, timeframe)\n            return (\n                pair,\n                timeframe,\n                candle_type,\n                data,\n                # funding_rates are always complete, so never need to be dropped.\n                self._ohlcv_partial_candle if candle_type != CandleType.FUNDING_RATE else False,\n            )\n\n        except ccxt.NotSupported as e:\n            raise OperationalException(\n                f\"Exchange {self._api.name} does not support fetching historical \"\n                f\"candle (OHLCV) data. Message: {e}\"\n            ) from e\n        except ccxt.DDoSProtection as e:\n            raise DDosProtection(e) from e\n        except (ccxt.OperationFailed, ccxt.ExchangeError) as e:\n            raise TemporaryError(\n                f\"Could not fetch historical candle (OHLCV) data \"\n                f\"for {pair}, {timeframe}, {candle_type} due to {e.__class__.__name__}. \"\n                f\"Message: {e}\"\n            ) from e\n        except ccxt.BaseError as e:\n            raise OperationalException(\n                f\"Could not fetch historical candle (OHLCV) data for \"\n                f\"{pair}, {timeframe}, {candle_type}. Message: {e}\"\n            ) from e\n\n    async def _fetch_funding_rate_history(\n        self,\n        pair: str,\n        timeframe: str,\n        limit: int,\n        since_ms: int | None = None,\n    ) -> list[list]:\n        \"\"\"\n        Fetch funding rate history - used to selectively override this by subclasses.\n        \"\"\"\n        # Funding rate\n        data = await self._api_async.fetch_funding_rate_history(pair, since=since_ms, limit=limit)\n        # Convert funding rate to candle pattern\n        data = [[x[\"timestamp\"], x[\"fundingRate\"], 0, 0, 0, 0] for x in data]\n        return data\n\n    def check_candle_type_support(self, candle_type: CandleType) -> bool:\n        \"\"\"\n        Check that the exchange supports the given candle type.\n        :param candle_type: CandleType to verify\n        :return: True if supported, False otherwise\n        \"\"\"\n        if candle_type == CandleType.FUNDING_RATE:\n            if not self.exchange_has(\"fetchFundingRateHistory\"):\n                return False\n        elif candle_type not in (CandleType.SPOT, CandleType.FUTURES):\n            mapping = {\n                CandleType.MARK: \"fetchMarkOHLCV\",\n                CandleType.INDEX: \"fetchIndexOHLCV\",\n                CandleType.PREMIUMINDEX: \"fetchPremiumIndexOHLCV\",\n                CandleType.FUNDING_RATE: \"fetchFundingRateHistory\",\n            }\n            _method = mapping.get(candle_type, \"fetchOHLCV\")\n            if not self.exchange_has(_method):\n                return False\n        return True\n\n    def verify_candle_type_support(self, candle_type: CandleType) -> None:\n        \"\"\"\n        Verify that the exchange supports the given candle type.\n        :param candle_type: CandleType to verify\n        :raises OperationalException: if the candle type is not supported\n        \"\"\"\n        if not self.check_candle_type_support(candle_type):\n            raise OperationalException(\n                f\"Exchange {self._api.name} does not support fetching {candle_type} candles.\"\n            )\n\n    # fetch Trade data stuff\n\n    def needed_candle_for_trades_ms(self, timeframe: str, candle_type: CandleType) -> int:\n        candle_limit = self.ohlcv_candle_limit(timeframe, candle_type)\n        tf_s = timeframe_to_seconds(timeframe)\n        candles_fetched = candle_limit * self.required_candle_call_count\n\n        max_candles = self._config[\"orderflow\"][\"max_candles\"]\n\n        required_candles = min(max_candles, candles_fetched)\n        move_to = (\n            tf_s * candle_limit * required_candles\n            if required_candles > candle_limit\n            else (max_candles + 1) * tf_s\n        )\n\n        now = timeframe_to_next_date(timeframe)\n        return int((now - timedelta(seconds=move_to)).timestamp() * 1000)\n\n    def _process_trades_df(\n        self,\n        pair: str,\n        timeframe: str,\n        c_type: CandleType,\n        ticks: list[list],\n        cache: bool,\n        first_required_candle_date: int,\n    ) -> DataFrame:\n        # keeping parsed dataframe in cache\n        trades_df = trades_list_to_df(ticks, True)\n\n        if cache:\n            if (pair, timeframe, c_type) in self._trades:\n                old = self._trades[(pair, timeframe, c_type)]\n                # Reassign so we return the updated, combined df\n                combined_df = concat([old, trades_df], axis=0)\n                logger.debug(f\"Clean duplicated ticks from Trades data {pair}\")\n                trades_df = DataFrame(\n                    trades_df_remove_duplicates(combined_df), columns=combined_df.columns\n                )\n                # Age out old candles\n                trades_df = trades_df[first_required_candle_date < trades_df[\"timestamp\"]]\n                trades_df = trades_df.reset_index(drop=True)\n            self._trades[(pair, timeframe, c_type)] = trades_df\n        return trades_df\n\n    async def _build_trades_dl_jobs(\n        self, pairwt: PairWithTimeframe, data_handler, cache: bool\n    ) -> tuple[PairWithTimeframe, DataFrame | None]:\n        \"\"\"\n        Build coroutines to refresh trades for (they're then called through async.gather)\n        \"\"\"\n        pair, timeframe, candle_type = pairwt\n        since_ms = None\n        new_ticks: list = []\n        all_stored_ticks_df = DataFrame(columns=[*DEFAULT_TRADES_COLUMNS, \"date\"])\n        first_candle_ms = self.needed_candle_for_trades_ms(timeframe, candle_type)\n        # refresh, if\n        # a. not in _trades\n        # b. no cache used\n        # c. need new data\n        is_in_cache = (pair, timeframe, candle_type) in self._trades\n        if (\n            not is_in_cache\n            or not cache\n            or self._now_is_time_to_refresh_trades(pair, timeframe, candle_type)\n        ):\n            logger.debug(f\"Refreshing TRADES data for {pair}\")\n            # fetch trades since latest _trades and\n            # store together with existing trades\n            try:\n                until = None\n                from_id = None\n                if is_in_cache:\n                    from_id = self._trades[(pair, timeframe, candle_type)].iloc[-1][\"id\"]\n                    until = dt_ts()  # now\n\n                else:\n                    until = int(timeframe_to_prev_date(timeframe).timestamp()) * 1000\n                    all_stored_ticks_df = data_handler.trades_load(\n                        f\"{pair}-cached\", self.trading_mode\n                    )\n\n                    if not all_stored_ticks_df.empty:\n                        if (\n                            all_stored_ticks_df.iloc[-1][\"timestamp\"] > first_candle_ms\n                            and all_stored_ticks_df.iloc[0][\"timestamp\"] <= first_candle_ms\n                        ):\n                            # Use cache and populate further\n                            last_cached_ms = all_stored_ticks_df.iloc[-1][\"timestamp\"]\n                            from_id = all_stored_ticks_df.iloc[-1][\"id\"]\n                            # only use cached if it's closer than first_candle_ms\n                            since_ms = (\n                                last_cached_ms\n                                if last_cached_ms > first_candle_ms\n                                else first_candle_ms\n                            )\n                        else:\n                            # Skip cache, it's too old\n                            all_stored_ticks_df = DataFrame(\n                                columns=[*DEFAULT_TRADES_COLUMNS, \"date\"]\n                            )\n\n                # from_id overrules with exchange set to id paginate\n                [_, new_ticks] = await self._async_get_trade_history(\n                    pair,\n                    since=since_ms if since_ms else first_candle_ms,\n                    until=until,\n                    from_id=from_id,\n                )\n\n            except Exception:\n                logger.exception(f\"Refreshing TRADES data for {pair} failed\")\n                return pairwt, None\n\n            if new_ticks:\n                all_stored_ticks_list = all_stored_ticks_df[DEFAULT_TRADES_COLUMNS].values.tolist()\n                all_stored_ticks_list.extend(new_ticks)\n                trades_df = self._process_trades_df(\n                    pair,\n                    timeframe,\n                    candle_type,\n                    all_stored_ticks_list,\n                    cache,\n                    first_required_candle_date=first_candle_ms,\n                )\n                data_handler.trades_store(\n                    f\"{pair}-cached\", trades_df[DEFAULT_TRADES_COLUMNS], self.trading_mode\n                )\n                return pairwt, trades_df\n            else:\n                logger.error(f\"No new ticks for {pair}\")\n        return pairwt, None\n\n    def refresh_latest_trades(\n        self,\n        pair_list: ListPairsWithTimeframes,\n        *,\n        cache: bool = True,\n    ) -> dict[PairWithTimeframe, DataFrame]:\n        \"\"\"\n        Refresh in-memory TRADES asynchronously and set `_trades` with the result\n        Loops asynchronously over pair_list and downloads all pairs async (semi-parallel).\n        Only used in the dataprovider.refresh() method.\n        :param pair_list: List of 3 element tuples containing (pair, timeframe, candle_type)\n        :param cache: Assign result to _trades. Useful for one-off downloads like for pairlists\n        :return: Dict of [{(pair, timeframe): Dataframe}]\n        \"\"\"\n        from freqtrade.data.history import get_datahandler\n\n        data_handler = get_datahandler(\n            self._config[\"datadir\"], data_format=self._config[\"dataformat_trades\"]\n        )\n        logger.debug(\"Refreshing TRADES data for %d pairs\", len(pair_list))\n        results_df = {}\n        trades_dl_jobs = []\n        for pair_wt in set(pair_list):\n            trades_dl_jobs.append(self._build_trades_dl_jobs(pair_wt, data_handler, cache))\n\n        async def gather_coroutines(coro):\n            return await asyncio.gather(*coro, return_exceptions=True)\n\n        for dl_job_chunk in chunks(trades_dl_jobs, 100):\n            with self._loop_lock:\n                results = self.loop.run_until_complete(gather_coroutines(dl_job_chunk))\n\n            for res in results:\n                if isinstance(res, Exception):\n                    logger.warning(f\"Async code raised an exception: {repr(res)}\")\n                    continue\n                pairwt, trades_df = res\n                if trades_df is not None:\n                    results_df[pairwt] = trades_df\n\n        return results_df\n\n    def _now_is_time_to_refresh_trades(\n        self, pair: str, timeframe: str, candle_type: CandleType\n    ) -> bool:  # Timeframe in seconds\n        trades = self.trades((pair, timeframe, candle_type), False)\n        pair_last_refreshed = int(trades.iloc[-1][\"timestamp\"])\n        full_candle = (\n            int(timeframe_to_next_date(timeframe, dt_from_ts(pair_last_refreshed)).timestamp())\n            * 1000\n        )\n        now = dt_ts()\n        return full_candle <= now\n\n    # Fetch historic trades\n\n    @retrier_async\n    async def _async_fetch_trades(\n        self, pair: str, since: int | None = None, params: dict | None = None\n    ) -> tuple[list[list], Any]:\n        \"\"\"\n        Asynchronously gets trade history using fetch_trades.\n        Handles exchange errors, does one call to the exchange.\n        :param pair: Pair to fetch trade data for\n        :param since: Since as integer timestamp in milliseconds\n        returns: List of dicts containing trades, the next iteration value (new \"since\" or trade_id)\n        \"\"\"\n        try:\n            trades_limit = self._ft_has[\"trades_limit\"]\n            # fetch trades asynchronously\n            if params:\n                logger.debug(\"Fetching trades for pair %s, params: %s \", pair, params)\n                trades = await self._api_async.fetch_trades(pair, params=params, limit=trades_limit)\n            else:\n                logger.debug(\n                    \"Fetching trades for pair %s, since %s %s...\",\n                    pair,\n                    since,\n                    \"(\" + dt_from_ts(since).isoformat() + \") \" if since is not None else \"\",\n                )\n                trades = await self._api_async.fetch_trades(pair, since=since, limit=trades_limit)\n            trades = self._trades_contracts_to_amount(trades)\n            pagination_value = self._get_trade_pagination_next_value(trades)\n            return trades_dict_to_list(trades), pagination_value\n        except ccxt.NotSupported as e:\n            raise OperationalException(\n                f\"Exchange {self._api.name} does not support fetching historical trade data.\"\n                f\"Message: {e}\"\n            ) from e\n        except ccxt.DDoSProtection as e:\n            raise DDosProtection(e) from e\n        except (ccxt.OperationFailed, ccxt.ExchangeError) as e:\n            raise TemporaryError(\n                f\"Could not load trade history due to {e.__class__.__name__}. Message: {e}\"\n            ) from e\n        except ccxt.BaseError as e:\n            raise OperationalException(f\"Could not fetch trade data. Msg: {e}\") from e\n\n    def _valid_trade_pagination_id(self, pair: str, from_id: str) -> bool:\n        \"\"\"\n        Verify trade-pagination id is valid.\n        Workaround for odd Kraken issue where ID is sometimes wrong.\n        \"\"\"\n        return True\n\n    def _get_trade_pagination_next_value(self, trades: list[dict]):\n        \"\"\"\n        Extract pagination id for the next \"from_id\" value\n        Applies only to fetch_trade_history by id.\n        \"\"\"\n        if not trades:\n            return None\n        if self._ft_has[\"trades_pagination\"] == \"id\":\n            return trades[-1].get(\"id\")\n        else:\n            return trades[-1].get(\"timestamp\")\n\n    async def _async_get_trade_history_id_startup(\n        self, pair: str, since: int\n    ) -> tuple[list[list], str]:\n        \"\"\"\n        override for initial trade_history_id call\n        \"\"\"\n        return await self._async_fetch_trades(pair, since=since)\n\n    async def _async_get_trade_history_id(\n        self, pair: str, *, until: int, since: int, from_id: str | None = None\n    ) -> tuple[str, list[list]]:\n        \"\"\"\n        Asynchronously gets trade history using fetch_trades\n        use this when exchange uses id-based iteration (check `self._ft_has[\"trades_pagination\"]`)\n        :param pair: Pair to fetch trade data for\n        :param since: Since as integer timestamp in milliseconds\n        :param until: Until as integer timestamp in milliseconds\n        :param from_id: Download data starting with ID (if id is known). Ignores \"since\" if set.\n        returns tuple: (pair, trades-list)\n        \"\"\"\n\n        trades: list[list] = []\n        # DEFAULT_TRADES_COLUMNS: 0 -> timestamp\n        # DEFAULT_TRADES_COLUMNS: 1 -> id\n        has_overlap = self._ft_has.get(\"trades_pagination_overlap\", True)\n        # Skip last trade by default since its the key for the next call\n        x = slice(None, -1) if has_overlap else slice(None)\n\n        if not from_id or not self._valid_trade_pagination_id(pair, from_id):\n            # Fetch first elements using timebased method to get an ID to paginate on\n            # Depending on the Exchange, this can introduce a drift at the start of the interval\n            # of up to an hour.\n            # e.g. Binance returns the \"last 1000\" candles within a 1h time interval\n            # - so we will miss the first trades.\n            t, from_id = await self._async_get_trade_history_id_startup(pair, since=since)\n            trades.extend(t[x])\n        while True:\n            try:\n                t, from_id_next = await self._async_fetch_trades(\n                    pair, params={self._ft_has[\"trades_pagination_arg\"]: from_id}\n                )\n                if t:\n                    trades.extend(t[x])\n                    if from_id == from_id_next or t[-1][0] > until:\n                        logger.debug(\n                            f\"Stopping because from_id did not change. Reached {t[-1][0]} > {until}\"\n                        )\n                        # Reached the end of the defined-download period - add last trade as well.\n                        if has_overlap:\n                            trades.extend(t[-1:])\n                        break\n\n                    from_id = from_id_next\n                else:\n                    logger.debug(\"Stopping as no more trades were returned.\")\n                    break\n            except asyncio.CancelledError:\n                logger.debug(\"Async operation Interrupted, breaking trades DL loop.\")\n                break\n\n        return (pair, trades)\n\n    async def _async_get_trade_history_time(\n        self, pair: str, until: int, since: int\n    ) -> tuple[str, list[list]]:\n        \"\"\"\n        Asynchronously gets trade history using fetch_trades,\n        when the exchange uses time-based iteration (check `self._ft_has[\"trades_pagination\"]`)\n        :param pair: Pair to fetch trade data for\n        :param since: Since as integer timestamp in milliseconds\n        :param until: Until as integer timestamp in milliseconds\n        returns tuple: (pair, trades-list)\n        \"\"\"\n\n        trades: list[list] = []\n        # DEFAULT_TRADES_COLUMNS: 0 -> timestamp\n        # DEFAULT_TRADES_COLUMNS: 1 -> id\n        while True:\n            try:\n                t, since_next = await self._async_fetch_trades(pair, since=since)\n                if t:\n                    # No more trades to download available at the exchange,\n                    # So we repeatedly get the same trade over and over again.\n                    if since == since_next and len(t) == 1:\n                        logger.debug(\"Stopping because no more trades are available.\")\n                        break\n                    since = since_next\n                    trades.extend(t)\n                    # Reached the end of the defined-download period\n                    if until and since_next > until:\n                        logger.debug(f\"Stopping because until was reached. {since_next} > {until}\")\n                        break\n                else:\n                    logger.debug(\"Stopping as no more trades were returned.\")\n                    break\n            except asyncio.CancelledError:\n                logger.debug(\"Async operation Interrupted, breaking trades DL loop.\")\n                break\n\n        return (pair, trades)\n\n    async def _async_get_trade_history(\n        self,\n        pair: str,\n        since: int,\n        until: int | None = None,\n        from_id: str | None = None,\n    ) -> tuple[str, list[list]]:\n        \"\"\"\n        Async wrapper handling downloading trades using either time or id based methods.\n        \"\"\"\n\n        logger.debug(\n            f\"_async_get_trade_history(), pair: {pair}, \"\n            f\"since: {since}, until: {until}, from_id: {from_id}\"\n        )\n\n        if until is None:\n            until = ccxt.Exchange.milliseconds()\n            logger.debug(f\"Exchange milliseconds: {until}\")\n\n        if self._ft_has[\"trades_pagination\"] == \"time\":\n            return await self._async_get_trade_history_time(pair=pair, since=since, until=until)\n        elif self._ft_has[\"trades_pagination\"] == \"id\":\n            return await self._async_get_trade_history_id(\n                pair=pair, since=since, until=until, from_id=from_id\n            )\n        else:\n            raise OperationalException(\n                f\"Exchange {self.name} does use neither time, nor id based pagination\"\n            )\n\n    def get_historic_trades(\n        self,\n        pair: str,\n        since: int,\n        until: int | None = None,\n        from_id: str | None = None,\n    ) -> tuple[str, list]:\n        \"\"\"\n        Get trade history data using asyncio.\n        Handles all async work and returns the list of candles.\n        Async over one pair, assuming we get `self.ohlcv_candle_limit()` candles per call.\n        :param pair: Pair to download\n        :param since: Timestamp in milliseconds to get history from\n        :param until: Timestamp in milliseconds. Defaults to current timestamp if not defined.\n        :param from_id: Download data starting with ID (if id is known)\n        :returns List of trade data\n        \"\"\"\n        if not self.exchange_has(\"fetchTrades\"):\n            raise OperationalException(\"This exchange does not support downloading Trades.\")\n\n        with self._loop_lock:\n            task = asyncio.ensure_future(\n                self._async_get_trade_history(pair=pair, since=since, until=until, from_id=from_id)\n            )\n\n            for sig in [signal.SIGINT, signal.SIGTERM]:\n                try:\n                    self.loop.add_signal_handler(sig, task.cancel)\n                except (NotImplementedError, RuntimeError):\n                    # Not all platforms implement signals (e.g. windows)\n                    pass\n            return self.loop.run_until_complete(task)\n\n    @retrier\n    def _get_funding_fees_from_exchange(self, pair: str, since: datetime | int) -> float:\n        \"\"\"\n        Returns the sum of all funding fees that were exchanged for a pair within a timeframe\n        Dry-run handling happens as part of _calculate_funding_fees.\n        :param pair: (e.g. ADA/USDT)\n        :param since: The earliest time of consideration for calculating funding fees,\n            in unix time or as a datetime\n        \"\"\"\n        if not self.exchange_has(\"fetchFundingHistory\"):\n            raise OperationalException(\n                f\"fetch_funding_history() is not available using {self.name}\"\n            )\n\n        if type(since) is datetime:\n            since = dt_ts(since)\n\n        try:\n            funding_history = self._api.fetch_funding_history(symbol=pair, since=since)\n            self._log_exchange_response(\n                \"funding_history\", funding_history, add_info=f\"pair: {pair}, since: {since}\"\n            )\n            return sum(fee[\"amount\"] for fee in funding_history)\n        except ccxt.DDoSProtection as e:\n            raise DDosProtection(e) from e\n        except (ccxt.OperationFailed, ccxt.ExchangeError) as e:\n            raise TemporaryError(\n                f\"Could not get funding fees due to {e.__class__.__name__}. Message: {e}\"\n            ) from e\n        except ccxt.BaseError as e:\n            raise OperationalException(e) from e\n\n    @retrier\n    def get_leverage_tiers(self) -> dict[str, list[dict]]:\n        try:\n            return self._api.fetch_leverage_tiers()\n        except ccxt.DDoSProtection as e:\n            raise DDosProtection(e) from e\n        except (ccxt.OperationFailed, ccxt.ExchangeError) as e:\n            raise TemporaryError(\n                f\"Could not load leverage tiers due to {e.__class__.__name__}. Message: {e}\"\n            ) from e\n        except ccxt.BaseError as e:\n            raise OperationalException(e) from e\n\n    @retrier_async\n    async def get_market_leverage_tiers(self, symbol: str) -> tuple[str, list[dict]]:\n        \"\"\"Leverage tiers per symbol\"\"\"\n        try:\n            tier = await self._api_async.fetch_market_leverage_tiers(symbol)\n            return symbol, tier\n        except ccxt.DDoSProtection as e:\n            raise DDosProtection(e) from e\n        except (ccxt.OperationFailed, ccxt.ExchangeError) as e:\n            raise TemporaryError(\n                f\"Could not load leverage tiers for {symbol}\"\n                f\" due to {e.__class__.__name__}. Message: {e}\"\n            ) from e\n        except ccxt.BaseError as e:\n            raise OperationalException(e) from e\n\n    def load_leverage_tiers(self) -> dict[str, list[dict]]:\n        if self.trading_mode == TradingMode.FUTURES:\n            if self.exchange_has(\"fetchLeverageTiers\"):\n                # Fetch all leverage tiers at once\n                return self.get_leverage_tiers()\n            elif self.exchange_has(\"fetchMarketLeverageTiers\"):\n                # Must fetch the leverage tiers for each market separately\n                # * This is slow(~45s) on Okx, makes ~90 api calls to load all linear swap markets\n                markets = self.markets\n\n                symbols = [\n                    symbol\n                    for symbol, market in markets.items()\n                    if (\n                        self.market_is_future(market)\n                        and market[\"quote\"] == self._config[\"stake_currency\"]\n                    )\n                ]\n\n                tiers: dict[str, list[dict]] = {}\n\n                tiers_cached = self.load_cached_leverage_tiers(self._config[\"stake_currency\"])\n                if tiers_cached:\n                    tiers = tiers_cached\n\n                coros = [\n                    self.get_market_leverage_tiers(symbol)\n                    for symbol in sorted(symbols)\n                    if symbol not in tiers\n                ]\n\n                # Be verbose here, as this delays startup by ~1 minute.\n                if coros:\n                    logger.info(\n                        f\"Initializing leverage_tiers for {len(symbols)} markets. \"\n                        \"This will take about a minute.\"\n                    )\n                else:\n                    logger.info(\"Using cached leverage_tiers.\")\n\n                async def gather_results(input_coro):\n                    return await asyncio.gather(*input_coro, return_exceptions=True)\n\n                for input_coro in chunks(coros, 100):\n                    with self._loop_lock:\n                        results = self.loop.run_until_complete(gather_results(input_coro))\n\n                    for res in results:\n                        if isinstance(res, Exception):\n                            logger.warning(f\"Leverage tier exception: {repr(res)}\")\n                            continue\n                        symbol, tier = res\n                        tiers[symbol] = tier\n                if len(coros) > 0:\n                    self.cache_leverage_tiers(tiers, self._config[\"stake_currency\"])\n                logger.info(f\"Done initializing {len(symbols)} markets.\")\n\n                return tiers\n        return {}\n\n    def cache_leverage_tiers(self, tiers: dict[str, list[dict]], stake_currency: str) -> None:\n        filename = self._config[\"datadir\"] / \"futures\" / f\"leverage_tiers_{stake_currency}.json\"\n        if not filename.parent.is_dir():\n            filename.parent.mkdir(parents=True)\n        data = {\n            \"updated\": datetime.now(UTC),\n            \"data\": tiers,\n        }\n        file_dump_json(filename, data)\n\n    def load_cached_leverage_tiers(\n        self, stake_currency: str, cache_time: timedelta | None = None\n    ) -> dict[str, list[dict]] | None:\n        \"\"\"\n        Load cached leverage tiers from disk\n        :param cache_time: The maximum age of the cache before it is considered outdated\n        \"\"\"\n        if not cache_time:\n            # Default to 4 weeks\n            cache_time = timedelta(weeks=4)\n        filename = self._config[\"datadir\"] / \"futures\" / f\"leverage_tiers_{stake_currency}.json\"\n        if filename.is_file():\n            try:\n                tiers = file_load_json(filename)\n                updated = tiers.get(\"updated\")\n                if updated:\n                    updated_dt = parser.parse(updated)\n                    if updated_dt < datetime.now(UTC) - cache_time:\n                        logger.info(\"Cached leverage tiers are outdated. Will update.\")\n                        return None\n                return tiers.get(\"data\")\n            except Exception:\n                logger.exception(\"Error loading cached leverage tiers. Refreshing.\")\n        return None\n\n    def fill_leverage_tiers(self) -> None:\n        \"\"\"\n        Assigns property _leverage_tiers to a dictionary of information about the leverage\n        allowed on each pair\n        \"\"\"\n        leverage_tiers = self.load_leverage_tiers()\n        for pair, tiers in leverage_tiers.items():\n            pair_tiers = []\n            for tier in tiers:\n                pair_tiers.append(self.parse_leverage_tier(tier))\n            self._leverage_tiers[pair] = pair_tiers\n\n    def parse_leverage_tier(self, tier) -> dict:\n        info = tier.get(\"info\", {})\n        return {\n            \"minNotional\": tier[\"minNotional\"],\n            \"maxNotional\": tier[\"maxNotional\"],\n            \"maintenanceMarginRate\": tier[\"maintenanceMarginRate\"],\n            \"maxLeverage\": tier[\"maxLeverage\"],\n            \"maintAmt\": float(info[\"cum\"]) if \"cum\" in info else None,\n        }\n\n    def get_max_leverage(self, pair: str, stake_amount: float | None) -> float:\n        \"\"\"\n        Returns the maximum leverage that a pair can be traded at\n        :param pair: The base/quote currency pair being traded\n        :stake_amount: The total value of the traders margin_mode in quote currency\n        \"\"\"\n\n        if self.trading_mode == TradingMode.SPOT:\n            return 1.0\n\n        if self.trading_mode == TradingMode.FUTURES:\n            # Checks and edge cases\n            if stake_amount is None:\n                raise OperationalException(\n                    f\"{self.name}.get_max_leverage requires argument stake_amount\"\n                )\n\n            if pair not in self._leverage_tiers:\n                # Maybe raise exception because it can't be traded on futures?\n                return 1.0\n\n            pair_tiers = self._leverage_tiers[pair]\n\n            if stake_amount == 0:\n                return pair_tiers[0][\"maxLeverage\"]  # Max lev for lowest amount\n\n            # Find the appropriate tier based on stake_amount\n            prior_max_lev = None\n            for tier in pair_tiers:\n                # Adjust notional by leverage to do a proper comparison\n                min_stake = tier[\"minNotional\"] / (prior_max_lev or tier[\"maxLeverage\"])\n                max_stake = tier[\"maxNotional\"] / tier[\"maxLeverage\"]\n                prior_max_lev = tier[\"maxLeverage\"]\n                if min_stake <= stake_amount <= max_stake:\n                    return tier[\"maxLeverage\"]\n                if stake_amount < min_stake and stake_amount <= max_stake:\n                    # TODO: Remove this warning eventually\n                    # Code could be simplified by removing the check for min-stake in the above\n                    # condition, making this branch unnecessary.\n                    logger.warning(\n                        f\"Fallback to next higher leverage tier for {pair}, stake: {stake_amount}, \"\n                        f\"min_stake: {min_stake}.\"\n                    )\n                    return tier[\"maxLeverage\"]\n\n            #     else:  # if on the last tier\n            if stake_amount > max_stake:\n                # If stake is > than max tradeable amount\n                raise InvalidOrderException(f\"Stake amount {stake_amount} too high for {pair}\")\n\n            raise OperationalException(\n                f\"Looped through all tiers without finding a max leverage for {pair}. \"\n                \"Should never be reached.\"\n            )\n\n        elif self.trading_mode == TradingMode.MARGIN:  # Search markets.limits for max lev\n            market = self.markets[pair]\n            if market[\"limits\"][\"leverage\"][\"max\"] is not None:\n                return market[\"limits\"][\"leverage\"][\"max\"]\n            else:\n                return 1.0  # Default if max leverage cannot be found\n        else:\n            return 1.0\n\n    def _get_max_notional_from_tiers(self, pair: str, leverage: float) -> float | None:\n        \"\"\"\n        get max_notional from leverage_tiers\n        :param pair: The base/quote currency pair being traded\n        :param leverage: The leverage to be used\n        :return: The maximum notional value for the given leverage or None if not found\n        \"\"\"\n        if self.trading_mode != TradingMode.FUTURES:\n            return None\n        if pair not in self._leverage_tiers:\n            return None\n        pair_tiers = self._leverage_tiers[pair]\n        for tier in reversed(pair_tiers):\n            if leverage <= tier[\"maxLeverage\"]:\n                return tier[\"maxNotional\"]\n        return None\n\n    @retrier\n    def _set_leverage(\n        self,\n        leverage: float,\n        pair: str | None = None,\n        accept_fail: bool = False,\n    ):\n        \"\"\"\n        Set's the leverage before making a trade, in order to not\n        have the same leverage on every trade\n        \"\"\"\n        if self._config[\"dry_run\"] or not self.exchange_has(\"setLeverage\"):\n            # Some exchanges only support one margin_mode type\n            return\n        if self._ft_has.get(\"floor_leverage\", False) is True:\n            # Rounding for binance ...\n            leverage = floor(leverage)\n        try:\n            res = self._api.set_leverage(symbol=pair, leverage=leverage)\n            self._log_exchange_response(\"set_leverage\", res)\n        except ccxt.DDoSProtection as e:\n            raise DDosProtection(e) from e\n        except (ccxt.BadRequest, ccxt.OperationRejected, ccxt.InsufficientFunds) as e:\n            if not accept_fail:\n                raise TemporaryError(\n                    f\"Could not set leverage due to {e.__class__.__name__}. Message: {e}\"\n                ) from e\n        except (ccxt.OperationFailed, ccxt.ExchangeError) as e:\n            raise TemporaryError(\n                f\"Could not set leverage due to {e.__class__.__name__}. Message: {e}\"\n            ) from e\n        except ccxt.BaseError as e:\n            raise OperationalException(e) from e\n\n    def get_interest_rate(self) -> float:\n        \"\"\"\n        Retrieve interest rate - necessary for Margin trading.\n        Should not call the exchange directly when used from backtesting.\n        \"\"\"\n        return 0.0\n\n    def funding_fee_cutoff(self, open_date: datetime) -> bool:\n        \"\"\"\n        Funding fees are only charged at full hours (usually every 4-8h).\n        Therefore a trade opening at 10:00:01 will not be charged a funding fee until the next hour.\n        :param open_date: The open date for a trade\n        :return: True if the date falls on a full hour, False otherwise\n        \"\"\"\n        return open_date.minute == 0 and open_date.second == 0\n\n    @retrier\n    def set_margin_mode(\n        self,\n        pair: str,\n        margin_mode: MarginMode,\n        accept_fail: bool = False,\n        params: dict | None = None,\n    ):\n        \"\"\"\n        Set's the margin mode on the exchange to cross or isolated for a specific pair\n        :param pair: base/quote currency pair (e.g. \"ADA/USDT\")\n        \"\"\"\n        if self._config[\"dry_run\"] or not self.exchange_has(\"setMarginMode\"):\n            # Some exchanges only support one margin_mode type\n            return\n\n        if params is None:\n            params = {}\n        try:\n            res = self._api.set_margin_mode(margin_mode.value, pair, params)\n            self._log_exchange_response(\"set_margin_mode\", res)\n        except ccxt.DDoSProtection as e:\n            raise DDosProtection(e) from e\n        except (ccxt.BadRequest, ccxt.OperationRejected) as e:\n            if not accept_fail:\n                raise TemporaryError(\n                    f\"Could not set margin mode due to {e.__class__.__name__}. Message: {e}\"\n                ) from e\n        except (ccxt.OperationFailed, ccxt.ExchangeError) as e:\n            raise TemporaryError(\n                f\"Could not set margin mode due to {e.__class__.__name__}. Message: {e}\"\n            ) from e\n        except ccxt.BaseError as e:\n            raise OperationalException(e) from e\n\n    def _fetch_and_calculate_funding_fees(\n        self,\n        pair: str,\n        amount: float,\n        is_short: bool,\n        open_date: datetime,\n        close_date: datetime | None = None,\n    ) -> float:\n        \"\"\"\n        Fetches and calculates the sum of all funding fees that occurred for a pair\n        during a futures trade.\n        Only used during dry-run or if the exchange does not provide a funding_rates endpoint.\n        :param pair: The quote/base pair of the trade\n        :param amount: The quantity of the trade\n        :param is_short: trade direction\n        :param open_date: The date and time that the trade started\n        :param close_date: The date and time that the trade ended\n        \"\"\"\n\n        if self.funding_fee_cutoff(open_date):\n            # Shift back to 1h candle to avoid missing funding fees\n            # Only really relevant for trades very close to the full hour\n            open_date = timeframe_to_prev_date(\"1h\", open_date)\n        timeframe = self._ft_has[\"mark_ohlcv_timeframe\"]\n        timeframe_ff = self._ft_has[\"funding_fee_timeframe\"]\n        mark_price_type = CandleType.from_string(self._ft_has[\"mark_ohlcv_price\"])\n\n        if not close_date:\n            close_date = datetime.now(UTC)\n        since_ms = dt_ts(timeframe_to_prev_date(timeframe, open_date))\n\n        mark_comb: PairWithTimeframe = (pair, timeframe, mark_price_type)\n        funding_comb: PairWithTimeframe = (pair, timeframe_ff, CandleType.FUNDING_RATE)\n\n        candle_histories = self.refresh_latest_ohlcv(\n            [mark_comb, funding_comb],\n            since_ms=since_ms,\n            cache=False,\n            drop_incomplete=False,\n        )\n        try:\n            # we can't assume we always get histories - for example during exchange downtimes\n            funding_rates = candle_histories[funding_comb]\n            mark_rates = candle_histories[mark_comb]\n        except KeyError:\n            raise ExchangeError(\"Could not find funding rates.\") from None\n\n        funding_mark_rates = self.combine_funding_and_mark(funding_rates, mark_rates)\n\n        return self.calculate_funding_fees(\n            funding_mark_rates,\n            amount=amount,\n            is_short=is_short,\n            open_date=open_date,\n            close_date=close_date,\n        )\n\n    @staticmethod\n    def combine_funding_and_mark(\n        funding_rates: DataFrame, mark_rates: DataFrame, futures_funding_rate: int | None = None\n    ) -> DataFrame:\n        \"\"\"\n        Combine funding-rates and mark-rates dataframes\n        :param funding_rates: Dataframe containing Funding rates (Type FUNDING_RATE)\n        :param mark_rates: Dataframe containing Mark rates (Type mark_ohlcv_price)\n        :param futures_funding_rate: Fake funding rate to use if funding_rates are not available\n        \"\"\"\n        relevant_cols = [\"date\", \"open_mark\", \"open_fund\"]\n        if futures_funding_rate is None:\n            return mark_rates.merge(\n                funding_rates, on=\"date\", how=\"inner\", suffixes=[\"_mark\", \"_fund\"]\n            )[relevant_cols]\n        else:\n            if len(funding_rates) == 0:\n                # No funding rate candles - full fillup with fallback variable\n                mark_rates[\"open_fund\"] = futures_funding_rate\n                return mark_rates.rename(\n                    columns={\n                        \"open\": \"open_mark\",\n                        \"close\": \"close_mark\",\n                        \"high\": \"high_mark\",\n                        \"low\": \"low_mark\",\n                        \"volume\": \"volume_mark\",\n                    }\n                )[relevant_cols]\n\n            else:\n                # Fill up missing funding_rate candles with fallback value\n                combined = mark_rates.merge(\n                    funding_rates, on=\"date\", how=\"left\", suffixes=[\"_mark\", \"_fund\"]\n                )\n                # Fill only leading missing funding rates so gaps stay untouched\n                first_valid_idx = combined[\"open_fund\"].first_valid_index()\n                if first_valid_idx is None:\n                    combined[\"open_fund\"] = futures_funding_rate\n                else:\n                    is_leading_na = (combined.index <= first_valid_idx) & combined[\n                        \"open_fund\"\n                    ].isna()\n                    combined.loc[is_leading_na, \"open_fund\"] = futures_funding_rate\n                return combined[relevant_cols].dropna()\n\n    def calculate_funding_fees(\n        self,\n        df: DataFrame,\n        amount: float,\n        is_short: bool,\n        open_date: datetime,\n        close_date: datetime,\n        time_in_ratio: float | None = None,\n    ) -> float:\n        \"\"\"\n        calculates the sum of all funding fees that occurred for a pair during a futures trade\n        :param df: Dataframe containing combined funding and mark rates\n                   as `open_fund` and `open_mark`.\n        :param amount: The quantity of the trade\n        :param is_short: trade direction\n        :param open_date: The date and time that the trade started\n        :param close_date: The date and time that the trade ended\n        :param time_in_ratio: Not used by most exchange classes\n        \"\"\"\n        fees: float = 0\n\n        if not df.empty:\n            df1 = df[(df[\"date\"] >= open_date) & (df[\"date\"] <= close_date)]\n            fees = sum(df1[\"open_fund\"] * df1[\"open_mark\"] * amount)\n        if isnan(fees):\n            fees = 0.0\n        # Negate fees for longs as funding_fees expects it this way based on live endpoints.\n        return fees if is_short else -fees\n\n    def get_funding_fees(\n        self, pair: str, amount: float, is_short: bool, open_date: datetime\n    ) -> float:\n        \"\"\"\n        Fetch funding fees, either from the exchange (live) or calculates them\n        based on funding rate/mark price history\n        :param pair: The quote/base pair of the trade\n        :param is_short: trade direction\n        :param amount: Trade amount\n        :param open_date: Open date of the trade\n        :return: funding fee since open_date\n        \"\"\"\n        if self.trading_mode == TradingMode.FUTURES:\n            try:\n                if self._config[\"dry_run\"]:\n                    funding_fees = self._fetch_and_calculate_funding_fees(\n                        pair, amount, is_short, open_date\n                    )\n                else:\n                    funding_fees = self._get_funding_fees_from_exchange(pair, open_date)\n                return funding_fees\n            except ExchangeError:\n                logger.warning(f\"Could not update funding fees for {pair}.\")\n\n        return 0.0\n\n    def get_liquidation_price(\n        self,\n        pair: str,\n        # Dry-run\n        open_rate: float,  # Entry price of position\n        is_short: bool,\n        amount: float,  # Absolute value of position size\n        stake_amount: float,\n        leverage: float,\n        wallet_balance: float,\n        open_trades: list | None = None,\n    ) -> float | None:\n        \"\"\"\n        Set's the margin mode on the exchange to cross or isolated for a specific pair\n        \"\"\"\n        if self.trading_mode == TradingMode.SPOT:\n            return None\n        elif self.trading_mode != TradingMode.FUTURES:\n            raise OperationalException(\n                f\"{self.name} does not support {self.margin_mode} {self.trading_mode}\"\n            )\n\n        liquidation_price = None\n        if self._config[\"dry_run\"] or not self.exchange_has(\"fetchPositions\"):\n            liquidation_price = self.dry_run_liquidation_price(\n                pair=pair,\n                open_rate=open_rate,\n                is_short=is_short,\n                amount=amount,\n                leverage=leverage,\n                stake_amount=stake_amount,\n                wallet_balance=wallet_balance,\n                open_trades=open_trades or [],\n            )\n        else:\n            positions = self.fetch_positions(pair)\n            if len(positions) > 0:\n                pos = positions[0]\n                liquidation_price = pos[\"liquidationPrice\"]\n\n        if liquidation_price is not None:\n            buffer_amount = abs(open_rate - liquidation_price) * self.liquidation_buffer\n            liquidation_price_buffer = (\n                liquidation_price - buffer_amount if is_short else liquidation_price + buffer_amount\n            )\n            return max(liquidation_price_buffer, 0.0)\n        else:\n            return None\n\n    def dry_run_liquidation_price(\n        self,\n        pair: str,\n        open_rate: float,\n        is_short: bool,\n        amount: float,\n        stake_amount: float,\n        leverage: float,\n        wallet_balance: float,\n        open_trades: list,\n    ) -> float | None:\n        \"\"\"\n        Important: Must be fetching data from cached values as this is used by backtesting!\n        PERPETUAL:\n         gate: https://www.gate.io/help/futures/futures/27724/liquidation-price-bankruptcy-price\n         > Liquidation Price = (Entry Price  Margin / Contract Multiplier / Size) /\n                                [ 1  (Maintenance Margin Ratio + Taker Rate)]\n            Wherein, \"+\" or \"-\" depends on whether the contract goes long or short:\n            \"-\" for long, and \"+\" for short.\n\n         okx: https://www.okx.com/support/hc/en-us/articles/\n            360053909592-VI-Introduction-to-the-isolated-mode-of-Single-Multi-currency-Portfolio-margin\n\n        :param pair: Pair to calculate liquidation price for\n        :param open_rate: Entry price of position\n        :param is_short: True if the trade is a short, false otherwise\n        :param amount: Absolute value of position size incl. leverage (in base currency)\n        :param stake_amount: Stake amount - Collateral in settle currency.\n        :param leverage: Leverage used for this position.\n        :param wallet_balance: Amount of margin_mode in the wallet being used to trade\n            Cross-Margin Mode: crossWalletBalance\n            Isolated-Margin Mode: isolatedWalletBalance\n        :param open_trades: List of other open trades in the same wallet\n        \"\"\"\n\n        market = self.markets[pair]\n        # default to some default fee if not available from exchange\n        taker_fee_rate = market[\"taker\"] or self._api.describe().get(\"fees\", {}).get(\n            \"trading\", {}\n        ).get(\"taker\", 0.001)\n        mm_ratio, _ = self.get_maintenance_ratio_and_amt(pair, stake_amount)\n\n        if self.trading_mode == TradingMode.FUTURES and self.margin_mode == MarginMode.ISOLATED:\n            if market[\"inverse\"]:\n                raise OperationalException(\"Freqtrade does not yet support inverse contracts\")\n\n            value = wallet_balance / amount\n\n            mm_ratio_taker = mm_ratio + taker_fee_rate\n            if is_short:\n                return (open_rate + value) / (1 + mm_ratio_taker)\n            else:\n                return (open_rate - value) / (1 - mm_ratio_taker)\n        else:\n            raise OperationalException(\n                \"Freqtrade only supports isolated futures for leverage trading\"\n            )\n\n    def get_maintenance_ratio_and_amt(\n        self,\n        pair: str,\n        notional_value: float,\n    ) -> tuple[float, float | None]:\n        \"\"\"\n        Important: Must be fetching data from cached values as this is used by backtesting!\n        :param pair: Market symbol\n        :param notional_value: The total trade amount in quote currency\n        :return: (maintenance margin ratio, maintenance amount)\n        \"\"\"\n\n        if (\n            self._config.get(\"runmode\") in OPTIMIZE_MODES\n            or self.exchange_has(\"fetchLeverageTiers\")\n            or self.exchange_has(\"fetchMarketLeverageTiers\")\n        ):\n            if pair not in self._leverage_tiers:\n                raise InvalidOrderException(\n                    f\"Maintenance margin rate for {pair} is unavailable for {self.name}\"\n                )\n\n            pair_tiers = self._leverage_tiers[pair]\n\n            for tier in reversed(pair_tiers):\n                if notional_value >= tier[\"minNotional\"]:\n                    return (tier[\"maintenanceMarginRate\"], tier[\"maintAmt\"])\n\n            raise ExchangeError(\"nominal value can not be lower than 0\")\n            # The lowest notional_floor for any pair in fetch_leverage_tiers is always 0 because it\n            # describes the min amt for a tier, and the lowest tier will always go down to 0\n        else:\n            raise ExchangeError(f\"Cannot get maintenance ratio using {self.name}\")\n\n    def check_delisting_time(self, pair: str) -> datetime | None:\n        \"\"\"\n        Check if the pair gonna be delisted.\n        This function should be overridden by the exchange class if the exchange\n        provides such information.\n        By default, it returns None.\n        :param pair: Market symbol\n        :return: Datetime if the pair gonna be delisted, None otherwise\n        \"\"\"\n        return None\n"
        },
        {
          "path": "freqtrade/exchange/common.py",
          "url": "https://github.com/freqtrade/freqtrade/blob/develop/freqtrade/exchange/common.py",
          "lines": "1-202",
          "code": "import asyncio\nimport logging\nimport time\nfrom collections.abc import Callable\nfrom functools import wraps\nfrom typing import Any, TypeVar, cast, overload\n\nfrom freqtrade.exceptions import DDosProtection, RetryableOrderError, TemporaryError\nfrom freqtrade.mixins import LoggingMixin\n\n\nlogger = logging.getLogger(__name__)\n__logging_mixin = None\n\n\ndef _reset_logging_mixin():\n    \"\"\"\n    Reset global logging mixin - used in tests only.\n    \"\"\"\n    global __logging_mixin\n    __logging_mixin = LoggingMixin(logger)\n\n\ndef _get_logging_mixin():\n    # Logging-mixin to cache kucoin responses\n    # Only to be used in retrier\n    global __logging_mixin\n    if not __logging_mixin:\n        __logging_mixin = LoggingMixin(logger)\n    return __logging_mixin\n\n\n# Maximum default retry count.\n# Functions are always called RETRY_COUNT + 1 times (for the original call)\nAPI_RETRY_COUNT = 4\nAPI_FETCH_ORDER_RETRY_COUNT = 5\n\nBAD_EXCHANGES = {\n    \"bitmex\": \"Various reasons\",\n    \"probit\": \"Requires additional, regular calls to `signIn()`\",\n    \"poloniex\": \"Does not provide fetch_order endpoint to fetch both open and closed orders\",\n    \"krakenfutures\": \"Unsupported futures exchange\",\n    \"kucoinfutures\": \"Unsupported futures exchange\",\n    \"poloniexfutures\": \"Unsupported futures exchange\",\n    \"binancecoinm\": \"Unsupported futures exchange\",\n}\n\nMAP_EXCHANGE_CHILDCLASS = {\n    \"okex\": \"okx\",\n    \"gateio\": \"gate\",\n    \"huboi\": \"htx\",\n}\n\nSUPPORTED_EXCHANGES = [\n    \"binance\",\n    \"binanceus\",\n    \"binanceusdm\",\n    \"bingx\",\n    \"bitmart\",\n    \"bitget\",\n    \"bybit\",\n    \"gate\",\n    \"htx\",\n    \"hyperliquid\",\n    \"kraken\",\n    \"okx\",\n    \"myokx\",\n]\n\n# either the main, or replacement methods (array) is required\nEXCHANGE_HAS_REQUIRED: dict[str, list[str]] = {\n    # Required / private\n    \"fetchOrder\": [\"fetchOpenOrder\", \"fetchClosedOrder\"],\n    \"fetchL2OrderBook\": [\"fetchTicker\"],\n    \"cancelOrder\": [],\n    \"createOrder\": [],\n    \"fetchBalance\": [],\n    # Public endpoints\n    \"fetchOHLCV\": [],\n}\n\nEXCHANGE_HAS_OPTIONAL: dict[str, list[str]] = {\n    # Private\n    \"fetchMyTrades\": [],  # Trades for order - fee detection\n    \"createLimitOrder\": [],\n    \"createMarketOrder\": [],  # Either OR for orders\n    # Public\n    \"fetchOrderBook\": [],\n    \"fetchL2OrderBook\": [],\n    \"fetchTicker\": [],  # OR for pricing\n    \"fetchTickers\": [],  # For volumepairlist?\n    \"fetchTrades\": [],  # Downloading trades data\n    \"fetchOrders\": [\"fetchOpenOrders\", \"fetchClosedOrders\"],  # ,  # Refinding balance...\n    # ccxt.pro\n    \"watchOHLCV\": [],\n}\n\nEXCHANGE_HAS_OPTIONAL_FUTURES: dict[str, list[str]] = {\n    # private\n    \"setLeverage\": [],  # Margin/Futures trading\n    \"setMarginMode\": [],  # Margin/Futures trading\n    \"fetchFundingHistory\": [],  # Futures trading\n    # Public\n    \"fetchFundingRateHistory\": [],  # Futures trading\n    \"fetchPositions\": [],  # Futures trading\n    \"fetchLeverageTiers\": [\"fetchMarketLeverageTiers\"],  # Futures initialization\n    \"fetchMarkOHLCV\": [],\n    \"fetchIndexOHLCV\": [],  # Futures additional data\n    \"fetchPremiumIndexOHLCV\": [],\n}\n\n\ndef calculate_backoff(retrycount, max_retries):\n    \"\"\"\n    Calculate backoff\n    \"\"\"\n    return (max_retries - retrycount) ** 2 + 1\n\n\ndef retrier_async(f):\n    async def wrapper(*args, **kwargs):\n        count = kwargs.pop(\"count\", API_RETRY_COUNT)\n        kucoin = args[0].name == \"KuCoin\"  # Check if the exchange is KuCoin.\n        try:\n            return await f(*args, **kwargs)\n        except TemporaryError as ex:\n            msg = f'{f.__name__}() returned exception: \"{ex}\". '\n            if count > 0:\n                msg += f\"Retrying still for {count} times.\"\n                count -= 1\n                kwargs[\"count\"] = count\n                if isinstance(ex, DDosProtection):\n                    if kucoin and \"429000\" in str(ex):\n                        # Temporary fix for 429000 error on kucoin\n                        # see https://github.com/freqtrade/freqtrade/issues/5700 for details.\n                        _get_logging_mixin().log_once(\n                            f\"Kucoin 429 error, avoid triggering DDosProtection backoff delay. \"\n                            f\"{count} tries left before giving up\",\n                            logmethod=logger.warning,\n                        )\n                        # Reset msg to avoid logging too many times.\n                        msg = \"\"\n                    else:\n                        backoff_delay = calculate_backoff(count + 1, API_RETRY_COUNT)\n                        logger.info(f\"Applying DDosProtection backoff delay: {backoff_delay}\")\n                        await asyncio.sleep(backoff_delay)\n                if msg:\n                    logger.warning(msg)\n                return await wrapper(*args, **kwargs)\n            else:\n                logger.warning(msg + \"Giving up.\")\n                raise ex\n\n    return wrapper\n\n\nF = TypeVar(\"F\", bound=Callable[..., Any])\n\n\n# Type shenanigans\n@overload\ndef retrier(_func: F) -> F: ...\n\n\n@overload\ndef retrier(_func: F, *, retries=API_RETRY_COUNT) -> F: ...\n\n\n@overload\ndef retrier(*, retries=API_RETRY_COUNT) -> Callable[[F], F]: ...\n\n\ndef retrier(_func: F | None = None, *, retries=API_RETRY_COUNT):\n    def decorator(f: F) -> F:\n        @wraps(f)\n        def wrapper(*args, **kwargs):\n            count = kwargs.pop(\"count\", retries)\n            try:\n                return f(*args, **kwargs)\n            except (TemporaryError, RetryableOrderError) as ex:\n                msg = f'{f.__name__}() returned exception: \"{ex}\". '\n                if count > 0:\n                    logger.warning(msg + f\"Retrying still for {count} times.\")\n                    count -= 1\n                    kwargs.update({\"count\": count})\n                    if isinstance(ex, DDosProtection | RetryableOrderError):\n                        # increasing backoff\n                        backoff_delay = calculate_backoff(count + 1, retries)\n                        logger.info(f\"Applying DDosProtection backoff delay: {backoff_delay}\")\n                        time.sleep(backoff_delay)\n                    return wrapper(*args, **kwargs)\n                else:\n                    logger.warning(msg + \"Giving up.\")\n                    raise ex\n\n        return cast(F, wrapper)\n\n    # Support both @retrier and @retrier(retries=2) syntax\n    if _func is None:\n        return decorator\n    else:\n        return decorator(_func)\n"
        }
      ]
    },
    {
      "id": 2,
      "name": "event_driven_backtest",
      "source_repo": "jesse-ai/jesse",
      "files": [
        {
          "path": "jesse/modes/backtest_mode.py",
          "url": "https://github.com/jesse-ai/jesse/blob/master/jesse/modes/backtest_mode.py",
          "lines": "1-1237",
          "code": "import time\nimport re\nfrom typing import Dict, List, Tuple, Optional\nimport numpy as np\nimport jesse.helpers as jh\nimport jesse.services.metrics as stats\nimport jesse.services.selectors as selectors\nfrom jesse import exceptions\nfrom jesse.config import config\nfrom jesse.enums import timeframes, order_types\nfrom jesse.models import Order, Position\nfrom jesse.modes.utils import save_daily_portfolio_balance\nfrom jesse.research.monte_carlo.candle_pipelines import BaseCandlesPipeline\nfrom jesse.routes import router\nfrom jesse.services import charts\nfrom jesse.services import report\nfrom jesse.services.candle import generate_candle_from_one_minutes, print_candle, candle_includes_price, split_candle, \\\n    get_candles, inject_warmup_candles_to_store\nfrom jesse.services.file import store_logs\nfrom jesse.services.validators import validate_routes\nfrom jesse.store import store\nfrom jesse.services import logger\nfrom jesse.services.failure import register_custom_exception_handler\nfrom jesse.services.redis import sync_publish, is_process_active\nfrom timeloop import Timeloop\nfrom datetime import timedelta\nfrom jesse.services.progressbar import Progressbar\nfrom jesse.constants import TIMEFRAME_TO_ONE_MINUTES\n\n\ndef run(\n        client_id: str,\n        debug_mode: bool,\n        user_config: dict,\n        exchange: str,\n        routes: List[Dict[str, str]],\n        data_routes: List[Dict[str, str]],\n        start_date: str,\n        finish_date: str,\n        candles: dict = None,\n        chart: bool = False,\n        tradingview: bool = False,\n        csv: bool = False,\n        json: bool = False,\n        fast_mode: bool = False,\n        benchmark: bool = False\n) -> None:\n    if not jh.is_unit_testing():\n        # at every second, we check to see if it's time to execute stuff\n        status_checker = Timeloop()\n\n        @status_checker.job(interval=timedelta(seconds=1))\n        def handle_time():\n            if is_process_active(client_id) is False:\n                raise exceptions.Termination\n\n        status_checker.start()\n\n    from jesse.config import config\n    config['app']['trading_mode'] = 'backtest'\n\n    # debug flag\n    config['app']['debug_mode'] = debug_mode\n\n    register_custom_exception_handler()\n\n    _execute_backtest(\n        client_id, debug_mode, user_config, exchange, routes, data_routes, start_date, finish_date, candles, chart,\n        tradingview, csv, json, fast_mode, benchmark\n    )\n\n\ndef _execute_backtest(\n        client_id: str,\n        debug_mode: bool,\n        user_config: dict,\n        exchange: str,\n        routes: List[Dict[str, str]],\n        data_routes: List[Dict[str, str]],\n        start_date: str,\n        finish_date: str,\n        candles: dict = None,\n        chart: bool = False,\n        tradingview: bool = False,\n        csv: bool = False,\n        json: bool = False,\n        fast_mode: bool = False,\n        benchmark: bool = False\n):\n    \"\"\"\n    Executes the backtest that has been initiated from within the dashboard. The purpose of extracting these\n    functionalities into this function is so that in case it fails due to a missing data route, it can add\n    it and then re-execute itself.\n    \"\"\"\n    from jesse.config import set_config\n\n    # inject config\n    if not jh.is_unit_testing():\n        set_config(user_config)\n    # add exchange to routes\n    for r in routes:\n        r['exchange'] = exchange\n    for r in data_routes:\n        r['exchange'] = exchange\n    # set routes\n    router.initiate(routes, data_routes)\n\n    store.app.set_session_id(client_id)\n\n    # Store backtest session in database (only for UI dashboard, not for CLI/research)\n    if not jh.should_execute_silently():\n        from jesse.models.BacktestSession import store_backtest_session\n        store_backtest_session(\n            id=client_id,\n            status='running'\n        )\n\n    # validate routes\n    validate_routes(router)\n\n    # initiate candle store\n    store.candles.init_storage(5000)\n\n    # load historical candles\n    if candles is None:\n        try:\n            warmup_candles, candles = load_candles(\n                jh.date_to_timestamp(start_date),\n                jh.date_to_timestamp(finish_date)\n            )\n            _handle_warmup_candles(warmup_candles, start_date)\n        except exceptions.CandlesNotFound as e:\n            # Extract symbol and exchange from error message\n            match = re.search(r\"for (.*?) on (.*?)$\", str(e))\n            if match:\n                symbol, exchange = match.groups()\n                raise exceptions.CandlesNotFound({\n                    'message': str(e),\n                    'symbol': symbol,\n                    'exchange': exchange,\n                    'start_date': start_date,\n                    'type': 'missing_candles'\n                })\n            raise e\n\n    if not jh.should_execute_silently():\n        sync_publish('general_info', {\n            'session_id': jh.get_session_id(),\n            'debug_mode': str(config['app']['debug_mode']),\n        })\n        # candles info\n        key = f\"{config['app']['considering_candles'][0][0]}-{config['app']['considering_candles'][0][1]}\"\n        sync_publish('candles_info', stats.candles_info(candles[key]['candles']))\n        # routes info\n        sync_publish('routes_info', stats.routes(router.routes))\n\n    # run backtest simulation\n    result = None\n    try:\n        result = simulator(\n            candles,\n            run_silently=jh.should_execute_silently(),\n            generate_tradingview=tradingview,\n            generate_csv=csv,\n            generate_json=json,\n            generate_equity_curve=True,\n            benchmark=benchmark,\n            generate_hyperparameters=True,\n            fast_mode=fast_mode,\n        )\n    except exceptions.RouteNotFound as e:\n        # Extract exchange, symbol, and timeframe using regular expressions\n        match = re.search(r\"symbol='(.+?)', timeframe='(.+?)'\", str(e))\n        if match:\n            symbol = match.group(1)\n            timeframe = match.group(2)\n            # Adjust data_routes to include the missing route\n            data_routes.append({\n                'exchange': exchange,\n                'symbol': symbol,\n                'timeframe': timeframe\n            })\n            # to prevent an issue with warmupcandles being None\n            candles = None\n            # notify the user about the missing data route and retry the backtest simulation\n            sync_publish('notification', {\n                'message': f'Missing data route for \"{symbol}\" with \"{timeframe}\" timeframe. Adding it and retrying...',\n                'type': 'error'\n            })\n            # retry the backtest simulation\n            _execute_backtest(\n                client_id, debug_mode, user_config, exchange, routes, data_routes, start_date, finish_date, candles,\n                chart, tradingview, csv, json, fast_mode, benchmark\n            )\n            return\n        else:\n            raise e\n    except Exception as e:\n        # Store exception in database (only for UI dashboard)\n        if not jh.should_execute_silently():\n            import traceback\n            from jesse.models.BacktestSession import store_backtest_session_exception, update_backtest_session_status\n            store_backtest_session_exception(client_id, str(e), traceback.format_exc())\n            update_backtest_session_status(client_id, 'stopped')\n        raise\n\n    if result and not jh.should_execute_silently():\n        sync_publish('alert', {\n            'message': f\"Successfully executed backtest simulation in: {result['execution_duration']} seconds\",\n            'type': 'success'\n        })\n        sync_publish('hyperparameters', result['hyperparameters'])\n        sync_publish('metrics', result['metrics'])\n        sync_publish('equity_curve', result['equity_curve'], compression=True)\n        sync_publish('trades', result['trades'], compression=True)\n        \n        # Prepare chart data if requested (call formatting functions once and cache)\n        chart_data = None\n        if chart:\n            # Store the data for database\n            chart_data = {\n                'candles_chart': _get_formatted_candles_for_frontend(),\n                'orders_chart': _get_formatted_orders_for_frontend(),\n                'add_line_to_candle_chart': _get_add_line_to_candle_chart(),\n                'add_extra_line_chart': _get_add_extra_line_chart(),\n                'add_horizontal_line_to_candle_chart': _get_add_horizontal_line_to_candle_chart(),\n                'add_horizontal_line_to_extra_chart': _get_add_horizontal_line_to_extra_chart()\n            }\n        \n        # Capture strategy codes for each route\n        strategy_codes = {}\n        import os\n        for r in router.routes:\n            key = f\"{r.exchange}-{r.symbol}\"\n            if key not in strategy_codes:\n                try:\n                    strategy_path = f'strategies/{r.strategy_name}/__init__.py'\n                    \n                    if os.path.exists(strategy_path):\n                        with open(strategy_path, 'r') as f:\n                            content = f.read()\n                        strategy_codes[key] = content\n                except Exception:\n                    pass\n        \n        # Update backtest session in database with results\n        from jesse.models.BacktestSession import update_backtest_session_results, update_backtest_session_status\n        update_backtest_session_results(\n            id=client_id,\n            metrics=result.get('metrics'),\n            equity_curve=result.get('equity_curve'),\n            trades=result.get('trades'),\n            hyperparameters=result.get('hyperparameters'),\n            chart_data=chart_data,\n            execution_duration=result.get('execution_duration'),\n            strategy_codes=strategy_codes if strategy_codes else None\n        )\n        update_backtest_session_status(client_id, 'finished')\n\n    # close database connection\n    from jesse.services.db import database\n    database.close_connection()\n\n\ndef _get_formatted_candles_for_frontend():\n    arr = []\n    for r in router.routes:\n        candles_arr = store.candles.get_candles(r.exchange, r.symbol, r.timeframe)\n        # Find the index where the starting time actually begins.\n        starting_index = 0\n        for i, c in enumerate(candles_arr):\n            if c[0] >= store.app.starting_time:\n                starting_index = i\n                break\n\n        candles = [{\n            'time': int(c[0]/1000),\n            'open': c[1],\n            'close': c[2],\n            'high': c[3],\n            'low': c[4],\n            'volume': c[5]\n        } for c in candles_arr[starting_index:]]\n        arr.append({\n            'exchange': r.exchange,\n            'symbol': r.symbol,\n            'timeframe': r.timeframe,\n            'candles': candles\n        })\n    return arr\n\n\ndef _get_formatted_orders_for_frontend():\n    arr = []\n    for r in router.routes:\n        arr.append({\n            'exchange': r.exchange,\n            'symbol': r.symbol,\n            'timeframe': r.timeframe,\n            'orders': r.strategy._executed_orders\n        })\n    return arr\n\n\ndef _get_add_line_to_candle_chart():\n    arr = []\n    for r in router.routes:\n        arr.append({\n            'exchange': r.exchange,\n            'symbol': r.symbol,\n            'timeframe': r.timeframe,\n            'lines': r.strategy._add_line_to_candle_chart_values\n        })\n    return arr\n\n\ndef _get_add_extra_line_chart():\n    arr = []\n    for r in router.routes:\n        arr.append({\n            'exchange': r.exchange,\n            'symbol': r.symbol,\n            'timeframe': r.timeframe,\n            'charts': r.strategy._add_extra_line_chart_values\n        })\n    return arr\n\n\ndef _get_add_horizontal_line_to_candle_chart():\n    arr = []\n    for r in router.routes:\n        arr.append({\n            'exchange': r.exchange,\n            'symbol': r.symbol,\n            'timeframe': r.timeframe,\n            'lines': r.strategy._add_horizontal_line_to_candle_chart_values\n        })\n    return arr\n\n\ndef _get_add_horizontal_line_to_extra_chart():\n    arr = []\n    for r in router.routes:\n        arr.append({\n            'exchange': r.exchange,\n            'symbol': r.symbol,\n            'timeframe': r.timeframe,\n            'lines': r.strategy._add_horizontal_line_to_extra_chart_values\n        })\n    return arr\n\n\ndef _handle_missing_candles(exchange: str, symbol: str, start_date: int, message: str = None):\n    \"\"\"Helper function to handle missing candles scenarios\"\"\"\n    formatted_date = jh.timestamp_to_date(start_date)\n    if message is None:\n        message = f'Missing trading candles for {symbol} on {exchange} from {formatted_date}'\n    \n    sync_publish(\n        \"missing_candles\",\n        {\n            \"message\": message,\n            \"symbol\": symbol,\n            \"exchange\": exchange,\n            \"start_date\": formatted_date,\n        },\n    )\n    \n    raise exceptions.CandlesNotFound({\n        'message': message,\n        'symbol': symbol,\n        'exchange': exchange,\n        'start_date': start_date,\n        'type': 'missing_candles'\n    })\n\n\ndef load_candles(start_date: int, finish_date: int) -> Tuple[dict, dict]:\n    warmup_num = jh.get_config('env.data.warmup_candles_num', 210)\n    max_timeframe = jh.max_timeframe(config['app']['considering_timeframes'])\n\n    # load and add required warm-up candles for backtest, and then Prepare trading candles\n    trading_candles = {}\n    warmup_candles = {}\n    for c in config['app']['considering_candles']:\n        exchange, symbol = c[0], c[1]\n        warmup_candles_arr, trading_candle_arr = get_candles(\n            exchange, symbol, max_timeframe, start_date, finish_date, warmup_num, caching=True, is_for_jesse=True\n        )\n\n        # Ensure that trading_candle_arr is not None or empty\n        if trading_candle_arr is None or (isinstance(trading_candle_arr, np.ndarray) and trading_candle_arr.size == 0):\n            _handle_missing_candles(\n                exchange, \n                symbol, \n                start_date, \n                f\"Missing trading candles for {symbol} on {exchange}\"\n            )\n\n        # Check that the first trading candle covers the requested start date.\n        if trading_candle_arr[0][0] > start_date:\n            _handle_missing_candles(exchange, symbol, start_date)\n\n        # Check that the last trading candle covers the requested finish date.\n        if trading_candle_arr[-1][0] < (finish_date - 60_000):\n            _handle_missing_candles(exchange, symbol, start_date)\n\n        # add trading candles\n        trading_candles[jh.key(exchange, symbol)] = {\n            'exchange': exchange,\n            'symbol': symbol,\n            'candles': trading_candle_arr\n        }\n\n        warmup_candles[jh.key(exchange, symbol)] = {\n            'exchange': exchange,\n            'symbol': symbol,\n            'candles': warmup_candles_arr\n        }\n\n    return warmup_candles, trading_candles\n\n\ndef _handle_warmup_candles(warmup_candles: dict, start_date: str) -> None:\n    try:\n        for c in config['app']['considering_candles']:\n            exchange, symbol = c[0], c[1]\n            inject_warmup_candles_to_store(warmup_candles[jh.key(exchange, symbol)]['candles'], exchange, symbol)\n    except ValueError as e:\n        # Extract exchange and symbol from error message\n        match = re.search(r\"for (.*?)/(.*?)\\?\", str(e))\n        if match:\n            exchange, symbol = match.groups()\n            \n            # Calculate warmup start date using the same logic as load_candles()\n            warmup_num = jh.get_config('env.data.warmup_candles_num', 210)\n            max_timeframe = jh.max_timeframe(config['app']['considering_timeframes'])\n            # Convert max_timeframe to minutes and multiply by warmup_num\n            warmup_minutes = TIMEFRAME_TO_ONE_MINUTES[max_timeframe] * warmup_num\n            warmup_start_timestamp = jh.date_to_timestamp(start_date) - (warmup_minutes * 60_000)\n            warmup_start_date = jh.timestamp_to_date(warmup_start_timestamp)\n            # Publish the missing candles error to the frontend\n            # This will trigger the alert in the BacktestTab.vue component\n            # so that the user can import the missing candles\n            sync_publish(\n                \"missing_candles\",\n                {\n                    \"message\": f'Missing warmup candles for {symbol} on {exchange} from {warmup_start_date}',\n                    \"symbol\": symbol,\n                    \"exchange\": exchange,\n                    \"start_date\": warmup_start_date,\n                },\n            )\n            raise exceptions.CandlesNotFound(str(e))\n        raise e\n\n\ndef simulator(*args, fast_mode: bool = False, **kwargs) -> dict:\n    if fast_mode:\n        return _skip_simulator(*args, **kwargs)\n\n    return _step_simulator(*args, **kwargs)\n\n\ndef _step_simulator(\n        candles: dict,\n        run_silently: bool,\n        hyperparameters: dict = None,\n        generate_tradingview: bool = False,\n        generate_csv: bool = False,\n        generate_json: bool = False,\n        generate_equity_curve: bool = False,\n        benchmark: bool = False,\n        generate_hyperparameters: bool = False,\n        generate_logs: bool = False,\n        with_candles_pipeline: bool = True,\n        candles_pipeline_class = None,\n        candles_pipeline_kwargs: dict = None,\n) -> dict:\n    # In case generating logs is specifically demanded, the debug mode must be enabled.\n    if generate_logs:\n        config['app']['debug_mode'] = True\n\n    begin_time_track = time.time()\n\n    key = f\"{config['app']['considering_candles'][0][0]}-{config['app']['considering_candles'][0][1]}\"\n    first_candles_set = candles[key]['candles']\n\n    length = _simulation_minutes_length(candles)\n    _prepare_times_before_simulation(candles)\n    candles_pipelines = _prepare_routes(hyperparameters, with_candles_pipeline, candles_pipeline_class, candles_pipeline_kwargs)\n\n    # add initial balance\n    save_daily_portfolio_balance(is_initial=True)\n\n    progressbar = Progressbar(length, step=420)\n    last_update_time = None\n    for i in range(length):\n        # update time\n        store.app.time = first_candles_set[i][0] + 60_000\n\n        # add candles\n        for j in candles:\n            candles_pipeline = candles_pipelines[j]\n            short_candle = get_candles_from_pipeline(candles_pipeline, candles[j]['candles'], i)\n            if i != 0:\n                previous_short_candle = candles[j]['candles'][i - 1]\n                short_candle = _get_fixed_jumped_candle(previous_short_candle, short_candle)\n            exchange = candles[j]['exchange']\n            symbol = candles[j]['symbol']\n\n            store.candles.add_candle(short_candle, exchange, symbol, '1m', with_execution=False,\n                                     with_generation=False)\n\n            # print short candle\n            if jh.is_debuggable('shorter_period_candles'):\n                print_candle(short_candle, True, symbol)\n\n            _simulate_price_change_effect(short_candle, exchange, symbol)\n\n            # generate and add candles for bigger timeframes\n            for timeframe in config['app']['considering_timeframes']:\n                # for 1m, no work is needed\n                if timeframe == '1m':\n                    continue\n\n                count = TIMEFRAME_TO_ONE_MINUTES[timeframe]\n                # until = count - ((i + 1) % count)\n\n                if (i + 1) % count == 0:\n                    generated_candle = generate_candle_from_one_minutes(\n                        timeframe,\n                        candles[j]['candles'][(i - (count - 1)):(i + 1)]\n                    )\n\n                    store.candles.add_candle(generated_candle, exchange, symbol, timeframe, with_execution=False,\n                                             with_generation=False)\n\n        last_update_time = _update_progress_bar(progressbar, run_silently, i, candle_step=420,\n                                                last_update_time=last_update_time)\n\n        # now that all new generated candles are ready, execute\n        for r in router.routes:\n            count = TIMEFRAME_TO_ONE_MINUTES[r.timeframe]\n            # 1m timeframe\n            if r.timeframe == timeframes.MINUTE_1:\n                r.strategy._execute()\n            elif (i + 1) % count == 0:\n                # print candle\n                if jh.is_debuggable('trading_candles'):\n                    print_candle(store.candles.get_current_candle(r.exchange, r.symbol, r.timeframe), False,\n                                 r.symbol)\n                r.strategy._execute()\n\n            store.orders.update_active_orders(r.exchange, r.symbol)\n\n        # now check to see if there's any MARKET orders waiting to be executed\n        _execute_market_orders()\n\n        if i != 0 and i % 1440 == 0:\n            save_daily_portfolio_balance()\n\n    _finish_progress_bar(progressbar, run_silently)\n\n    execution_duration = 0\n    if not run_silently:\n        # print executed time for the backtest session\n        finish_time_track = time.time()\n        execution_duration = round(finish_time_track - begin_time_track, 2)\n\n    for r in router.routes:\n        r.strategy._terminate()\n        _execute_market_orders()\n\n    # now that backtest simulation is finished, add finishing balance\n    save_daily_portfolio_balance()\n\n    # set the ending time for the backtest session\n    store.app.ending_time = store.app.time + 60_000\n\n    result = _generate_outputs(\n        candles,\n        generate_tradingview=generate_tradingview,\n        generate_csv=generate_csv,\n        generate_json=generate_json,\n        generate_equity_curve=generate_equity_curve,\n        benchmark=benchmark,\n        generate_hyperparameters=generate_hyperparameters,\n        generate_logs=generate_logs,\n    )\n    result['execution_duration'] = execution_duration\n    return result\n\n\ndef _simulation_minutes_length(candles: dict) -> int:\n    key = f\"{config['app']['considering_candles'][0][0]}-{config['app']['considering_candles'][0][1]}\"\n    first_candles_set = candles[key][\"candles\"]\n    return len(first_candles_set)\n\n\ndef _prepare_times_before_simulation(candles: dict) -> None:\n    # result = {}\n    # begin_time_track = time.time()\n    key = f\"{config['app']['considering_candles'][0][0]}-{config['app']['considering_candles'][0][1]}\"\n    first_candles_set = candles[key][\"candles\"]\n    # length = len(first_candles_set)\n    # to preset the array size for performance\n    try:\n        store.app.starting_time = first_candles_set[0][0]\n    except IndexError:\n        raise IndexError('Check your \"warm_up_candles\" config value')\n    store.app.time = first_candles_set[0][0]\n\n\ndef _prepare_routes(hyperparameters: dict = None,\n                    with_candles_pipeline: bool = True,\n                    candles_pipeline_class = None,\n                    candles_pipeline_kwargs: dict = None,\n                    ) -> Dict[str, BaseCandlesPipeline | None]:\n    # initiate strategies\n    candles_pipeline = {}\n\n    for r in router.routes:\n        # if the r.strategy is str read it from file\n        if isinstance(r.strategy_name, str):\n            StrategyClass = jh.get_strategy_class(r.strategy_name)\n        # else it is a class object so just use it\n        else:\n            StrategyClass = r.strategy_name\n\n        try:\n            r.strategy = StrategyClass()\n        except TypeError:\n            raise exceptions.InvalidStrategy(\n                \"Strategy validation failed. Make sure your strategy has the mandatory methods such as should_long(), \"\n                \"go_long(), etc. For working examples, visit: https://jesse.trade/strategies\"\n            )\n        except:\n            raise\n\n        r.strategy.name = r.strategy_name\n        r.strategy.exchange = r.exchange\n        r.strategy.symbol = r.symbol\n        r.strategy.timeframe = r.timeframe\n\n        # read the dna from strategy's dna() and use it for injecting inject hyperparameters\n        # first convert DNS string into hyperparameters\n        if len(r.strategy.dna()) > 0 and hyperparameters is None:\n            hyperparameters = jh.dna_to_hp(\n                r.strategy.hyperparameters(), r.strategy.dna()\n            )\n\n        # inject hyperparameters sent within the optimize mode\n        if hyperparameters is not None:\n            r.strategy.hp = hyperparameters\n\n        # init few objects that couldn't be initiated in Strategy __init__\n        # it also injects hyperparameters into self.hp in case the route does not uses any DNAs\n        r.strategy._init_objects()\n        if with_candles_pipeline:\n            if candles_pipeline_class is not None:\n                # Use the provided pipeline class with kwargs if available\n                kwargs = candles_pipeline_kwargs or {}\n                candles_pipeline[jh.key(r.exchange, r.symbol)] = candles_pipeline_class(**kwargs)\n            else:\n                # Otherwise, fall back to the strategy's pipeline\n                candles_pipeline[jh.key(r.exchange, r.symbol)] = r.strategy.candles_pipeline()\n        else:\n            candles_pipeline[jh.key(r.exchange, r.symbol)] = None\n\n        selectors.get_position(r.exchange, r.symbol).strategy = r.strategy\n\n    # Ensure pipelines exist for data routes as well (no strategy attached)\n    # Keys in `candles` include both trading and data routes; provide a pipeline (or None) for each\n    for dr in getattr(router, 'data_routes', []) or []:\n        key = jh.key(dr.exchange, dr.symbol)\n        if key in candles_pipeline:\n            continue\n        if with_candles_pipeline and candles_pipeline_class is not None:\n            kwargs = candles_pipeline_kwargs or {}\n            candles_pipeline[key] = candles_pipeline_class(**kwargs)\n        else:\n            candles_pipeline[key] = None\n\n    return candles_pipeline\n\n\ndef get_candles_from_pipeline(candles_pipeline: Optional[BaseCandlesPipeline], candles: np.ndarray, i: int, candles_step: int = -1) -> np.ndarray:\n    if candles_pipeline is None:\n        if candles_step == -1:\n            return candles[i]\n        else:\n            return candles[i: i+candles_step]\n    return candles_pipeline.get_candles(candles[i: i + candles_pipeline._batch_size], i, candles_step)\n\n\ndef _update_progress_bar(\n        progressbar: Progressbar, run_silently: bool, candle_index: int, candle_step: int, last_update_time: float\n) -> float:\n    throttle_interval = 0.5\n    current_time = time.time()\n    if not run_silently and candle_index % candle_step == 0:\n        progressbar.update()\n\n        if last_update_time is None or (current_time - last_update_time) >= throttle_interval:\n            sync_publish(\n                \"progressbar\",\n                {\n                    \"current\": progressbar.current,\n                    \"estimated_remaining_seconds\": progressbar.estimated_remaining_seconds,\n                },\n            )\n            # Update the last update time\n            last_update_time = current_time\n\n    # Return the last update time for future reference\n    return last_update_time\n\n\ndef _finish_progress_bar(progressbar: Progressbar, run_silently: bool):\n    if run_silently:\n        return\n\n    progressbar.finish()\n    sync_publish(\n        \"progressbar\",\n        {\n            \"current\": 100,\n            \"estimated_remaining_seconds\": 0,\n        },\n    )\n\n\ndef _get_fixed_jumped_candle(\n        previous_candle: np.ndarray, candle: np.ndarray\n) -> np.ndarray:\n    \"\"\"\n    A little workaround for the times that the price has jumped and the opening\n    price of the current candle is not equal to the previous candle's close!\n\n    :param previous_candle: np.ndarray\n    :param candle: np.ndarray\n    \"\"\"\n    if previous_candle[2] < candle[1]:\n        candle[1] = previous_candle[2]\n        candle[4] = min(previous_candle[2], candle[4])\n    elif previous_candle[2] > candle[1]:\n        candle[1] = previous_candle[2]\n        candle[3] = max(previous_candle[2], candle[3])\n\n    return candle\n\n\ndef _simulate_price_change_effect(real_candle: np.ndarray, exchange: str, symbol: str) -> None:\n    current_temp_candle = real_candle.copy()\n    executed_order = False\n\n    executing_orders = _get_executing_orders(exchange, symbol, real_candle)\n    if len(executing_orders) > 1:\n        # extend the candle shape from (6,) to (1,6)\n        executing_orders = _sort_execution_orders(executing_orders, current_temp_candle[None, :])\n\n    while True:\n        if len(executing_orders) == 0:\n            executed_order = False\n        else:\n            for index, order in enumerate(executing_orders):\n                if index == len(executing_orders) - 1 and not order.is_active:\n                    executed_order = False\n\n                if not order.is_active:\n                    continue\n\n                if candle_includes_price(current_temp_candle, order.price):\n                    storable_temp_candle, current_temp_candle = split_candle(current_temp_candle, order.price)\n                    _update_all_routes_a_partial_candle(exchange, symbol, storable_temp_candle)\n\n                    p = selectors.get_position(exchange, symbol)\n                    p.current_price = storable_temp_candle[2]\n\n                    executed_order = True\n\n                    order.execute()\n                    executing_orders = _get_executing_orders(exchange, symbol, current_temp_candle)\n                    if len(executing_orders) > 1:\n                        # extend the candle shape from (6,) to (1,6)\n                        executing_orders = _sort_execution_orders(executing_orders, current_temp_candle[None, :])\n\n                    # break from the for loop, we'll try again inside the while\n                    # loop with the new current_temp_candle\n                    break\n                else:\n                    executed_order = False\n\n        if not executed_order:\n            # add/update the real_candle to the store so we can move on\n            store.candles.add_candle(\n                real_candle, exchange, symbol, '1m',\n                with_execution=False,\n                with_generation=False\n            )\n            p = selectors.get_position(exchange, symbol)\n            if p:\n                p.current_price = real_candle[2]\n            break\n\n    _check_for_liquidations(real_candle, exchange, symbol)\n\n\ndef _check_for_liquidations(candle: np.ndarray, exchange: str, symbol: str) -> None:\n    p: Position = selectors.get_position(exchange, symbol)\n\n    if not p:\n        return\n\n    # for now, we only support the isolated mode:\n    if p.mode != 'isolated':\n        return\n\n    if candle_includes_price(candle, p.liquidation_price):\n        closing_order_side = jh.closing_side(p.type)\n\n        # create the market order that is used as the liquidation order\n        order = Order({\n            'id': jh.generate_unique_id(),\n            'symbol': symbol,\n            'exchange': exchange,\n            'side': closing_order_side,\n            'type': order_types.MARKET,\n            'reduce_only': True,\n            'qty': jh.prepare_qty(p.qty, closing_order_side),\n            'price': p.bankruptcy_price\n        })\n\n        store.orders.add_order(order)\n\n        store.app.total_liquidations += 1\n\n        logger.info(f'{p.symbol} liquidated at {p.liquidation_price}')\n\n        order.execute()\n\n\ndef _generate_outputs(\n        candles: dict,\n        generate_tradingview: bool = False,\n        generate_csv: bool = False,\n        generate_json: bool = False,\n        generate_equity_curve: bool = False,\n        benchmark: bool = False,\n        generate_hyperparameters: bool = False,\n        generate_logs: bool = False,\n):\n    result = {}\n    if generate_hyperparameters:\n        result[\"hyperparameters\"] = stats.hyperparameters(router.routes)\n    result[\"metrics\"] = report.portfolio_metrics()\n    result[\"trades\"] = report.trades()\n    # generate logs in json, csv and tradingview's pine-editor format\n    logs_path = store_logs(generate_json, generate_tradingview, generate_csv)\n    if generate_json:\n        result[\"json\"] = logs_path[\"json\"]\n    if generate_tradingview:\n        result[\"tradingview\"] = logs_path[\"tradingview\"]\n    if generate_csv:\n        result[\"csv\"] = logs_path[\"csv\"]\n    if generate_equity_curve:\n        result[\"equity_curve\"] = charts.equity_curve(benchmark)\n    if generate_logs:\n        result[\"logs\"] = f\"storage/logs/backtest-mode/{jh.get_session_id()}.txt\"\n    return result\n\n\ndef _skip_simulator(\n        candles: dict,\n        run_silently: bool,\n        hyperparameters: dict = None,\n        generate_tradingview: bool = False,\n        generate_csv: bool = False,\n        generate_json: bool = False,\n        generate_equity_curve: bool = False,\n        benchmark: bool = False,\n        generate_hyperparameters: bool = False,\n        generate_logs: bool = False,\n        with_candles_pipeline: bool = True,\n        candles_pipeline_class = None,\n        candles_pipeline_kwargs: dict = None,\n) -> dict:\n    # In case generating logs is specifically demanded, the debug mode must be enabled.\n    if generate_logs:\n        config[\"app\"][\"debug_mode\"] = True\n\n    begin_time_track = time.time()\n\n    length = _simulation_minutes_length(candles)\n    _prepare_times_before_simulation(candles)\n    candles_pipelines = _prepare_routes(hyperparameters, with_candles_pipeline, candles_pipeline_class, candles_pipeline_kwargs)\n\n    # add initial balance\n    save_daily_portfolio_balance(is_initial=True)\n\n    candles_step = _calculate_minimum_candle_step()\n    progressbar = Progressbar(length, step=candles_step)\n    last_update_time = None\n    for i in range(0, length, candles_step):\n        # update time moved to _simulate_price_change_effect__multiple_candles\n        # store.app.time = first_candles_set[i][0] + (60_000 * candles_step)\n        _simulate_new_candles(candles, candles_pipelines, i, candles_step)\n\n        last_update_time = _update_progress_bar(progressbar, run_silently, i, candles_step,\n                                                last_update_time=last_update_time)\n\n        _execute_routes(i, candles_step)\n\n        # now check to see if there's any MARKET orders waiting to be executed\n        _execute_market_orders()\n\n        if i != 0 and i % 1440 == 0:\n            save_daily_portfolio_balance()\n\n    _finish_progress_bar(progressbar, run_silently)\n\n    execution_duration = 0\n    if not run_silently:\n        # print executed time for the backtest session\n        finish_time_track = time.time()\n        execution_duration = round(finish_time_track - begin_time_track, 2)\n\n    for r in router.routes:\n        r.strategy._terminate()\n        _execute_market_orders()\n\n    # now that backtest simulation is finished, add finishing balance\n    save_daily_portfolio_balance()\n\n    # set the ending time for the backtest session\n    store.app.ending_time = store.app.time + 60_000\n\n    result = _generate_outputs(\n        candles,\n        generate_tradingview=generate_tradingview,\n        generate_csv=generate_csv,\n        generate_json=generate_json,\n        generate_equity_curve=generate_equity_curve,\n        benchmark=benchmark,\n        generate_hyperparameters=generate_hyperparameters,\n        generate_logs=generate_logs,\n    )\n    result['execution_duration'] = execution_duration\n    return result\n\n\ndef _calculate_minimum_candle_step():\n    \"\"\"\n    Calculates the minimum step for update candles that will allow simple updates on the simulator.\n    \"\"\"\n    # config[\"app\"][\"considering_timeframes\"] use '1m' also even if not required by the user so take only what the user\n    # is requested.\n    consider_time_frames = [\n        TIMEFRAME_TO_ONE_MINUTES[route[\"timeframe\"]]\n        for route in router.all_formatted_routes\n    ]\n    return np.gcd.reduce(consider_time_frames)\n\ntimeframe_to_one_minutes = {\n    timeframes.MINUTE_1: 1,\n    timeframes.MINUTE_3: 3,\n    timeframes.MINUTE_5: 5,\n    timeframes.MINUTE_15: 15,\n    timeframes.MINUTE_30: 30,\n    timeframes.MINUTE_45: 45,\n    timeframes.HOUR_1: 60,\n    timeframes.HOUR_2: 60 * 2,\n    timeframes.HOUR_3: 60 * 3,\n    timeframes.HOUR_4: 60 * 4,\n    timeframes.HOUR_6: 60 * 6,\n    timeframes.HOUR_8: 60 * 8,\n    timeframes.HOUR_12: 60 * 12,\n    timeframes.DAY_1: 60 * 24,\n    timeframes.DAY_3: 60 * 24 * 3,\n    timeframes.WEEK_1: 60 * 24 * 7,\n    timeframes.MONTH_1: 60 * 24 * 30,\n}\ndef _simulate_new_candles(candles: dict, candles_pipelines: Dict[str, BaseCandlesPipeline], candle_index: int, candles_step: int) -> None:\n    i = candle_index\n    # add candles\n    for j in candles:\n        candles_pipeline = candles_pipelines[j]\n        short_candles = get_candles_from_pipeline(candles_pipeline, candles[j]['candles'], i, candles_step)\n        candles[j]['candles'][i:i+candles_step] = short_candles\n        if i != 0:\n            previous_short_candles = candles[j][\"candles\"][i - 1]\n            # work the same, the fix needs to be done only on the gap of 1m edge candles.\n            short_candles[0] = _get_fixed_jumped_candle(\n                previous_short_candles, short_candles[0]\n            )\n        exchange = candles[j][\"exchange\"]\n        symbol = candles[j][\"symbol\"]\n\n        _simulate_price_change_effect_multiple_candles(\n            short_candles, exchange, symbol\n        )\n\n        # generate and add candles for bigger timeframes\n        for timeframe in config[\"app\"][\"considering_timeframes\"]:\n            # for 1m, no work is needed\n            if timeframe == \"1m\":\n                continue\n\n            count = TIMEFRAME_TO_ONE_MINUTES[timeframe]\n\n            if (i + candles_step) % count == 0:\n                generated_candle = generate_candle_from_one_minutes(\n                    timeframe,\n                    candles[j][\"candles\"][\n                    i - count + candles_step: i + candles_step],\n                )\n\n                store.candles.add_candle(\n                    generated_candle,\n                    exchange,\n                    symbol,\n                    timeframe,\n                    with_execution=False,\n                    with_generation=False,\n                )\n\n\ndef _simulate_price_change_effect_multiple_candles(\n        short_timeframes_candles: np.ndarray, exchange: str, symbol: str\n) -> None:\n    real_candle = np.array(\n        [\n            short_timeframes_candles[0][0],\n            short_timeframes_candles[0][1],\n            short_timeframes_candles[-1][2],\n            short_timeframes_candles[:, 3].max(),\n            short_timeframes_candles[:, 4].min(),\n            short_timeframes_candles[:, 5].sum(),\n        ]\n    )\n    executing_orders = _get_executing_orders(exchange, symbol, real_candle)\n    if len(executing_orders) > 0:\n        if len(executing_orders) > 1:\n            executing_orders = _sort_execution_orders(executing_orders, short_timeframes_candles)\n\n        for i in range(len(short_timeframes_candles)):\n            current_temp_candle = short_timeframes_candles[i].copy()\n            if i > 0:\n                current_temp_candle[3] = max(current_temp_candle[3], short_timeframes_candles[i-1, 2])\n                current_temp_candle[4] = min(current_temp_candle[4], short_timeframes_candles[i-1, 2])\n            is_executed_order = False\n\n            while True:\n                if len(executing_orders) == 0:\n                    is_executed_order = False\n                else:\n                    for index, order in enumerate(executing_orders):\n                        if index == len(executing_orders) - 1 and not order.is_active:\n                            is_executed_order = False\n                        if not order.is_active:\n                            continue\n\n                        if candle_includes_price(current_temp_candle, order.price):\n                            storable_temp_candle, current_temp_candle = split_candle(\n                                current_temp_candle, order.price\n                            )\n                            _update_all_routes_a_partial_candle(\n                                exchange,\n                                symbol,\n                                storable_temp_candle,\n                            )\n                            p = selectors.get_position(exchange, symbol)\n                            p.current_price = storable_temp_candle[2]\n\n                            is_executed_order = True\n\n                            store.app.time = storable_temp_candle[0] + 60_000\n                            order.execute()\n                            executing_orders = _get_executing_orders(\n                                exchange, symbol, real_candle\n                            )\n\n                            # break from the for loop, we'll try again inside the while\n                            # loop with the new current_temp_candle\n                            break\n                        else:\n                            is_executed_order = False\n\n                if not is_executed_order:\n                    # add/update the real_candle to the store so we can move on\n                    store.candles.add_candle(\n                        short_timeframes_candles[i].copy(),\n                        exchange,\n                        symbol,\n                        \"1m\",\n                        with_execution=False,\n                        with_generation=False,\n                    )\n                    p = selectors.get_position(exchange, symbol)\n                    if p:\n                        p.current_price = current_temp_candle[2]\n                    break\n\n    store.candles.add_multiple_1m_candles(\n        short_timeframes_candles,\n        exchange,\n        symbol,\n    )\n    store.app.time = real_candle[0] + (60_000 * len(short_timeframes_candles))\n    _check_for_liquidations(real_candle, exchange, symbol)\n\n    p = selectors.get_position(exchange, symbol)\n    if p:\n        p.current_price = short_timeframes_candles[-1, 2]\n\n\ndef _update_all_routes_a_partial_candle(\n        exchange: str,\n        symbol: str,\n        storable_temp_candle: np.ndarray,\n) -> None:\n    \"\"\"\n    This function get called when an order is getting executed you need to update the other timeframe how their last\n    candles looks like\n    \"\"\"\n    store.candles.add_candle(\n        storable_temp_candle,\n        exchange,\n        symbol,\n        \"1m\",\n        with_execution=False,\n        with_generation=False,\n    )\n\n    for route in router.all_formatted_routes:\n        timeframe = route['timeframe']\n        if route['exchange'] != exchange or route['symbol'] != symbol:\n            continue\n        if timeframe == '1m':\n            continue\n        tf_minutes = TIMEFRAME_TO_ONE_MINUTES[timeframe]\n        number_of_needed_candles = int(storable_temp_candle[0] % (tf_minutes * 60_000) // 60000) + 1\n        candles_1m = store.candles.get_candles(exchange, symbol, '1m')[-number_of_needed_candles:]\n        generated_candle = generate_candle_from_one_minutes(\n            timeframe,\n            candles_1m,\n            accept_forming_candles=True\n        )\n        store.candles.add_candle(\n            generated_candle,\n            exchange,\n            symbol,\n            timeframe,\n            with_execution=False,\n            with_generation=False,\n        )\n\n\ndef _execute_routes(candle_index: int, candles_step: int) -> None:\n    # now that all new generated candles are ready, execute\n    for r in router.routes:\n        count = TIMEFRAME_TO_ONE_MINUTES[r.timeframe]\n        # 1m timeframe\n        if r.timeframe == timeframes.MINUTE_1:\n            r.strategy._execute()\n        elif (candle_index + candles_step) % count == 0:\n            # print candle\n            if jh.is_debuggable(\"trading_candles\"):\n                print_candle(\n                    store.candles.get_current_candle(\n                        r.exchange, r.symbol, r.timeframe\n                    ),\n                    False,\n                    r.symbol,\n                )\n            r.strategy._execute()\n\n        store.orders.update_active_orders(r.exchange, r.symbol)\n\n\ndef _execute_market_orders():\n    store.orders.execute_pending_market_orders()\n\n\ndef _get_executing_orders(exchange, symbol, real_candle):\n    orders = store.orders.get_active_orders(exchange, symbol)\n    return [\n        order\n        for order in orders\n        if order.is_active and candle_includes_price(real_candle, order.price)\n    ]\n\n\ndef _sort_execution_orders(orders: List[Order], short_candles: np.ndarray):\n    remaining_orders = set(orders)\n    sorted_orders = []\n    \n    for candle in short_candles:\n        open_price, close_price, low, high = candle[1], candle[2], candle[4], candle[3]\n\n        # Did not use candle_includes_price() for performance, keeping it vectorization-friendly\n        included_orders = [order for order in remaining_orders if low <= order.price <= high]\n\n        if len(included_orders) == 1:\n            sorted_orders.append(included_orders[0])\n            remaining_orders.remove(included_orders[0])\n        elif len(included_orders) > 1:\n            # in case that the orders are above\n            on_open, above_open, below_open = [], [], []\n            for order in included_orders:\n                if order.price == open_price:\n                    on_open.append(order)\n                if order.price > open_price:\n                    above_open.append(order)\n                else:\n                    below_open.append(order)\n            sorted_orders += on_open\n            remaining_orders.difference_update(on_open)\n\n            is_red = open_price > close_price\n            if is_red:\n                # heuristic that first the price goes up and then down, so this is the order execution sort\n                above_open.sort(key=lambda o: o.price)\n                below_open.sort(key=lambda o: o.price, reverse=True)\n                sorted_orders += above_open + below_open\n                remaining_orders.difference_update(above_open + below_open)\n            else:\n                below_open.sort(key=lambda o: o.price, reverse=True)\n                above_open.sort(key=lambda o: o.price)\n                sorted_orders += below_open + above_open\n                remaining_orders.difference_update(below_open + above_open)\n\n        if len(sorted_orders) == len(orders):\n            break\n\n    return sorted_orders\n"
        },
        {
          "path": "jesse/services/broker.py",
          "url": "https://github.com/jesse-ai/jesse/blob/master/jesse/services/broker.py",
          "lines": "1-161",
          "code": "from typing import Union\n\nimport jesse.helpers as jh\nfrom jesse.enums import sides\nfrom jesse.exceptions import OrderNotAllowed, InvalidStrategy\nfrom jesse.models import Order\nfrom jesse.models import Position\n\n\nclass Broker:\n    def __init__(self, position: Position, exchange: str, symbol: str, timeframe: str) -> None:\n        self.position = position\n        self.symbol = symbol\n        self.timeframe = timeframe\n        self.exchange = exchange\n        from jesse.services.api import api\n        self.api = api\n\n    @staticmethod\n    def _validate_qty(qty: float) -> None:\n        if qty == 0:\n            raise InvalidStrategy('qty cannot be 0. \\nRead more: https://jesse.trade/help/faq/i-keep-getting-invalidstrategy')\n\n    def sell_at_market(self, qty: float) -> Union[Order, None]:\n        self._validate_qty(qty)\n\n        return self.api.market_order(\n            self.exchange,\n            self.symbol,\n            abs(qty),\n            self.position.current_price,\n            sides.SELL,\n            reduce_only=False\n        )\n\n    def sell_at(self, qty: float, price: float) -> Union[Order, None]:\n        self._validate_qty(qty)\n\n        if price < 0:\n            raise ValueError('price cannot be negative.')\n\n        return self.api.limit_order(\n            self.exchange,\n            self.symbol,\n            abs(qty),\n            price,\n            sides.SELL,\n            reduce_only=False\n        )\n\n    def buy_at_market(self, qty: float) -> Union[Order, None]:\n        self._validate_qty(qty)\n\n        return self.api.market_order(\n            self.exchange,\n            self.symbol,\n            abs(qty),\n            self.position.current_price,\n            sides.BUY,\n            reduce_only=False\n        )\n\n    def buy_at(self, qty: float, price: float) -> Union[Order, None]:\n        self._validate_qty(qty)\n\n        if price < 0:\n            raise ValueError('price cannot be negative.')\n\n        return self.api.limit_order(\n            self.exchange,\n            self.symbol,\n            abs(qty),\n            price,\n            sides.BUY,\n            reduce_only=False\n        )\n\n    def reduce_position_at(self, qty: float, price: float, current_price: float) -> Union[Order, None]:\n        self._validate_qty(qty)\n\n        qty = abs(qty)\n\n        # validation\n        if price < 0:\n            raise ValueError(f'order price cannot be negative. You passed {price}')\n\n        # validation\n        if self.position.is_close:\n            raise OrderNotAllowed(\n                'Cannot submit a reduce_position order when there is no open position'\n            )\n\n        side = jh.opposite_side(jh.type_to_side(self.position.type))\n\n        # MARKET order\n        # if the price difference is bellow 0.01% of the current price, then we submit a market order\n        if jh.is_price_near(price, current_price):\n            return self.api.market_order(\n                self.exchange,\n                self.symbol,\n                qty,\n                price,\n                side,\n                reduce_only=True\n            )\n\n        # LIMIT order\n        elif (side == 'sell' and self.position.type == 'long' and price > current_price) or (\n                side == 'buy' and self.position.type == 'short' and price < current_price):\n            return self.api.limit_order(\n                self.exchange,\n                self.symbol,\n                qty,\n                price,\n                side,\n                reduce_only=True\n            )\n\n        # STOP order\n        elif (side == 'sell' and self.position.type == 'long' and price < current_price) or (\n                side == 'buy' and self.position.type == 'short' and price > current_price):\n            return self.api.stop_order(\n                self.exchange,\n                self.symbol,\n                abs(qty),\n                price,\n                side,\n                reduce_only=True\n            )\n        else:\n            raise OrderNotAllowed(\"This order doesn't seem to be for reducing the position.\")\n\n    def start_profit_at(self, side: str, qty: float, price: float) -> Union[Order, None]:\n        self._validate_qty(qty)\n\n        if price < 0:\n            raise ValueError('price cannot be negative.')\n\n        if side == 'buy' and price < self.position.current_price:\n            raise OrderNotAllowed(\n                f'A buy start_profit({price}) order must have a price higher than current_price({self.position.current_price}).'\n            )\n        if side == 'sell' and price > self.position.current_price:\n            raise OrderNotAllowed(\n                f'A sell start_profit({price}) order must have a price lower than current_price({self.position.current_price}).'\n            )\n\n        return self.api.stop_order(\n            self.exchange,\n            self.symbol,\n            abs(qty),\n            price,\n            side,\n            reduce_only=False\n        )\n\n    def cancel_all_orders(self) -> bool:\n        return self.api.cancel_all_orders(self.exchange, self.symbol)\n\n    def cancel_order(self, order_id: str) -> bool:\n        return self.api.cancel_order(self.exchange, self.symbol, order_id)\n"
        },
        {
          "path": "jesse/services/candle.py",
          "url": "https://github.com/jesse-ai/jesse/blob/master/jesse/services/candle.py",
          "lines": "1-398",
          "code": "from typing import Tuple\nimport numpy as np\nimport arrow\nfrom jesse.exceptions import CandleNotFoundInDatabase, InvalidDateRange\nimport jesse.helpers as jh\nfrom jesse.services import logger\nfrom jesse.models import Candle\nfrom typing import List, Dict\n\n\ndef generate_candle_from_one_minutes(\n        timeframe: str,\n        candles: np.ndarray,\n        accept_forming_candles: bool = False\n) -> np.ndarray:\n    if len(candles) == 0:\n        raise ValueError('No candles were passed')\n\n    if not accept_forming_candles and len(candles) != jh.timeframe_to_one_minutes(timeframe):\n        raise ValueError(\n            f'Sent only {len(candles)} candles but {jh.timeframe_to_one_minutes(timeframe)} is required to create a \"{timeframe}\" candle.'\n        )\n\n    return np.array([\n        candles[0][0],\n        candles[0][1],\n        candles[-1][2],\n        candles[:, 3].max(),\n        candles[:, 4].min(),\n        candles[:, 5].sum(),\n    ])\n\n\ndef candle_dict_to_np_array(candle: dict) -> np.ndarray:\n    return np.array([\n        candle['timestamp'],\n        candle['open'],\n        candle['close'],\n        candle['high'],\n        candle['low'],\n        candle['volume']\n    ])\n\n\ndef print_candle(candle: np.ndarray, is_partial: bool, symbol: str) -> None:\n    \"\"\"\n    Ever since the new GUI dashboard, this function should log instead of actually printing\n\n    :param candle: np.ndarray\n    :param is_partial: bool\n    :param symbol: str\n    \"\"\"\n    if jh.should_execute_silently():\n        return\n\n    candle_form = '  ==' if is_partial else '===='\n    candle_info = f' {symbol} | {str(arrow.get(candle[0] / 1000))[:-9]} | {candle[1]} | {candle[2]} | {candle[3]} | {candle[4]} | {round(candle[5], 2)}'\n    msg = candle_form + candle_info\n\n    # store it in the log file\n    logger.info(msg)\n\n\ndef is_bullish(candle: np.ndarray) -> bool:\n    return candle[2] >= candle[1]\n\n\ndef is_bearish(candle: np.ndarray) -> bool:\n    return candle[2] < candle[1]\n\n\ndef candle_includes_price(candle: np.ndarray, price: float) -> bool:\n    return (price >= candle[4]) and (price <= candle[3])\n\n\ndef split_candle(candle: np.ndarray, price: float) -> tuple:\n    \"\"\"\n    splits a single candle into two candles: earlier + later\n\n    :param candle: np.ndarray\n    :param price: float\n\n    :return: tuple\n    \"\"\"\n    timestamp = candle[0]\n    o = candle[1]\n    c = candle[2]\n    h = candle[3]\n    l = candle[4]\n    v = candle[5]\n\n    if is_bullish(candle) and l < price < o:\n        return np.array([\n            timestamp, o, price, o, price, v\n        ]), np.array([\n            timestamp, price, c, h, l, v\n        ])\n    elif price == o:\n        return candle, candle\n    elif is_bearish(candle) and o < price < h:\n        return np.array([\n            timestamp, o, price, price, o, v\n        ]), np.array([\n            timestamp, price, c, h, l, v\n        ])\n    elif is_bearish(candle) and l < price < c:\n        return np.array([\n            timestamp, o, price, h, price, v\n        ]), np.array([\n            timestamp, price, c, c, l, v\n        ])\n    elif is_bullish(candle) and c < price < h:\n        return np.array([\n            timestamp, o, price, price, l, v\n        ]), np.array([\n            timestamp, price, c, h, c, v\n        ]),\n    elif is_bearish(candle) and price == c:\n        return np.array([\n            timestamp, o, c, h, c, v\n        ]), np.array([\n            timestamp, price, price, price, l, v\n        ])\n    elif is_bullish(candle) and price == c:\n        return np.array([\n            timestamp, o, c, c, l, v\n        ]), np.array([\n            timestamp, price, price, h, price, v\n        ])\n    elif is_bearish(candle) and price == h:\n        return np.array([\n            timestamp, o, h, h, o, v\n        ]), np.array([\n            timestamp, h, c, h, l, v\n        ])\n    elif is_bullish(candle) and price == l:\n        return np.array([\n            timestamp, o, l, o, l, v\n        ]), np.array([\n            timestamp, l, c, h, l, v\n        ])\n    elif is_bearish(candle) and price == l:\n        return np.array([\n            timestamp, o, l, h, l, v\n        ]), np.array([\n            timestamp, l, c, c, l, v\n        ])\n    elif is_bullish(candle) and price == h:\n        return np.array([\n            timestamp, o, h, h, l, v\n        ]), np.array([\n            timestamp, h, c, h, c, v\n        ])\n    elif is_bearish(candle) and c < price < o:\n        return np.array([\n            timestamp, o, price, h, price, v\n        ]), np.array([\n            timestamp, price, c, price, l, v\n        ])\n    elif is_bullish(candle) and o < price < c:\n        return np.array([\n            timestamp, o, price, price, l, v\n        ]), np.array([\n            timestamp, price, c, h, price, v\n        ])\n\n\ndef inject_warmup_candles_to_store(candles: np.ndarray, exchange: str, symbol: str) -> None:\n    if candles is None or candles.size == 0:\n        raise ValueError(f'Could not inject warmup candles because the passed candles are empty. Have you imported enough warmup candles for {exchange}/{symbol}?')\n\n    from jesse.config import config\n    from jesse.store import store\n\n    # batch add 1m candles:\n    store.candles.batch_add_candle(candles, exchange, symbol, '1m', with_generation=False)\n\n    # loop to generate, and add candles (without execution)\n    for i in range(len(candles)):\n        for timeframe in config['app']['considering_timeframes']:\n            # skip 1m. already added\n            if timeframe == '1m':\n                continue\n\n            num = jh.timeframe_to_one_minutes(timeframe)\n\n            if (i + 1) % num == 0:\n                generated_candle = generate_candle_from_one_minutes(\n                    timeframe,\n                    candles[(i - (num - 1)):(i + 1)],\n                    True\n                )\n\n                store.candles.add_candle(\n                    generated_candle,\n                    exchange,\n                    symbol,\n                    timeframe,\n                    with_execution=False,\n                    with_generation=False\n                )\n\n\ndef get_candles(\n        exchange: str,\n        symbol: str,\n        timeframe: str,\n        start_date_timestamp: int,\n        finish_date_timestamp: int,\n        warmup_candles_num: int = 0,\n        caching: bool = False,\n        is_for_jesse: bool = False\n) -> Tuple[np.ndarray, np.ndarray]:\n    symbol = symbol.upper()\n\n    # convert start_date and finish_date to timestamps\n    trading_start_date_timestamp = jh.timestamp_to_arrow(start_date_timestamp).floor(\n        'day').int_timestamp * 1000\n    trading_finish_date_timestamp = (jh.timestamp_to_arrow(finish_date_timestamp).floor(\n        'day').int_timestamp * 1000) - 60_000\n\n    # if warmup_candles is set, calculate the warmup start and finish timestamps\n    if warmup_candles_num > 0:\n        warmup_finish_timestamp = trading_start_date_timestamp\n        warmup_start_timestamp = warmup_finish_timestamp - (\n                warmup_candles_num * jh.timeframe_to_one_minutes(timeframe) * 60_000)\n        warmup_finish_timestamp -= 60_000\n        warmup_candles = _get_candles_from_db(exchange, symbol, warmup_start_timestamp, warmup_finish_timestamp,\n                                              caching=caching)\n    else:\n        warmup_candles = None\n\n    # fetch trading candles from database\n    trading_candles = _get_candles_from_db(exchange, symbol, trading_start_date_timestamp,\n                                           trading_finish_date_timestamp, caching=caching)\n\n    # if timeframe is 1m or is_for_jesse is True, return the candles as is because they\n    # are already 1m candles which is the accepted format for practicing with Jesse.\n    if timeframe == '1m' or is_for_jesse:\n        return warmup_candles, trading_candles\n\n    # if the timeframe is not 1m, generate the candles for the requested timeframe\n    if warmup_candles_num > 0:\n        warmup_candles = _get_generated_candles(timeframe, warmup_candles)\n    else:\n        warmup_candles = None\n    trading_candles = _get_generated_candles(timeframe, trading_candles)\n\n    return warmup_candles, trading_candles\n\n\ndef _get_candles_from_db(\n        exchange, symbol, start_date_timestamp, finish_date_timestamp, caching: bool = False\n) -> np.ndarray:\n    from jesse.models import Candle\n    from jesse.services.cache import cache\n\n    if caching:\n        key = jh.key(exchange, symbol)\n        cache_key = f\"{start_date_timestamp}-{finish_date_timestamp}-{key}\"\n        cached_value = cache.get_value(cache_key)\n        if cached_value:\n            return np.array(cached_value)\n\n    # validate the dates\n    if start_date_timestamp == finish_date_timestamp:\n        raise InvalidDateRange('start_date and finish_date cannot be the same.')\n    if start_date_timestamp > finish_date_timestamp:\n        raise InvalidDateRange(f'start_date ({jh.timestamp_to_date(start_date_timestamp)}) is greater than finish_date ({jh.timestamp_to_date(finish_date_timestamp)}).')\n    \n    # validate finish_date is not in the future\n    current_timestamp = arrow.utcnow().int_timestamp * 1000\n    if finish_date_timestamp > current_timestamp:\n        today_str = jh.timestamp_to_date(current_timestamp)\n        yesterday_date = jh.timestamp_to_date(current_timestamp - 86400000)\n        raise InvalidDateRange(f'The finish date \"{jh.timestamp_to_time(finish_date_timestamp)[:19]}\" cannot be in the future. Please select a date up to \"{yesterday_date}\".')\n\n    # validate start_date is not in the future\n    if start_date_timestamp > current_timestamp:\n        raise InvalidDateRange(f'Can\\'t backtest the future! start_date ({jh.timestamp_to_date(start_date_timestamp)}) is greater than the current time ({jh.timestamp_to_date(current_timestamp)}).')\n\n    # Always materialize the database results immediately\n    candles_tuple = list(Candle.select(\n        Candle.timestamp, Candle.open, Candle.close, Candle.high, Candle.low,\n        Candle.volume\n    ).where(\n        Candle.exchange == exchange,\n        Candle.symbol == symbol,\n        Candle.timeframe == '1m' or Candle.timeframe.is_null(),\n        Candle.timestamp.between(start_date_timestamp, finish_date_timestamp)\n    ).order_by(Candle.timestamp.asc()).tuples())\n\n    # Check if we got any candles\n    if not candles_tuple:\n        raise CandleNotFoundInDatabase(f\"No candles found for {symbol} on {exchange} between {jh.timestamp_to_date(start_date_timestamp)} and {jh.timestamp_to_date(finish_date_timestamp)}.\")\n    \n    # Convert to numpy array for easier timestamp extraction\n    candles_array = np.array(candles_tuple)\n    \n    # Verify the retrieved data covers the requested range\n    if len(candles_array) > 0:\n        earliest_available = candles_array[0][0]  # First timestamp\n        latest_available = candles_array[-1][0]   # Last timestamp\n        \n        # Check if earliest available timestamp is after the requested start date\n        if earliest_available > start_date_timestamp + 60_000:  # Allow 1 minute tolerance\n            raise CandleNotFoundInDatabase(\n                f\"Missing candles for {symbol} on {exchange}. \"\n                f\"Requested data from {jh.timestamp_to_date(start_date_timestamp)}, \"\n                f\"but earliest available candle is from {jh.timestamp_to_date(earliest_available)}.\"\n            )\n            \n        # For finish date validation, we need to check if we have candles up to exactly one minute\n        # before the start of the requested finish date\n        # Check if the latest available candle timestamp is before the required last candle\n        if latest_available < finish_date_timestamp:\n            # Missing candles at the end of the requested range\n            raise CandleNotFoundInDatabase(\n                f\"Missing recent candles for \\\"{symbol}\\\" on \\\"{exchange}\\\". \"\n                f\"Requested data until \\\"{jh.timestamp_to_time(finish_date_timestamp)[:19]}\\\", \"\n                f\"but latest available candle is up to \\\"{jh.timestamp_to_time(latest_available)[:19]}\\\".\"\n            )\n\n    if caching:\n        # cache for 1 week it for near future calls\n        cache.set_value(cache_key, candles_tuple, expire_seconds=60 * 60 * 24 * 7)\n\n    return candles_array\n\n\ndef _get_generated_candles(timeframe, trading_candles) -> np.ndarray:\n    # generate candles for the requested timeframe\n    generated_candles = []\n    for i in range(len(trading_candles)):\n        num = jh.timeframe_to_one_minutes(timeframe)\n\n        if (i + 1) % num == 0:\n            generated_candles.append(\n                generate_candle_from_one_minutes(\n                    timeframe,\n                    trading_candles[(i - (num - 1)):(i + 1)],\n                    True\n                )\n            )\n\n    return np.array(generated_candles)\n\n\ndef get_existing_candles() -> List[Dict]:\n    \"\"\"\n    Returns a list of all existing candles grouped by exchange and symbol\n    \"\"\"\n    results = []\n    \n    # Get unique exchange-symbol combinations\n    pairs = Candle.select(\n        Candle.exchange, \n        Candle.symbol\n    ).distinct().tuples()\n\n    for exchange, symbol in pairs:\n        # Get first and last candle for this pair\n        first = Candle.select(\n            Candle.timestamp\n        ).where(\n            Candle.exchange == exchange,\n            Candle.symbol == symbol\n        ).order_by(\n            Candle.timestamp.asc()\n        ).first()\n\n        last = Candle.select(\n            Candle.timestamp\n        ).where(\n            Candle.exchange == exchange,\n            Candle.symbol == symbol\n        ).order_by(\n            Candle.timestamp.desc()\n        ).first()\n\n        if first and last:\n            results.append({\n                'exchange': exchange,\n                'symbol': symbol,\n                'start_date': arrow.get(first.timestamp / 1000).format('YYYY-MM-DD'),\n                'end_date': arrow.get(last.timestamp / 1000).format('YYYY-MM-DD')\n            })\n\n    return results\n\ndef delete_candles(exchange: str, symbol: str) -> None:\n    \"\"\"\n    Deletes all candles for the given exchange and symbol\n    \"\"\"\n    Candle.delete().where(\n        Candle.exchange == exchange,\n        Candle.symbol == symbol\n    ).execute()\n"
        },
        {
          "path": "jesse/models/Exchange.py",
          "url": "https://github.com/jesse-ai/jesse/blob/master/jesse/models/Exchange.py",
          "lines": "1-73",
          "code": "from abc import ABC, abstractmethod\nfrom jesse.models import Order\nfrom jesse.services import selectors\nimport jesse.helpers as jh\nfrom jesse.libs import DynamicNumpyArray\nfrom jesse.info import exchange_info\n\nclass Exchange(ABC):\n    def __init__(self, name: str, starting_balance: float, fee_rate: float, exchange_type: str):\n        # currently holding assets\n        self.assets = {}\n        # used for calculating available balance in futures mode:\n        self.temp_reduced_amount = {}\n        # used for calculating final performance metrics\n        self.starting_assets = {}\n        # current available assets (dynamically changes based on active orders)\n        self.available_assets = {}\n        self.fee_rate = fee_rate\n        # some exchanges might require even further info\n        self.vars = {}\n\n        self.buy_orders = {}\n        self.sell_orders = {}\n\n        self.name = name\n        self.type = exchange_type.lower()\n\n        # in running session's quote currency\n        self.starting_balance = starting_balance\n\n        all_trading_routes = selectors.get_all_trading_routes()\n        first_route = all_trading_routes[0]\n        # check the settlement_currency is in the exchange info with name equal to the exchange name\n        if self.name in exchange_info and 'settlement_currency' in exchange_info[self.name]:\n            self.settlement_currency = exchange_info[self.name]['settlement_currency']\n        else:\n            self.settlement_currency = jh.quote_asset(first_route.symbol)\n\n        # initiate dict keys for trading assets\n        for r in all_trading_routes:\n            base_asset = jh.base_asset(r.symbol)\n            self.buy_orders[base_asset] = DynamicNumpyArray((10, 2))\n            self.sell_orders[base_asset] = DynamicNumpyArray((10, 2))\n            self.assets[base_asset] = 0.0\n            self.assets[self.settlement_currency] = 0.0 if jh.is_livetrading() else starting_balance\n            self.temp_reduced_amount[base_asset] = 0.0\n            self.temp_reduced_amount[self.settlement_currency] = 0.0\n            self.starting_assets[base_asset] = 0.0\n            self.starting_assets[self.settlement_currency] = starting_balance\n            self.available_assets[base_asset] = 0.0\n            self.available_assets[self.settlement_currency] = starting_balance\n\n    @property\n    @abstractmethod\n    def wallet_balance(self) -> float:\n        pass\n\n    @property\n    @abstractmethod\n    def available_margin(self) -> float:\n        pass\n\n    @abstractmethod\n    def on_order_submission(self, order: Order) -> None:\n        pass\n\n    @abstractmethod\n    def on_order_execution(self, order: Order) -> None:\n        pass\n\n    @abstractmethod\n    def on_order_cancellation(self, order: Order) -> None:\n        pass\n"
        }
      ]
    },
    {
      "id": 3,
      "name": "rl_policy_networks",
      "source_repo": "AI4Finance-Foundation/FinRL",
      "files": [
        {
          "path": "finrl/agents/stablebaselines3/models.py",
          "url": "https://github.com/AI4Finance-Foundation/FinRL/blob/master/finrl/agents/stablebaselines3/models.py",
          "lines": "1-713",
          "code": "# DRL models from Stable Baselines 3\nfrom __future__ import annotations\n\nimport statistics\nimport time\n\nimport numpy as np\nimport pandas as pd\nfrom stable_baselines3 import A2C\nfrom stable_baselines3 import DDPG\nfrom stable_baselines3 import PPO\nfrom stable_baselines3 import SAC\nfrom stable_baselines3 import TD3\nfrom stable_baselines3.common.callbacks import BaseCallback\nfrom stable_baselines3.common.callbacks import CallbackList\nfrom stable_baselines3.common.noise import NormalActionNoise\nfrom stable_baselines3.common.noise import OrnsteinUhlenbeckActionNoise\nfrom stable_baselines3.common.vec_env import DummyVecEnv\n\nfrom finrl import config\nfrom finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\nfrom finrl.meta.preprocessor.preprocessors import data_split\n\nMODELS = {\"a2c\": A2C, \"ddpg\": DDPG, \"td3\": TD3, \"sac\": SAC, \"ppo\": PPO}\n\nMODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\n\nNOISE = {\n    \"normal\": NormalActionNoise,\n    \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n}\n\n\nclass TensorboardCallback(BaseCallback):\n    \"\"\"\n    Custom callback for plotting additional values in tensorboard.\n    \"\"\"\n\n    def __init__(self, verbose=0):\n        super().__init__(verbose)\n\n    def _on_step(self) -> bool:\n        try:\n            self.logger.record(key=\"train/reward\", value=self.locals[\"rewards\"][0])\n\n        except BaseException as error:\n            try:\n                self.logger.record(key=\"train/reward\", value=self.locals[\"reward\"][0])\n\n            except BaseException as inner_error:\n                # Handle the case where neither \"rewards\" nor \"reward\" is found\n                self.logger.record(key=\"train/reward\", value=None)\n                # Print the original error and the inner error for debugging\n                print(\"Original Error:\", error)\n                print(\"Inner Error:\", inner_error)\n        return True\n\n    def _on_rollout_end(self) -> bool:\n        try:\n            rollout_buffer_rewards = self.locals[\"rollout_buffer\"].rewards.flatten()\n            self.logger.record(\n                key=\"train/reward_min\", value=min(rollout_buffer_rewards)\n            )\n            self.logger.record(\n                key=\"train/reward_mean\", value=statistics.mean(rollout_buffer_rewards)\n            )\n            self.logger.record(\n                key=\"train/reward_max\", value=max(rollout_buffer_rewards)\n            )\n        except BaseException as error:\n            # Handle the case where \"rewards\" is not found\n            self.logger.record(key=\"train/reward_min\", value=None)\n            self.logger.record(key=\"train/reward_mean\", value=None)\n            self.logger.record(key=\"train/reward_max\", value=None)\n            print(\"Logging Error:\", error)\n        return True\n\n\nclass DRLAgent:\n    \"\"\"Provides implementations for DRL algorithms\n\n    Attributes\n    ----------\n        env: gym environment class\n            user-defined class\n\n    Methods\n    -------\n        get_model()\n            setup DRL algorithms\n        train_model()\n            train DRL algorithms in a train dataset\n            and output the trained model\n        DRL_prediction()\n            make a prediction in a test dataset and get results\n    \"\"\"\n\n    def __init__(self, env):\n        self.env = env\n\n    def get_model(\n        self,\n        model_name,\n        policy=\"MlpPolicy\",\n        policy_kwargs=None,\n        model_kwargs=None,\n        verbose=1,\n        seed=None,\n        tensorboard_log=None,\n    ):\n        if model_name not in MODELS:\n            raise ValueError(\n                f\"Model '{model_name}' not found in MODELS.\"\n            )  # this is more informative than NotImplementedError(\"NotImplementedError\")\n\n        if model_kwargs is None:\n            model_kwargs = MODEL_KWARGS[model_name]\n\n        if \"action_noise\" in model_kwargs:\n            n_actions = self.env.action_space.shape[-1]\n            model_kwargs[\"action_noise\"] = NOISE[model_kwargs[\"action_noise\"]](\n                mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions)\n            )\n        print(model_kwargs)\n        return MODELS[model_name](\n            policy=policy,\n            env=self.env,\n            tensorboard_log=tensorboard_log,\n            verbose=verbose,\n            policy_kwargs=policy_kwargs,\n            seed=seed,\n            **model_kwargs,\n        )\n\n    @staticmethod\n    def train_model(\n        model,\n        tb_log_name,\n        total_timesteps=5000,\n        callbacks: Type[BaseCallback] = None,\n    ):  # this function is static method, so it can be called without creating an instance of the class\n        model = model.learn(\n            total_timesteps=total_timesteps,\n            tb_log_name=tb_log_name,\n            callback=(\n                CallbackList(\n                    [TensorboardCallback()] + [callback for callback in callbacks]\n                )\n                if callbacks is not None\n                else TensorboardCallback()\n            ),\n        )\n        return model\n\n    @staticmethod\n    def DRL_prediction(model, environment, deterministic=True):\n        \"\"\"make a prediction and get results\"\"\"\n        test_env, test_obs = environment.get_sb_env()\n        account_memory = None  # This help avoid unnecessary list creation\n        actions_memory = None  # optimize memory consumption\n        # state_memory=[] #add memory pool to store states\n\n        test_env.reset()\n        max_steps = len(environment.df.index.unique()) - 1\n\n        for i in range(len(environment.df.index.unique())):\n            action, _states = model.predict(test_obs, deterministic=deterministic)\n            # account_memory = test_env.env_method(method_name=\"save_asset_memory\")\n            # actions_memory = test_env.env_method(method_name=\"save_action_memory\")\n            test_obs, rewards, dones, info = test_env.step(action)\n\n            if (\n                i == max_steps - 1\n            ):  # more descriptive condition for early termination to clarify the logic\n                account_memory = test_env.env_method(method_name=\"save_asset_memory\")\n                actions_memory = test_env.env_method(method_name=\"save_action_memory\")\n            # add current state to state memory\n            # state_memory=test_env.env_method(method_name=\"save_state_memory\")\n\n            if dones[0]:\n                print(\"hit end!\")\n                break\n        return account_memory[0], actions_memory[0]\n\n    @staticmethod\n    def DRL_prediction_load_from_file(model_name, environment, cwd, deterministic=True):\n        if model_name not in MODELS:\n            raise ValueError(\n                f\"Model '{model_name}' not found in MODELS.\"\n            )  # this is more informative than NotImplementedError(\"NotImplementedError\")\n        try:\n            # load agent\n            model = MODELS[model_name].load(cwd)\n            print(\"Successfully load model\", cwd)\n        except BaseException as error:\n            raise ValueError(f\"Failed to load agent. Error: {str(error)}\") from error\n\n        # test on the testing env\n        state = environment.reset()\n        episode_returns = []  # the cumulative_return / initial_account\n        episode_total_assets = [environment.initial_total_asset]\n        done = False\n        while not done:\n            action = model.predict(state, deterministic=deterministic)[0]\n            state, reward, done, _ = environment.step(action)\n\n            total_asset = (\n                environment.amount\n                + (environment.price_ary[environment.day] * environment.stocks).sum()\n            )\n            episode_total_assets.append(total_asset)\n            episode_return = total_asset / environment.initial_total_asset\n            episode_returns.append(episode_return)\n\n        print(\"episode_return\", episode_return)\n        print(\"Test Finished!\")\n        return episode_total_assets\n\n\nclass DRLEnsembleAgent:\n    @staticmethod\n    def get_model(\n        model_name,\n        env,\n        policy=\"MlpPolicy\",\n        policy_kwargs=None,\n        model_kwargs=None,\n        seed=None,\n        verbose=1,\n    ):\n        if model_name not in MODELS:\n            raise ValueError(\n                f\"Model '{model_name}' not found in MODELS.\"\n            )  # this is more informative than NotImplementedError(\"NotImplementedError\")\n\n        if model_kwargs is None:\n            temp_model_kwargs = MODEL_KWARGS[model_name]\n        else:\n            temp_model_kwargs = model_kwargs.copy()\n\n        if \"action_noise\" in temp_model_kwargs:\n            n_actions = env.action_space.shape[-1]\n            temp_model_kwargs[\"action_noise\"] = NOISE[\n                temp_model_kwargs[\"action_noise\"]\n            ](mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n        print(temp_model_kwargs)\n        return MODELS[model_name](\n            policy=policy,\n            env=env,\n            tensorboard_log=f\"{config.TENSORBOARD_LOG_DIR}/{model_name}\",\n            verbose=verbose,\n            policy_kwargs=policy_kwargs,\n            seed=seed,\n            **temp_model_kwargs,\n        )\n\n    @staticmethod\n    def train_model(\n        model,\n        model_name,\n        tb_log_name,\n        iter_num,\n        total_timesteps=5000,\n        callbacks: Type[BaseCallback] = None,\n    ):\n        model = model.learn(\n            total_timesteps=total_timesteps,\n            tb_log_name=tb_log_name,\n            callback=(\n                CallbackList(\n                    [TensorboardCallback()] + [callback for callback in callbacks]\n                )\n                if callbacks is not None\n                else TensorboardCallback()\n            ),\n        )\n        model.save(\n            f\"{config.TRAINED_MODEL_DIR}/{model_name.upper()}_{total_timesteps // 1000}k_{iter_num}\"\n        )\n        return model\n\n    @staticmethod\n    def get_validation_sharpe(iteration, model_name):\n        \"\"\"Calculate Sharpe ratio based on validation results\"\"\"\n        df_total_value = pd.read_csv(\n            f\"results/account_value_validation_{model_name}_{iteration}.csv\"\n        )\n        # If the agent did not make any transaction\n        if df_total_value[\"daily_return\"].var() == 0:\n            if df_total_value[\"daily_return\"].mean() > 0:\n                return np.inf\n            else:\n                return 0.0\n        else:\n            return (\n                (4**0.5)\n                * df_total_value[\"daily_return\"].mean()\n                / df_total_value[\"daily_return\"].std()\n            )\n\n    def __init__(\n        self,\n        df,\n        train_period,\n        val_test_period,\n        rebalance_window,\n        validation_window,\n        stock_dim,\n        hmax,\n        initial_amount,\n        buy_cost_pct,\n        sell_cost_pct,\n        reward_scaling,\n        state_space,\n        action_space,\n        tech_indicator_list,\n        print_verbosity,\n    ):\n        self.df = df\n        self.train_period = train_period\n        self.val_test_period = val_test_period\n\n        self.unique_trade_date = df[\n            (df.date > val_test_period[0]) & (df.date <= val_test_period[1])\n        ].date.unique()\n        self.rebalance_window = rebalance_window\n        self.validation_window = validation_window\n\n        self.stock_dim = stock_dim\n        self.hmax = hmax\n        self.initial_amount = initial_amount\n        self.buy_cost_pct = buy_cost_pct\n        self.sell_cost_pct = sell_cost_pct\n        self.reward_scaling = reward_scaling\n        self.state_space = state_space\n        self.action_space = action_space\n        self.tech_indicator_list = tech_indicator_list\n        self.print_verbosity = print_verbosity\n        self.train_env = None  # defined in train_validation() function\n\n    def DRL_validation(self, model, test_data, test_env, test_obs):\n        \"\"\"validation process\"\"\"\n        for _ in range(len(test_data.index.unique())):\n            action, _states = model.predict(test_obs)\n            test_obs, rewards, dones, info = test_env.step(action)\n\n    def DRL_prediction(\n        self, model, name, last_state, iter_num, turbulence_threshold, initial\n    ):\n        \"\"\"make a prediction based on trained model\"\"\"\n\n        # trading env\n        trade_data = data_split(\n            self.df,\n            start=self.unique_trade_date[iter_num - self.rebalance_window],\n            end=self.unique_trade_date[iter_num],\n        )\n        trade_env = DummyVecEnv(\n            [\n                lambda: StockTradingEnv(\n                    df=trade_data,\n                    stock_dim=self.stock_dim,\n                    hmax=self.hmax,\n                    initial_amount=self.initial_amount,\n                    num_stock_shares=[0] * self.stock_dim,\n                    buy_cost_pct=[self.buy_cost_pct] * self.stock_dim,\n                    sell_cost_pct=[self.sell_cost_pct] * self.stock_dim,\n                    reward_scaling=self.reward_scaling,\n                    state_space=self.state_space,\n                    action_space=self.action_space,\n                    tech_indicator_list=self.tech_indicator_list,\n                    turbulence_threshold=turbulence_threshold,\n                    initial=initial,\n                    previous_state=last_state,\n                    model_name=name,\n                    mode=\"trade\",\n                    iteration=iter_num,\n                    print_verbosity=self.print_verbosity,\n                )\n            ]\n        )\n\n        trade_obs = trade_env.reset()\n\n        for i in range(len(trade_data.index.unique())):\n            action, _states = model.predict(trade_obs)\n            trade_obs, rewards, dones, info = trade_env.step(action)\n            if i == (len(trade_data.index.unique()) - 2):\n                # print(env_test.render())\n                last_state = trade_env.envs[0].render()\n\n        df_last_state = pd.DataFrame({\"last_state\": last_state})\n        df_last_state.to_csv(f\"results/last_state_{name}_{i}.csv\", index=False)\n        return last_state\n\n    def _train_window(\n        self,\n        model_name,\n        model_kwargs,\n        sharpe_list,\n        validation_start_date,\n        validation_end_date,\n        timesteps_dict,\n        i,\n        validation,\n        turbulence_threshold,\n    ):\n        \"\"\"\n        Train the model for a single window.\n        \"\"\"\n        if model_kwargs is None:\n            return None, sharpe_list, -1\n\n        print(f\"======{model_name} Training========\")\n        model = self.get_model(\n            model_name, self.train_env, policy=\"MlpPolicy\", model_kwargs=model_kwargs\n        )\n        model = self.train_model(\n            model,\n            model_name,\n            tb_log_name=f\"{model_name}_{i}\",\n            iter_num=i,\n            total_timesteps=timesteps_dict[model_name],\n        )  # 100_000\n        print(\n            f\"======{model_name} Validation from: \",\n            validation_start_date,\n            \"to \",\n            validation_end_date,\n        )\n        val_env = DummyVecEnv(\n            [\n                lambda: StockTradingEnv(\n                    df=validation,\n                    stock_dim=self.stock_dim,\n                    hmax=self.hmax,\n                    initial_amount=self.initial_amount,\n                    num_stock_shares=[0] * self.stock_dim,\n                    buy_cost_pct=[self.buy_cost_pct] * self.stock_dim,\n                    sell_cost_pct=[self.sell_cost_pct] * self.stock_dim,\n                    reward_scaling=self.reward_scaling,\n                    state_space=self.state_space,\n                    action_space=self.action_space,\n                    tech_indicator_list=self.tech_indicator_list,\n                    turbulence_threshold=turbulence_threshold,\n                    iteration=i,\n                    model_name=model_name,\n                    mode=\"validation\",\n                    print_verbosity=self.print_verbosity,\n                )\n            ]\n        )\n        val_obs = val_env.reset()\n        self.DRL_validation(\n            model=model,\n            test_data=validation,\n            test_env=val_env,\n            test_obs=val_obs,\n        )\n        sharpe = self.get_validation_sharpe(i, model_name=model_name)\n        print(f\"{model_name} Sharpe Ratio: \", sharpe)\n        sharpe_list.append(sharpe)\n        return model, sharpe_list, sharpe\n\n    def run_ensemble_strategy(\n        self,\n        A2C_model_kwargs,\n        PPO_model_kwargs,\n        DDPG_model_kwargs,\n        SAC_model_kwargs,\n        TD3_model_kwargs,\n        timesteps_dict,\n    ):\n        # Model Parameters\n        kwargs = {\n            \"a2c\": A2C_model_kwargs,\n            \"ppo\": PPO_model_kwargs,\n            \"ddpg\": DDPG_model_kwargs,\n            \"sac\": SAC_model_kwargs,\n            \"td3\": TD3_model_kwargs,\n        }\n        # Model Sharpe Ratios\n        model_dct = {k: {\"sharpe_list\": [], \"sharpe\": -1} for k in MODELS.keys()}\n\n        \"\"\"Ensemble Strategy that combines A2C, PPO, DDPG, SAC, and TD3\"\"\"\n        print(\"============Start Ensemble Strategy============\")\n        # for ensemble model, it's necessary to feed the last state\n        # of the previous model to the current model as the initial state\n        last_state_ensemble = []\n\n        model_use = []\n        validation_start_date_list = []\n        validation_end_date_list = []\n        iteration_list = []\n\n        insample_turbulence = self.df[\n            (self.df.date < self.train_period[1])\n            & (self.df.date >= self.train_period[0])\n        ]\n        insample_turbulence_threshold = np.quantile(\n            insample_turbulence.turbulence.values, 0.90\n        )\n\n        start = time.time()\n        for i in range(\n            self.rebalance_window + self.validation_window,\n            len(self.unique_trade_date),\n            self.rebalance_window,\n        ):\n            validation_start_date = self.unique_trade_date[\n                i - self.rebalance_window - self.validation_window\n            ]\n            validation_end_date = self.unique_trade_date[i - self.rebalance_window]\n\n            validation_start_date_list.append(validation_start_date)\n            validation_end_date_list.append(validation_end_date)\n            iteration_list.append(i)\n\n            print(\"============================================\")\n            # initial state is empty\n            if i - self.rebalance_window - self.validation_window == 0:\n                # inital state\n                initial = True\n            else:\n                # previous state\n                initial = False\n\n            # Tuning trubulence index based on historical data\n            # Turbulence lookback window is one quarter (63 days)\n            end_date_index = self.df.index[\n                self.df[\"date\"]\n                == self.unique_trade_date[\n                    i - self.rebalance_window - self.validation_window\n                ]\n            ].to_list()[-1]\n            start_date_index = end_date_index - 63 + 1\n\n            historical_turbulence = self.df.iloc[\n                start_date_index : (end_date_index + 1), :\n            ]\n\n            historical_turbulence = historical_turbulence.drop_duplicates(\n                subset=[\"date\"]\n            )\n\n            historical_turbulence_mean = np.mean(\n                historical_turbulence.turbulence.values\n            )\n\n            # print(historical_turbulence_mean)\n\n            if historical_turbulence_mean > insample_turbulence_threshold:\n                # if the mean of the historical data is greater than the 90% quantile of insample turbulence data\n                # then we assume that the current market is volatile,\n                # therefore we set the 90% quantile of insample turbulence data as the turbulence threshold\n                # meaning the current turbulence can't exceed the 90% quantile of insample turbulence data\n                turbulence_threshold = insample_turbulence_threshold\n            else:\n                # if the mean of the historical data is less than the 90% quantile of insample turbulence data\n                # then we tune up the turbulence_threshold, meaning we lower the risk\n                turbulence_threshold = np.quantile(\n                    insample_turbulence.turbulence.values, 1\n                )\n\n            turbulence_threshold = np.quantile(\n                insample_turbulence.turbulence.values, 0.99\n            )\n            print(\"turbulence_threshold: \", turbulence_threshold)\n\n            # Environment Setup starts\n            # training env\n            train = data_split(\n                self.df,\n                start=self.train_period[0],\n                end=self.unique_trade_date[\n                    i - self.rebalance_window - self.validation_window\n                ],\n            )\n            self.train_env = DummyVecEnv(\n                [\n                    lambda: StockTradingEnv(\n                        df=train,\n                        stock_dim=self.stock_dim,\n                        hmax=self.hmax,\n                        initial_amount=self.initial_amount,\n                        num_stock_shares=[0] * self.stock_dim,\n                        buy_cost_pct=[self.buy_cost_pct] * self.stock_dim,\n                        sell_cost_pct=[self.sell_cost_pct] * self.stock_dim,\n                        reward_scaling=self.reward_scaling,\n                        state_space=self.state_space,\n                        action_space=self.action_space,\n                        tech_indicator_list=self.tech_indicator_list,\n                        print_verbosity=self.print_verbosity,\n                    )\n                ]\n            )\n\n            validation = data_split(\n                self.df,\n                start=self.unique_trade_date[\n                    i - self.rebalance_window - self.validation_window\n                ],\n                end=self.unique_trade_date[i - self.rebalance_window],\n            )\n            # Environment Setup ends\n\n            # Training and Validation starts\n            print(\n                \"======Model training from: \",\n                self.train_period[0],\n                \"to \",\n                self.unique_trade_date[\n                    i - self.rebalance_window - self.validation_window\n                ],\n            )\n            # print(\"training: \",len(data_split(df, start=20090000, end=test.datadate.unique()[i-rebalance_window]) ))\n            # print(\"==============Model Training===========\")\n            # Train Each Model\n            for model_name in MODELS.keys():\n                # Train The Model\n                model, sharpe_list, sharpe = self._train_window(\n                    model_name,\n                    kwargs[model_name],\n                    model_dct[model_name][\"sharpe_list\"],\n                    validation_start_date,\n                    validation_end_date,\n                    timesteps_dict,\n                    i,\n                    validation,\n                    turbulence_threshold,\n                )\n                # Save the model's sharpe ratios, and the model itself\n                model_dct[model_name][\"sharpe_list\"] = sharpe_list\n                model_dct[model_name][\"model\"] = model\n                model_dct[model_name][\"sharpe\"] = sharpe\n\n            print(\n                \"======Best Model Retraining from: \",\n                self.train_period[0],\n                \"to \",\n                self.unique_trade_date[i - self.rebalance_window],\n            )\n            # Environment setup for model retraining up to first trade date\n            # train_full = data_split(self.df, start=self.train_period[0],\n            # end=self.unique_trade_date[i - self.rebalance_window])\n            # self.train_full_env = DummyVecEnv([lambda: StockTradingEnv(train_full,\n            #                                               self.stock_dim,\n            #                                               self.hmax,\n            #                                               self.initial_amount,\n            #                                               self.buy_cost_pct,\n            #                                               self.sell_cost_pct,\n            #                                               self.reward_scaling,\n            #                                               self.state_space,\n            #                                               self.action_space,\n            #                                               self.tech_indicator_list,\n            #                                              print_verbosity=self.print_verbosity\n            # )])\n            # Model Selection based on sharpe ratio\n            # Same order as MODELS: {\"a2c\": A2C, \"ddpg\": DDPG, \"td3\": TD3, \"sac\": SAC, \"ppo\": PPO}\n            sharpes = [model_dct[k][\"sharpe\"] for k in MODELS.keys()]\n            # Find the model with the highest sharpe ratio\n            max_mod = list(MODELS.keys())[np.argmax(sharpes)]\n            model_use.append(max_mod.upper())\n            model_ensemble = model_dct[max_mod][\"model\"]\n            # Training and Validation ends\n\n            # Trading starts\n            print(\n                \"======Trading from: \",\n                self.unique_trade_date[i - self.rebalance_window],\n                \"to \",\n                self.unique_trade_date[i],\n            )\n            # print(\"Used Model: \", model_ensemble)\n            last_state_ensemble = self.DRL_prediction(\n                model=model_ensemble,\n                name=\"ensemble\",\n                last_state=last_state_ensemble,\n                iter_num=i,\n                turbulence_threshold=turbulence_threshold,\n                initial=initial,\n            )\n            # Trading ends\n\n        end = time.time()\n        print(\"Ensemble Strategy took: \", (end - start) / 60, \" minutes\")\n\n        df_summary = pd.DataFrame(\n            [\n                iteration_list,\n                validation_start_date_list,\n                validation_end_date_list,\n                model_use,\n                model_dct[\"a2c\"][\"sharpe_list\"],\n                model_dct[\"ppo\"][\"sharpe_list\"],\n                model_dct[\"ddpg\"][\"sharpe_list\"],\n                model_dct[\"sac\"][\"sharpe_list\"],\n                model_dct[\"td3\"][\"sharpe_list\"],\n            ]\n        ).T\n        df_summary.columns = [\n            \"Iter\",\n            \"Val Start\",\n            \"Val End\",\n            \"Model Used\",\n            \"A2C Sharpe\",\n            \"PPO Sharpe\",\n            \"DDPG Sharpe\",\n            \"SAC Sharpe\",\n            \"TD3 Sharpe\",\n        ]\n\n        return df_summary\n"
        },
        {
          "path": "finrl/meta/env_stock_trading/env_stocktrading.py",
          "url": "https://github.com/AI4Finance-Foundation/FinRL/blob/master/finrl/meta/env_stock_trading/env_stocktrading.py",
          "lines": "1-567",
          "code": "from __future__ import annotations\n\nfrom typing import List\n\nimport gymnasium as gym\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom gymnasium import spaces\nfrom gymnasium.utils import seeding\nfrom stable_baselines3.common.vec_env import DummyVecEnv\n\nmatplotlib.use(\"Agg\")\n\n# from stable_baselines3.common.logger import Logger, KVWriter, CSVOutputFormat\n\n\nclass StockTradingEnv(gym.Env):\n    \"\"\"\n    A stock trading environment for OpenAI gym\n\n    Parameters:\n        df (pandas.DataFrame): Dataframe containing data\n        hmax (int): Maximum cash to be traded in each trade per asset.\n        initial_amount (int): Amount of cash initially available\n        buy_cost_pct (float, array): Cost for buying shares, each index corresponds to each asset\n        sell_cost_pct (float, array): Cost for selling shares, each index corresponds to each asset\n        turbulence_threshold (float): Maximum turbulence allowed in market for purchases to occur. If exceeded, positions are liquidated\n        print_verbosity(int): When iterating (step), how often to print stats about state of env\n    \"\"\"\n\n    metadata = {\"render.modes\": [\"human\"]}\n\n    def __init__(\n        self,\n        df: pd.DataFrame,\n        stock_dim: int,\n        hmax: int,\n        initial_amount: int,\n        num_stock_shares: list[int],\n        buy_cost_pct: list[float],\n        sell_cost_pct: list[float],\n        reward_scaling: float,\n        state_space: int,\n        action_space: int,\n        tech_indicator_list: list[str],\n        turbulence_threshold=None,\n        risk_indicator_col=\"turbulence\",\n        make_plots: bool = False,\n        print_verbosity=10,\n        day=0,\n        initial=True,\n        previous_state=[],\n        model_name=\"\",\n        mode=\"\",\n        iteration=\"\",\n    ):\n        self.day = day\n        self.df = df\n        self.stock_dim = stock_dim\n        self.hmax = hmax\n        self.num_stock_shares = num_stock_shares\n        self.initial_amount = initial_amount  # get the initial cash\n        self.buy_cost_pct = buy_cost_pct\n        self.sell_cost_pct = sell_cost_pct\n        self.reward_scaling = reward_scaling\n        self.state_space = state_space\n        self.action_space = action_space\n        self.tech_indicator_list = tech_indicator_list\n        self.action_space = spaces.Box(low=-1, high=1, shape=(self.action_space,))\n        self.observation_space = spaces.Box(\n            low=-np.inf, high=np.inf, shape=(self.state_space,)\n        )\n        self.data = self.df.loc[self.day, :]\n        self.terminal = False\n        self.make_plots = make_plots\n        self.print_verbosity = print_verbosity\n        self.turbulence_threshold = turbulence_threshold\n        self.risk_indicator_col = risk_indicator_col\n        self.initial = initial\n        self.previous_state = previous_state\n        self.model_name = model_name\n        self.mode = mode\n        self.iteration = iteration\n        # initalize state\n        self.state = self._initiate_state()\n\n        # initialize reward\n        self.reward = 0\n        self.turbulence = 0\n        self.cost = 0\n        self.trades = 0\n        self.episode = 0\n        # memorize all the total balance change\n        self.asset_memory = [\n            self.initial_amount\n            + np.sum(\n                np.array(self.num_stock_shares)\n                * np.array(self.state[1 : 1 + self.stock_dim])\n            )\n        ]  # the initial total asset is calculated by cash + sum (num_share_stock_i * price_stock_i)\n        self.rewards_memory = []\n        self.actions_memory = []\n        self.state_memory = (\n            []\n        )  # we need sometimes to preserve the state in the middle of trading process\n        self.date_memory = [self._get_date()]\n        #         self.logger = Logger('results',[CSVOutputFormat])\n        # self.reset()\n        self._seed()\n\n    def _sell_stock(self, index, action):\n        def _do_sell_normal():\n            if (\n                self.state[index + 2 * self.stock_dim + 1] != True\n            ):  # check if the stock is able to sell, for simlicity we just add it in techical index\n                # if self.state[index + 1] > 0: # if we use price<0 to denote a stock is unable to trade in that day, the total asset calculation may be wrong for the price is unreasonable\n                # Sell only if the price is > 0 (no missing data in this particular date)\n                # perform sell action based on the sign of the action\n                if self.state[index + self.stock_dim + 1] > 0:\n                    # Sell only if current asset is > 0\n                    sell_num_shares = min(\n                        abs(action), self.state[index + self.stock_dim + 1]\n                    )\n                    sell_amount = (\n                        self.state[index + 1]\n                        * sell_num_shares\n                        * (1 - self.sell_cost_pct[index])\n                    )\n                    # update balance\n                    self.state[0] += sell_amount\n\n                    self.state[index + self.stock_dim + 1] -= sell_num_shares\n                    self.cost += (\n                        self.state[index + 1]\n                        * sell_num_shares\n                        * self.sell_cost_pct[index]\n                    )\n                    self.trades += 1\n                else:\n                    sell_num_shares = 0\n            else:\n                sell_num_shares = 0\n\n            return sell_num_shares\n\n        # perform sell action based on the sign of the action\n        if self.turbulence_threshold is not None:\n            if self.turbulence >= self.turbulence_threshold:\n                if self.state[index + 1] > 0:\n                    # Sell only if the price is > 0 (no missing data in this particular date)\n                    # if turbulence goes over threshold, just clear out all positions\n                    if self.state[index + self.stock_dim + 1] > 0:\n                        # Sell only if current asset is > 0\n                        sell_num_shares = self.state[index + self.stock_dim + 1]\n                        sell_amount = (\n                            self.state[index + 1]\n                            * sell_num_shares\n                            * (1 - self.sell_cost_pct[index])\n                        )\n                        # update balance\n                        self.state[0] += sell_amount\n                        self.state[index + self.stock_dim + 1] = 0\n                        self.cost += (\n                            self.state[index + 1]\n                            * sell_num_shares\n                            * self.sell_cost_pct[index]\n                        )\n                        self.trades += 1\n                    else:\n                        sell_num_shares = 0\n                else:\n                    sell_num_shares = 0\n            else:\n                sell_num_shares = _do_sell_normal()\n        else:\n            sell_num_shares = _do_sell_normal()\n\n        return sell_num_shares\n\n    def _buy_stock(self, index, action):\n        def _do_buy():\n            if (\n                self.state[index + 2 * self.stock_dim + 1] != True\n            ):  # check if the stock is able to buy\n                # if self.state[index + 1] >0:\n                # Buy only if the price is > 0 (no missing data in this particular date)\n                available_amount = self.state[0] // (\n                    self.state[index + 1] * (1 + self.buy_cost_pct[index])\n                )  # when buying stocks, we should consider the cost of trading when calculating available_amount, or we may be have cash<0\n                # print('available_amount:{}'.format(available_amount))\n\n                # update balance\n                buy_num_shares = min(available_amount, action)\n                buy_amount = (\n                    self.state[index + 1]\n                    * buy_num_shares\n                    * (1 + self.buy_cost_pct[index])\n                )\n                self.state[0] -= buy_amount\n\n                self.state[index + self.stock_dim + 1] += buy_num_shares\n\n                self.cost += (\n                    self.state[index + 1] * buy_num_shares * self.buy_cost_pct[index]\n                )\n                self.trades += 1\n            else:\n                buy_num_shares = 0\n\n            return buy_num_shares\n\n        # perform buy action based on the sign of the action\n        if self.turbulence_threshold is None:\n            buy_num_shares = _do_buy()\n        else:\n            if self.turbulence < self.turbulence_threshold:\n                buy_num_shares = _do_buy()\n            else:\n                buy_num_shares = 0\n                pass\n\n        return buy_num_shares\n\n    def _make_plot(self):\n        plt.plot(self.asset_memory, \"r\")\n        plt.savefig(f\"results/account_value_trade_{self.episode}.png\")\n        plt.close()\n\n    def step(self, actions):\n        self.terminal = self.day >= len(self.df.index.unique()) - 1\n        if self.terminal:\n            # print(f\"Episode: {self.episode}\")\n            if self.make_plots:\n                self._make_plot()\n            end_total_asset = self.state[0] + sum(\n                np.array(self.state[1 : (self.stock_dim + 1)])\n                * np.array(self.state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)])\n            )\n            df_total_value = pd.DataFrame(self.asset_memory)\n            tot_reward = (\n                self.state[0]\n                + sum(\n                    np.array(self.state[1 : (self.stock_dim + 1)])\n                    * np.array(\n                        self.state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)]\n                    )\n                )\n                - self.asset_memory[0]\n            )  # initial_amount is only cash part of our initial asset\n            df_total_value.columns = [\"account_value\"]\n            df_total_value[\"date\"] = self.date_memory\n            df_total_value[\"daily_return\"] = df_total_value[\"account_value\"].pct_change(\n                1\n            )\n            if df_total_value[\"daily_return\"].std() != 0:\n                sharpe = (\n                    (252**0.5)\n                    * df_total_value[\"daily_return\"].mean()\n                    / df_total_value[\"daily_return\"].std()\n                )\n            df_rewards = pd.DataFrame(self.rewards_memory)\n            df_rewards.columns = [\"account_rewards\"]\n            df_rewards[\"date\"] = self.date_memory[:-1]\n            if self.episode % self.print_verbosity == 0:\n                print(f\"day: {self.day}, episode: {self.episode}\")\n                print(f\"begin_total_asset: {self.asset_memory[0]:0.2f}\")\n                print(f\"end_total_asset: {end_total_asset:0.2f}\")\n                print(f\"total_reward: {tot_reward:0.2f}\")\n                print(f\"total_cost: {self.cost:0.2f}\")\n                print(f\"total_trades: {self.trades}\")\n                if df_total_value[\"daily_return\"].std() != 0:\n                    print(f\"Sharpe: {sharpe:0.3f}\")\n                print(\"=================================\")\n\n            if (self.model_name != \"\") and (self.mode != \"\"):\n                df_actions = self.save_action_memory()\n                df_actions.to_csv(\n                    \"results/actions_{}_{}_{}.csv\".format(\n                        self.mode, self.model_name, self.iteration\n                    )\n                )\n                df_total_value.to_csv(\n                    \"results/account_value_{}_{}_{}.csv\".format(\n                        self.mode, self.model_name, self.iteration\n                    ),\n                    index=False,\n                )\n                df_rewards.to_csv(\n                    \"results/account_rewards_{}_{}_{}.csv\".format(\n                        self.mode, self.model_name, self.iteration\n                    ),\n                    index=False,\n                )\n                plt.plot(self.asset_memory, \"r\")\n                plt.savefig(\n                    \"results/account_value_{}_{}_{}.png\".format(\n                        self.mode, self.model_name, self.iteration\n                    )\n                )\n                plt.close()\n\n            # Add outputs to logger interface\n            # logger.record(\"environment/portfolio_value\", end_total_asset)\n            # logger.record(\"environment/total_reward\", tot_reward)\n            # logger.record(\"environment/total_reward_pct\", (tot_reward / (end_total_asset - tot_reward)) * 100)\n            # logger.record(\"environment/total_cost\", self.cost)\n            # logger.record(\"environment/total_trades\", self.trades)\n\n            return self.state, self.reward, self.terminal, False, {}\n\n        else:\n            actions = actions * self.hmax  # actions initially is scaled between 0 to 1\n            actions = actions.astype(\n                int\n            )  # convert into integer because we can't by fraction of shares\n            if self.turbulence_threshold is not None:\n                if self.turbulence >= self.turbulence_threshold:\n                    actions = np.array([-self.hmax] * self.stock_dim)\n            begin_total_asset = self.state[0] + sum(\n                np.array(self.state[1 : (self.stock_dim + 1)])\n                * np.array(self.state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)])\n            )\n            # print(\"begin_total_asset:{}\".format(begin_total_asset))\n\n            argsort_actions = np.argsort(actions)\n            sell_index = argsort_actions[: np.where(actions < 0)[0].shape[0]]\n            buy_index = argsort_actions[::-1][: np.where(actions > 0)[0].shape[0]]\n\n            for index in sell_index:\n                # print(f\"Num shares before: {self.state[index+self.stock_dim+1]}\")\n                # print(f'take sell action before : {actions[index]}')\n                actions[index] = self._sell_stock(index, actions[index]) * (-1)\n                # print(f'take sell action after : {actions[index]}')\n                # print(f\"Num shares after: {self.state[index+self.stock_dim+1]}\")\n\n            for index in buy_index:\n                # print('take buy action: {}'.format(actions[index]))\n                actions[index] = self._buy_stock(index, actions[index])\n\n            self.actions_memory.append(actions)\n\n            # state: s -> s+1\n            self.day += 1\n            self.data = self.df.loc[self.day, :]\n            if self.turbulence_threshold is not None:\n                if len(self.df.tic.unique()) == 1:\n                    self.turbulence = self.data[self.risk_indicator_col]\n                elif len(self.df.tic.unique()) > 1:\n                    self.turbulence = self.data[self.risk_indicator_col].values[0]\n            self.state = self._update_state()\n\n            end_total_asset = self.state[0] + sum(\n                np.array(self.state[1 : (self.stock_dim + 1)])\n                * np.array(self.state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)])\n            )\n            self.asset_memory.append(end_total_asset)\n            self.date_memory.append(self._get_date())\n            self.reward = end_total_asset - begin_total_asset\n            self.rewards_memory.append(self.reward)\n            self.reward = self.reward * self.reward_scaling\n            self.state_memory.append(\n                self.state\n            )  # add current state in state_recorder for each step\n\n        return self.state, self.reward, self.terminal, False, {}\n\n    def reset(\n        self,\n        *,\n        seed=None,\n        options=None,\n    ):\n        # initiate state\n        self.day = 0\n        self.data = self.df.loc[self.day, :]\n        self.state = self._initiate_state()\n\n        if self.initial:\n            self.asset_memory = [\n                self.initial_amount\n                + np.sum(\n                    np.array(self.num_stock_shares)\n                    * np.array(self.state[1 : 1 + self.stock_dim])\n                )\n            ]\n        else:\n            previous_total_asset = self.previous_state[0] + sum(\n                np.array(self.state[1 : (self.stock_dim + 1)])\n                * np.array(\n                    self.previous_state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)]\n                )\n            )\n            self.asset_memory = [previous_total_asset]\n\n        self.turbulence = 0\n        self.cost = 0\n        self.trades = 0\n        self.terminal = False\n        # self.iteration=self.iteration\n        self.rewards_memory = []\n        self.actions_memory = []\n        self.date_memory = [self._get_date()]\n\n        self.episode += 1\n\n        return self.state, {}\n\n    def render(self, mode=\"human\", close=False):\n        return self.state\n\n    def _initiate_state(self):\n        if self.initial:\n            # For Initial State\n            if len(self.df.tic.unique()) > 1:\n                # for multiple stock\n                state = (\n                    [self.initial_amount]\n                    + self.data.close.values.tolist()\n                    + self.num_stock_shares\n                    + sum(\n                        (\n                            self.data[tech].values.tolist()\n                            for tech in self.tech_indicator_list\n                        ),\n                        [],\n                    )\n                )  # append initial stocks_share to initial state, instead of all zero\n            else:\n                # for single stock\n                state = (\n                    [self.initial_amount]\n                    + [self.data.close]\n                    + [0] * self.stock_dim\n                    + sum(([self.data[tech]] for tech in self.tech_indicator_list), [])\n                )\n        else:\n            # Using Previous State\n            if len(self.df.tic.unique()) > 1:\n                # for multiple stock\n                state = (\n                    [self.previous_state[0]]\n                    + self.data.close.values.tolist()\n                    + self.previous_state[\n                        (self.stock_dim + 1) : (self.stock_dim * 2 + 1)\n                    ]\n                    + sum(\n                        (\n                            self.data[tech].values.tolist()\n                            for tech in self.tech_indicator_list\n                        ),\n                        [],\n                    )\n                )\n            else:\n                # for single stock\n                state = (\n                    [self.previous_state[0]]\n                    + [self.data.close]\n                    + self.previous_state[\n                        (self.stock_dim + 1) : (self.stock_dim * 2 + 1)\n                    ]\n                    + sum(([self.data[tech]] for tech in self.tech_indicator_list), [])\n                )\n        return state\n\n    def _update_state(self):\n        if len(self.df.tic.unique()) > 1:\n            # for multiple stock\n            state = (\n                [self.state[0]]\n                + self.data.close.values.tolist()\n                + list(self.state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)])\n                + sum(\n                    (\n                        self.data[tech].values.tolist()\n                        for tech in self.tech_indicator_list\n                    ),\n                    [],\n                )\n            )\n\n        else:\n            # for single stock\n            state = (\n                [self.state[0]]\n                + [self.data.close]\n                + list(self.state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)])\n                + sum(([self.data[tech]] for tech in self.tech_indicator_list), [])\n            )\n\n        return state\n\n    def _get_date(self):\n        if len(self.df.tic.unique()) > 1:\n            date = self.data.date.unique()[0]\n        else:\n            date = self.data.date\n        return date\n\n    # add save_state_memory to preserve state in the trading process\n    def save_state_memory(self):\n        if len(self.df.tic.unique()) > 1:\n            # date and close price length must match actions length\n            date_list = self.date_memory[:-1]\n            df_date = pd.DataFrame(date_list)\n            df_date.columns = [\"date\"]\n\n            state_list = self.state_memory\n            df_states = pd.DataFrame(\n                state_list,\n                columns=[\n                    \"cash\",\n                    \"Bitcoin_price\",\n                    \"Gold_price\",\n                    \"Bitcoin_num\",\n                    \"Gold_num\",\n                    \"Bitcoin_Disable\",\n                    \"Gold_Disable\",\n                ],\n            )\n            df_states.index = df_date.date\n            # df_actions = pd.DataFrame({'date':date_list,'actions':action_list})\n        else:\n            date_list = self.date_memory[:-1]\n            state_list = self.state_memory\n            df_states = pd.DataFrame({\"date\": date_list, \"states\": state_list})\n        # print(df_states)\n        return df_states\n\n    def save_asset_memory(self):\n        date_list = self.date_memory\n        asset_list = self.asset_memory\n        # print(len(date_list))\n        # print(len(asset_list))\n        df_account_value = pd.DataFrame(\n            {\"date\": date_list, \"account_value\": asset_list}\n        )\n        return df_account_value\n\n    def save_action_memory(self):\n        if len(self.df.tic.unique()) > 1:\n            # date and close price length must match actions length\n            date_list = self.date_memory[:-1]\n            df_date = pd.DataFrame(date_list)\n            df_date.columns = [\"date\"]\n\n            action_list = self.actions_memory\n            df_actions = pd.DataFrame(action_list)\n            df_actions.columns = self.data.tic.values\n            df_actions.index = df_date.date\n            # df_actions = pd.DataFrame({'date':date_list,'actions':action_list})\n        else:\n            date_list = self.date_memory[:-1]\n            action_list = self.actions_memory\n            df_actions = pd.DataFrame({\"date\": date_list, \"actions\": action_list})\n        return df_actions\n\n    def _seed(self, seed=None):\n        self.np_random, seed = seeding.np_random(seed)\n        return [seed]\n\n    def get_sb_env(self):\n        e = DummyVecEnv([lambda: self])\n        obs = e.reset()\n        return e, obs\n"
        },
        {
          "path": "finrl/meta/preprocessor/preprocessors.py",
          "url": "https://github.com/AI4Finance-Foundation/FinRL/blob/master/finrl/meta/preprocessor/preprocessors.py",
          "lines": "1-334",
          "code": "from __future__ import annotations\n\nimport datetime\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.base import BaseEstimator\nfrom sklearn.base import TransformerMixin\nfrom sklearn.preprocessing import MaxAbsScaler\nfrom stockstats import StockDataFrame as Sdf\n\nfrom finrl import config\nfrom finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n\n\ndef load_dataset(*, file_name: str) -> pd.DataFrame:\n    \"\"\"\n    load csv dataset from path\n    :return: (df) pandas dataframe\n    \"\"\"\n    # _data = pd.read_csv(f\"{config.DATASET_DIR}/{file_name}\")\n    _data = pd.read_csv(file_name)\n    return _data\n\n\ndef data_split(df, start, end, target_date_col=\"date\"):\n    \"\"\"\n    split the dataset into training or testing using date\n    :param data: (df) pandas dataframe, start, end\n    :return: (df) pandas dataframe\n    \"\"\"\n    data = df[(df[target_date_col] >= start) & (df[target_date_col] < end)]\n    data = data.sort_values([target_date_col, \"tic\"], ignore_index=True)\n    data.index = data[target_date_col].factorize()[0]\n    return data\n\n\ndef convert_to_datetime(time):\n    time_fmt = \"%Y-%m-%dT%H:%M:%S\"\n    if isinstance(time, str):\n        return datetime.datetime.strptime(time, time_fmt)\n\n\nclass GroupByScaler(BaseEstimator, TransformerMixin):\n    \"\"\"Sklearn-like scaler that scales considering groups of data.\n\n    In the financial setting, this scale can be used to normalize a DataFrame\n    with time series of multiple tickers. The scaler will fit and transform\n    data for each ticker independently.\n    \"\"\"\n\n    def __init__(self, by, scaler=MaxAbsScaler, columns=None, scaler_kwargs=None):\n        \"\"\"Initializes GoupBy scaler.\n\n        Args:\n            by: Name of column that will be used to group.\n            scaler: Scikit-learn scaler class to be used.\n            columns: List of columns that will be scaled.\n            scaler_kwargs: Keyword arguments for chosen scaler.\n        \"\"\"\n        self.scalers = {}  # dictionary with scalers\n        self.by = by\n        self.scaler = scaler\n        self.columns = columns\n        self.scaler_kwargs = {} if scaler_kwargs is None else scaler_kwargs\n\n    def fit(self, X, y=None):\n        \"\"\"Fits the scaler to input data.\n\n        Args:\n            X: DataFrame to fit.\n            y: Not used.\n\n        Returns:\n            Fitted GroupBy scaler.\n        \"\"\"\n        # if columns aren't specified, considered all numeric columns\n        if self.columns is None:\n            self.columns = X.select_dtypes(exclude=[\"object\"]).columns\n        # fit one scaler for each group\n        for value in X[self.by].unique():\n            X_group = X.loc[X[self.by] == value, self.columns]\n            self.scalers[value] = self.scaler(**self.scaler_kwargs).fit(X_group)\n        return self\n\n    def transform(self, X, y=None):\n        \"\"\"Transforms unscaled data.\n\n        Args:\n            X: DataFrame to transform.\n            y: Not used.\n\n        Returns:\n            Transformed DataFrame.\n        \"\"\"\n        # apply scaler for each group\n        X = X.copy()\n        for value in X[self.by].unique():\n            select_mask = X[self.by] == value\n            X.loc[select_mask, self.columns] = self.scalers[value].transform(\n                X.loc[select_mask, self.columns]\n            )\n        return X\n\n\nclass FeatureEngineer:\n    \"\"\"Provides methods for preprocessing the stock price data\n\n    Attributes\n    ----------\n        use_technical_indicator : boolean\n            we technical indicator or not\n        tech_indicator_list : list\n            a list of technical indicator names (modified from neofinrl_config.py)\n        use_turbulence : boolean\n            use turbulence index or not\n        user_defined_feature:boolean\n            use user defined features or not\n\n    Methods\n    -------\n    preprocess_data()\n        main method to do the feature engineering\n\n    \"\"\"\n\n    def __init__(\n        self,\n        use_technical_indicator=True,\n        tech_indicator_list=config.INDICATORS,\n        use_vix=False,\n        use_turbulence=False,\n        user_defined_feature=False,\n    ):\n        self.use_technical_indicator = use_technical_indicator\n        self.tech_indicator_list = tech_indicator_list\n        self.use_vix = use_vix\n        self.use_turbulence = use_turbulence\n        self.user_defined_feature = user_defined_feature\n\n    def preprocess_data(self, df):\n        \"\"\"main method to do the feature engineering\n        @:param config: source dataframe\n        @:return: a DataMatrices object\n        \"\"\"\n        # clean data\n        df = self.clean_data(df)\n\n        # add technical indicators using stockstats\n        if self.use_technical_indicator:\n            df = self.add_technical_indicator(df)\n            print(\"Successfully added technical indicators\")\n\n        # add vix for multiple stock\n        if self.use_vix:\n            df = self.add_vix(df)\n            print(\"Successfully added vix\")\n\n        # add turbulence index for multiple stock\n        if self.use_turbulence:\n            df = self.add_turbulence(df)\n            print(\"Successfully added turbulence index\")\n\n        # add user defined feature\n        if self.user_defined_feature:\n            df = self.add_user_defined_feature(df)\n            print(\"Successfully added user defined features\")\n\n        # fill the missing values at the beginning and the end\n        df = df.ffill().bfill()\n        return df\n\n    def clean_data(self, data):\n        \"\"\"\n        clean the raw data\n        deal with missing values\n        reasons: stocks could be delisted, not incorporated at the time step\n        :param data: (df) pandas dataframe\n        :return: (df) pandas dataframe\n        \"\"\"\n        df = data.copy()\n        df = df.sort_values([\"date\", \"tic\"], ignore_index=True)\n        df.index = df.date.factorize()[0]\n        merged_closes = df.pivot_table(index=\"date\", columns=\"tic\", values=\"close\")\n        merged_closes = merged_closes.dropna(axis=1)\n        tics = merged_closes.columns\n        df = df[df.tic.isin(tics)]\n        # df = data.copy()\n        # list_ticker = df[\"tic\"].unique().tolist()\n        # only apply to daily level data, need to fix for minute level\n        # list_date = list(pd.date_range(df['date'].min(),df['date'].max()).astype(str))\n        # combination = list(itertools.product(list_date,list_ticker))\n\n        # df_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(df,on=[\"date\",\"tic\"],how=\"left\")\n        # df_full = df_full[df_full['date'].isin(df['date'])]\n        # df_full = df_full.sort_values(['date','tic'])\n        # df_full = df_full.fillna(0)\n        return df\n\n    def add_technical_indicator(self, data):\n        \"\"\"\n        calculate technical indicators\n        use stockstats package to add technical inidactors\n        :param data: (df) pandas dataframe\n        :return: (df) pandas dataframe\n        \"\"\"\n        df = data.copy()\n        df = df.sort_values(by=[\"tic\", \"date\"])\n        stock = Sdf.retype(df.copy())\n        unique_ticker = stock.tic.unique()\n\n        for indicator in self.tech_indicator_list:\n            indicator_df = pd.DataFrame()\n            for i in range(len(unique_ticker)):\n                try:\n                    temp_indicator = stock[stock.tic == unique_ticker[i]][indicator]\n                    temp_indicator = pd.DataFrame(temp_indicator)\n                    temp_indicator[\"tic\"] = unique_ticker[i]\n                    temp_indicator[\"date\"] = df[df.tic == unique_ticker[i]][\n                        \"date\"\n                    ].to_list()\n                    # indicator_df = indicator_df.append(\n                    #     temp_indicator, ignore_index=True\n                    # )\n                    indicator_df = pd.concat(\n                        [indicator_df, temp_indicator], axis=0, ignore_index=True\n                    )\n                except Exception as e:\n                    print(e)\n            df = df.merge(\n                indicator_df[[\"tic\", \"date\", indicator]], on=[\"tic\", \"date\"], how=\"left\"\n            )\n        df = df.sort_values(by=[\"date\", \"tic\"])\n        return df\n        # df = data.set_index(['date','tic']).sort_index()\n        # df = df.join(df.groupby(level=0, group_keys=False).apply(lambda x, y: Sdf.retype(x)[y], y=self.tech_indicator_list))\n        # return df.reset_index()\n\n    def add_user_defined_feature(self, data):\n        \"\"\"\n         add user defined features\n        :param data: (df) pandas dataframe\n        :return: (df) pandas dataframe\n        \"\"\"\n        df = data.copy()\n        df[\"daily_return\"] = df.close.pct_change(1)\n        # df['return_lag_1']=df.close.pct_change(2)\n        # df['return_lag_2']=df.close.pct_change(3)\n        # df['return_lag_3']=df.close.pct_change(4)\n        # df['return_lag_4']=df.close.pct_change(5)\n        return df\n\n    def add_vix(self, data):\n        \"\"\"\n        add vix from yahoo finance\n        :param data: (df) pandas dataframe\n        :return: (df) pandas dataframe\n        \"\"\"\n        df = data.copy()\n        df_vix = YahooDownloader(\n            start_date=df.date.min(), end_date=df.date.max(), ticker_list=[\"^VIX\"]\n        ).fetch_data()\n        vix = df_vix[[\"date\", \"close\"]]\n        vix.columns = [\"date\", \"vix\"]\n\n        df = df.merge(vix, on=\"date\")\n        df = df.sort_values([\"date\", \"tic\"]).reset_index(drop=True)\n        return df\n\n    def add_turbulence(self, data):\n        \"\"\"\n        add turbulence index from a precalcualted dataframe\n        :param data: (df) pandas dataframe\n        :return: (df) pandas dataframe\n        \"\"\"\n        df = data.copy()\n        turbulence_index = self.calculate_turbulence(df)\n        df = df.merge(turbulence_index, on=\"date\")\n        df = df.sort_values([\"date\", \"tic\"]).reset_index(drop=True)\n        return df\n\n    def calculate_turbulence(self, data):\n        \"\"\"calculate turbulence index based on dow 30\"\"\"\n        # can add other market assets\n        df = data.copy()\n        df_price_pivot = df.pivot(index=\"date\", columns=\"tic\", values=\"close\")\n        # use returns to calculate turbulence\n        df_price_pivot = df_price_pivot.pct_change()\n\n        unique_date = df.date.unique()\n        # start after a year\n        start = 252\n        turbulence_index = [0] * start\n        # turbulence_index = [0]\n        count = 0\n        for i in range(start, len(unique_date)):\n            current_price = df_price_pivot[df_price_pivot.index == unique_date[i]]\n            # use one year rolling window to calcualte covariance\n            hist_price = df_price_pivot[\n                (df_price_pivot.index < unique_date[i])\n                & (df_price_pivot.index >= unique_date[i - 252])\n            ]\n            # Drop tickers which has number missing values more than the \"oldest\" ticker\n            filtered_hist_price = hist_price.iloc[\n                hist_price.isna().sum().min() :\n            ].dropna(axis=1)\n\n            cov_temp = filtered_hist_price.cov()\n            current_temp = current_price[[x for x in filtered_hist_price]] - np.mean(\n                filtered_hist_price, axis=0\n            )\n            # cov_temp = hist_price.cov()\n            # current_temp=(current_price - np.mean(hist_price,axis=0))\n\n            temp = current_temp.values.dot(np.linalg.pinv(cov_temp)).dot(\n                current_temp.values.T\n            )\n            if temp > 0:\n                count += 1\n                if count > 2:\n                    turbulence_temp = temp[0][0]\n                else:\n                    # avoid large outlier because of the calculation just begins\n                    turbulence_temp = 0\n            else:\n                turbulence_temp = 0\n            turbulence_index.append(turbulence_temp)\n        try:\n            turbulence_index = pd.DataFrame(\n                {\"date\": df_price_pivot.index, \"turbulence\": turbulence_index}\n            )\n        except ValueError:\n            raise Exception(\"Turbulence information could not be added.\")\n        return turbulence_index\n"
        }
      ]
    },
    {
      "id": 4,
      "name": "cython_order_book",
      "source_repo": "hummingbot/hummingbot",
      "files": [
        {
          "path": "hummingbot/core/data_type/order_book.pyx",
          "url": "https://github.com/hummingbot/hummingbot/blob/master/hummingbot/core/data_type/order_book.pyx",
          "lines": "1-483",
          "code": "# distutils: language=c++\n# distutils: sources=hummingbot/core/cpp/OrderBookEntry.cpp\nimport bisect\nimport logging\nimport time\nfrom typing import (\n    Dict,\n    Iterator,\n    List,\n    Optional,\n    Tuple,\n)\n\nimport numpy as np\nimport pandas as pd\n\nfrom cython.operator cimport(\n    address as ref,\n    dereference as deref,\n    postincrement as inc,\n)\n\nfrom hummingbot.core.data_type.order_book_message import OrderBookMessage\nfrom hummingbot.core.data_type.order_book_query_result import OrderBookQueryResult\nfrom hummingbot.core.data_type.order_book_row import OrderBookRow\nfrom hummingbot.core.data_type.OrderBookEntry cimport truncateOverlapEntries\nfrom hummingbot.logger import HummingbotLogger\nfrom hummingbot.core.event.events import (\n    OrderBookEvent,\n    OrderBookTradeEvent\n)\n\ncimport numpy as np\n\nob_logger = None\nNaN = float(\"nan\")\n\n\ncdef class OrderBook(PubSub):\n    ORDER_BOOK_TRADE_EVENT_TAG = OrderBookEvent.TradeEvent.value\n\n    @classmethod\n    def logger(cls) -> HummingbotLogger:\n        global ob_logger\n        if ob_logger is None:\n            ob_logger = logging.getLogger(__name__)\n        return ob_logger\n\n    def __init__(self, dex=False):\n        super().__init__()\n        self._snapshot_uid = 0\n        self._last_diff_uid = 0\n        self._best_bid = self._best_ask = float(\"NaN\")\n        self._last_trade_price = float(\"NaN\")\n        self._last_applied_trade = -1000.0\n        self._last_trade_price_rest_updated = -1000\n        self._dex = dex\n\n    cdef c_apply_diffs(self, vector[OrderBookEntry] bids, vector[OrderBookEntry] asks, int64_t update_id):\n        cdef:\n            set[OrderBookEntry].iterator bid_book_end = self._bid_book.end()\n            set[OrderBookEntry].iterator ask_book_end = self._ask_book.end()\n            set[OrderBookEntry].reverse_iterator bid_iterator\n            set[OrderBookEntry].iterator ask_iterator\n            set[OrderBookEntry].iterator result\n            OrderBookEntry top_bid\n            OrderBookEntry top_ask\n\n        # Apply the diffs. Diffs with 0 amounts mean deletion.\n        for bid in bids:\n            result = self._bid_book.find(bid)\n            if result != bid_book_end:\n                self._bid_book.erase(result)\n            if bid.getAmount() > 0:\n                self._bid_book.insert(bid)\n        for ask in asks:\n            result = self._ask_book.find(ask)\n            if result != ask_book_end:\n                self._ask_book.erase(result)\n            if ask.getAmount() > 0:\n                self._ask_book.insert(ask)\n\n        # If any overlapping entries between the bid and ask books, centralised: newer entries win, dex: see OrderBookEntry.cpp\n        truncateOverlapEntries(self._bid_book, self._ask_book, self._dex)\n\n        # Record the current best prices, for faster c_get_price() calls.\n        bid_iterator = self._bid_book.rbegin()\n        ask_iterator = self._ask_book.begin()\n        if bid_iterator != self._bid_book.rend():\n            top_bid = deref(bid_iterator)\n            self._best_bid = top_bid.getPrice()\n        if ask_iterator != self._ask_book.end():\n            top_ask = deref(ask_iterator)\n            self._best_ask = top_ask.getPrice()\n\n        # Remember the last diff update ID.\n        self._last_diff_uid = update_id\n\n    cdef c_apply_snapshot(self, vector[OrderBookEntry] bids, vector[OrderBookEntry] asks, int64_t update_id):\n        cdef:\n            double best_bid_price = float(\"NaN\")\n            double best_ask_price = float(\"NaN\")\n            set[OrderBookEntry].reverse_iterator bid_iterator\n            set[OrderBookEntry].iterator ask_iterator\n            OrderBookEntry top_bid\n            OrderBookEntry top_ask\n\n        # Start with an empty order book, and then insert all entries.\n        self._bid_book.clear()\n        self._ask_book.clear()\n        for bid in bids:\n            self._bid_book.insert(bid)\n            if not (bid.getPrice() <= best_bid_price):\n                best_bid_price = bid.getPrice()\n        for ask in asks:\n            self._ask_book.insert(ask)\n            if not (ask.getPrice() >= best_ask_price):\n                best_ask_price = ask.getPrice()\n\n        if self._dex:\n            truncateOverlapEntries(self._bid_book, self._ask_book, self._dex)\n            # Record the current best prices, for faster c_get_price() calls.\n            bid_iterator = self._bid_book.rbegin()\n            ask_iterator = self._ask_book.begin()\n            if bid_iterator != self._bid_book.rend():\n                top_bid = deref(bid_iterator)\n                best_bid_price = top_bid.getPrice()\n            if ask_iterator != self._ask_book.end():\n                top_ask = deref(ask_iterator)\n                best_ask_price = top_ask.getPrice()\n\n        # Record the current best prices, for faster c_get_price() calls.\n        self._best_bid = best_bid_price\n        self._best_ask = best_ask_price\n\n        # Remember the last snapshot update ID.\n        self._snapshot_uid = update_id\n\n    cdef c_apply_trade(self, object trade_event):\n        self._last_trade_price = trade_event.price\n        self._last_applied_trade = time.perf_counter()\n        self.c_trigger_event(self.ORDER_BOOK_TRADE_EVENT_TAG, trade_event)\n\n    @property\n    def last_trade_price(self) -> float:\n        return self._last_trade_price\n\n    @last_trade_price.setter\n    def last_trade_price(self, value: float):\n        self._last_trade_price = value\n\n    @property\n    def last_applied_trade(self) -> float:\n        return self._last_applied_trade\n\n    @property\n    def last_trade_price_rest_updated(self) -> float:\n        return self._last_trade_price_rest_updated\n\n    @last_trade_price_rest_updated.setter\n    def last_trade_price_rest_updated(self, value: float):\n        self._last_trade_price_rest_updated = value\n\n    @property\n    def snapshot_uid(self) -> int:\n        return self._snapshot_uid\n\n    @property\n    def last_diff_uid(self) -> int:\n        return self._last_diff_uid\n\n    @property\n    def snapshot(self) -> Tuple[pd.DataFrame, pd.DataFrame]:\n        bids_rows = list(self.bid_entries())\n        asks_rows = list(self.ask_entries())\n        bids_df = pd.DataFrame(data=bids_rows, columns=OrderBookRow._fields, dtype=\"float64\")\n        asks_df = pd.DataFrame(data=asks_rows, columns=OrderBookRow._fields, dtype=\"float64\")\n        return bids_df, asks_df\n\n    def apply_diffs(self, bids: List[OrderBookRow], asks: List[OrderBookRow], update_id: int):\n        cdef:\n            vector[OrderBookEntry] cpp_bids\n            vector[OrderBookEntry] cpp_asks\n        for row in bids:\n            cpp_bids.push_back(OrderBookEntry(row.price, row.amount, row.update_id))\n        for row in asks:\n            cpp_asks.push_back(OrderBookEntry(row.price, row.amount, row.update_id))\n        self.c_apply_diffs(cpp_bids, cpp_asks, update_id)\n\n    def apply_snapshot(self, bids: List[OrderBookRow], asks: List[OrderBookRow], update_id: int):\n        cdef:\n            vector[OrderBookEntry] cpp_bids\n            vector[OrderBookEntry] cpp_asks\n        for row in bids:\n            cpp_bids.push_back(OrderBookEntry(row.price, row.amount, row.update_id))\n        for row in asks:\n            cpp_asks.push_back(OrderBookEntry(row.price, row.amount, row.update_id))\n        self.c_apply_snapshot(cpp_bids, cpp_asks, update_id)\n\n    def apply_trade(self, trade: OrderBookTradeEvent):\n        self.c_apply_trade(trade)\n\n    def apply_pandas_diffs(self, bids_df: pd.DataFrame, asks_df: pd.DataFrame):\n        \"\"\"\n        The diffs data frame must have 3 columns, [price, amount, update_id], and a UNIX timestamp index.\n\n        All columns are of double type.\n        \"\"\"\n        self.apply_numpy_diffs(bids_df.values, asks_df.values)\n\n    def apply_numpy_diffs(self, bids_array: np.ndarray, asks_array: np.ndarray):\n        \"\"\"\n        The diffs data frame must have 3 columns, [price, amount, update_id].\n        All columns are of double type.\n        \"\"\"\n        self.c_apply_numpy_diffs(bids_array, asks_array)\n\n    cdef c_apply_numpy_diffs(self,\n                             np.ndarray[np.float64_t, ndim=2] bids_array,\n                             np.ndarray[np.float64_t, ndim=2] asks_array):\n        \"\"\"\n        The diffs data frame must have 3 columns, [price, amount, update_id].\n        All columns are of double type.\n        \"\"\"\n        cdef:\n            vector[OrderBookEntry] cpp_bids\n            vector[OrderBookEntry] cpp_asks\n            int64_t last_update_id = 0\n\n        for row in bids_array:\n            cpp_bids.push_back(OrderBookEntry(row[0], row[1], <int64_t>(row[2])))\n            last_update_id = max(last_update_id, <int64_t>row[2])\n        for row in asks_array:\n            cpp_asks.push_back(OrderBookEntry(row[0], row[1], <int64_t>(row[2])))\n            last_update_id = max(last_update_id, <int64_t>row[2])\n        self.c_apply_diffs(cpp_bids, cpp_asks, last_update_id)\n\n    def apply_numpy_snapshot(self, bids_array: np.ndarray, asks_array: np.ndarray):\n        \"\"\"\n        The diffs data frame must have 3 columns, [price, amount, update_id].\n        All columns are of double type.\n        \"\"\"\n        self.c_apply_numpy_snapshot(bids_array, asks_array)\n\n    cdef c_apply_numpy_snapshot(self,\n                                np.ndarray[np.float64_t, ndim=2] bids_array,\n                                np.ndarray[np.float64_t, ndim=2] asks_array):\n        \"\"\"\n        The diffs data frame must have 3 columns, [price, amount, update_id].\n        All columns are of double type.\n        \"\"\"\n        cdef:\n            vector[OrderBookEntry] cpp_bids\n            vector[OrderBookEntry] cpp_asks\n            int64_t last_update_id = 0\n\n        for row in bids_array:\n            cpp_bids.push_back(OrderBookEntry(row[0], row[1], <int64_t>(row[2])))\n            last_update_id = max(last_update_id, <int64_t>row[2])\n        for row in asks_array:\n            cpp_asks.push_back(OrderBookEntry(row[0], row[1], <int64_t>(row[2])))\n            last_update_id = max(last_update_id, <int64_t>row[2])\n        self.c_apply_snapshot(cpp_bids, cpp_asks, last_update_id)\n\n    def bid_entries(self) -> Iterator[OrderBookRow]:\n        cdef:\n            set[OrderBookEntry].reverse_iterator it = self._bid_book.rbegin()\n            OrderBookEntry entry\n        while it != self._bid_book.rend():\n            entry = deref(it)\n            yield OrderBookRow(entry.getPrice(), entry.getAmount(), entry.getUpdateId())\n            inc(it)\n\n    def ask_entries(self) -> Iterator[OrderBookRow]:\n        cdef:\n            set[OrderBookEntry].iterator it = self._ask_book.begin()\n            OrderBookEntry entry\n        while it != self._ask_book.end():\n            entry = deref(it)\n            yield OrderBookRow(entry.getPrice(), entry.getAmount(), entry.getUpdateId())\n            inc(it)\n\n    def simulate_buy(self, amount: float) -> List[OrderBookRow]:\n        amount_left = amount\n        retval = []\n        for ask_entry in self.ask_entries():\n            ask_entry = ask_entry\n            if ask_entry.amount < amount_left:\n                retval.append(ask_entry)\n                amount_left -= ask_entry.amount\n            else:\n                retval.append(OrderBookRow(ask_entry.price, amount_left, ask_entry.update_id))\n                amount_left = 0.0\n                break\n        return retval\n\n    def simulate_sell(self, amount: float) -> List[OrderBookRow]:\n        amount_left = amount\n        retval = []\n        for bid_entry in self.bid_entries():\n            bid_entry = bid_entry\n            if bid_entry.amount < amount_left:\n                retval.append(bid_entry)\n                amount_left -= bid_entry.amount\n            else:\n                retval.append(OrderBookRow(bid_entry.price, amount_left, bid_entry.update_id))\n                amount_left = 0.0\n                break\n        return retval\n\n    cdef double c_get_price(self, bint is_buy) except? -1:\n        cdef:\n            set[OrderBookEntry] *book = ref(self._ask_book) if is_buy else ref(self._bid_book)\n        if deref(book).size() < 1:\n            raise EnvironmentError(\"Order book is empty - no price quote is possible.\")\n        return self._best_ask if is_buy else self._best_bid\n\n    def get_price(self, is_buy: bool) -> float:\n        return self.c_get_price(is_buy)\n\n    cdef OrderBookQueryResult c_get_price_for_volume(self, bint is_buy, double volume):\n        cdef:\n            double cumulative_volume = 0\n            double result_price = NaN\n\n        if is_buy:\n            for order_book_row in self.ask_entries():\n                cumulative_volume += order_book_row.amount\n                if cumulative_volume >= volume:\n                    result_price = order_book_row.price\n                    break\n        else:\n            for order_book_row in self.bid_entries():\n                cumulative_volume += order_book_row.amount\n                if cumulative_volume >= volume:\n                    result_price = order_book_row.price\n                    break\n\n        return OrderBookQueryResult(NaN, volume, result_price, min(cumulative_volume, volume))\n\n    cdef OrderBookQueryResult c_get_vwap_for_volume(self, bint is_buy, double volume):\n        cdef:\n            double total_cost = 0\n            double total_volume = 0\n            double result_vwap = NaN\n        if is_buy:\n            for order_book_row in self.ask_entries():\n                total_cost += order_book_row.amount * order_book_row.price\n                total_volume += order_book_row.amount\n                if total_volume >= volume:\n                    total_cost -= order_book_row.amount * order_book_row.price\n                    total_volume -= order_book_row.amount\n                    incremental_amount = volume - total_volume\n                    total_cost += incremental_amount * order_book_row.price\n                    total_volume += incremental_amount\n                    result_vwap = total_cost / total_volume\n                    break\n        else:\n            for order_book_row in self.bid_entries():\n                total_cost += order_book_row.amount * order_book_row.price\n                total_volume += order_book_row.amount\n                if total_volume >= volume:\n                    total_cost -= order_book_row.amount * order_book_row.price\n                    total_volume -= order_book_row.amount\n                    incremental_amount = volume - total_volume\n                    total_cost += incremental_amount * order_book_row.price\n                    total_volume += incremental_amount\n                    result_vwap = total_cost / total_volume\n                    break\n\n        return OrderBookQueryResult(NaN, volume, result_vwap, min(total_volume, volume))\n\n    cdef OrderBookQueryResult c_get_price_for_quote_volume(self, bint is_buy, double quote_volume):\n        cdef:\n            double cumulative_volume = 0\n            double result_price = NaN\n\n        if is_buy:\n            for order_book_row in self.ask_entries():\n                cumulative_volume += order_book_row.amount * order_book_row.price\n                if cumulative_volume >= quote_volume:\n                    result_price = order_book_row.price\n                    break\n        else:\n            for order_book_row in self.bid_entries():\n                cumulative_volume += order_book_row.amount * order_book_row.price\n                if cumulative_volume >= quote_volume:\n                    result_price = order_book_row.price\n                    break\n\n        return OrderBookQueryResult(NaN, quote_volume, result_price, min(cumulative_volume, quote_volume))\n\n    cdef OrderBookQueryResult c_get_quote_volume_for_base_amount(self, bint is_buy, double base_amount):\n        cdef:\n            double cumulative_volume = 0\n            double cumulative_base_amount = 0\n            double row_amount = 0\n\n        if is_buy:\n            for order_book_row in self.ask_entries():\n                row_amount = order_book_row.amount\n                if row_amount + cumulative_base_amount >= base_amount:\n                    row_amount = base_amount - cumulative_base_amount\n                cumulative_base_amount += row_amount\n                cumulative_volume += row_amount * order_book_row.price\n                if cumulative_base_amount >= base_amount:\n                    break\n        else:\n            for order_book_row in self.bid_entries():\n                row_amount = order_book_row.amount\n                if row_amount + cumulative_base_amount >= base_amount:\n                    row_amount = base_amount - cumulative_base_amount\n                cumulative_base_amount += row_amount\n                cumulative_volume += row_amount * order_book_row.price\n                if cumulative_base_amount >= base_amount:\n                    break\n\n        return OrderBookQueryResult(NaN, base_amount, NaN, cumulative_volume)\n\n    cdef OrderBookQueryResult c_get_volume_for_price(self, bint is_buy, double price):\n        cdef:\n            double cumulative_volume = 0\n            double result_price = NaN\n\n        if is_buy:\n            for order_book_row in self.ask_entries():\n                if order_book_row.price > price:\n                    break\n                cumulative_volume += order_book_row.amount\n                result_price = order_book_row.price\n        else:\n            for order_book_row in self.bid_entries():\n                if order_book_row.price < price:\n                    break\n                cumulative_volume += order_book_row.amount\n                result_price = order_book_row.price\n\n        return OrderBookQueryResult(price, NaN, result_price, cumulative_volume)\n\n    cdef OrderBookQueryResult c_get_quote_volume_for_price(self, bint is_buy, double price):\n        cdef:\n            double cumulative_volume = 0\n            double result_price = NaN\n\n        if is_buy:\n            for order_book_row in self.ask_entries():\n                if order_book_row.price > price:\n                    break\n                cumulative_volume += order_book_row.amount * order_book_row.price\n                result_price = order_book_row.price\n        else:\n            for order_book_row in self.bid_entries():\n                if order_book_row.price < price:\n                    break\n                cumulative_volume += order_book_row.amount * order_book_row.price\n                result_price = order_book_row.price\n\n        return OrderBookQueryResult(price, NaN, result_price, cumulative_volume)\n\n    def get_price_for_volume(self, is_buy: bool, volume: float) -> OrderBookQueryResult:\n        return self.c_get_price_for_volume(is_buy, volume)\n\n    def get_vwap_for_volume(self, is_buy: bool, volume: float) -> OrderBookQueryResult:\n        return self.c_get_vwap_for_volume(is_buy, volume)\n\n    def get_price_for_quote_volume(self, is_buy: bool, quote_volume: float) -> OrderBookQueryResult:\n        return self.c_get_price_for_quote_volume(is_buy, quote_volume)\n\n    def get_quote_volume_for_base_amount(self, is_buy: bool, base_amount: float) -> OrderBookQueryResult:\n        return self.c_get_quote_volume_for_base_amount(is_buy, base_amount)\n\n    def get_volume_for_price(self, bint is_buy, double price) -> OrderBookQueryResult:\n        return self.c_get_volume_for_price(is_buy, price)\n\n    def get_quote_volume_for_price(self, is_buy: bool, price: float) -> OrderBookQueryResult:\n        return self.c_get_quote_volume_for_price(is_buy, price)\n\n    def restore_from_snapshot_and_diffs(self, snapshot: OrderBookMessage, diffs: List[OrderBookMessage]):\n        replay_position = bisect.bisect_right(diffs, snapshot)\n        replay_diffs = diffs[replay_position:]\n        self.apply_snapshot(snapshot.bids, snapshot.asks, snapshot.update_id)\n        for diff in replay_diffs:\n            self.apply_diffs(diff.bids, diff.asks, diff.update_id)\n"
        },
        {
          "path": "hummingbot/connector/exchange_base.pyx",
          "url": "https://github.com/hummingbot/hummingbot/blob/master/hummingbot/connector/exchange_base.pyx",
          "lines": "1-383",
          "code": "import asyncio\nfrom decimal import Decimal\nfrom typing import Dict, List, Iterator, Mapping, Optional\n\nfrom bidict import bidict\n\nfrom hummingbot.connector.budget_checker import BudgetChecker\nfrom hummingbot.connector.connector_base import ConnectorBase\nfrom hummingbot.core.data_type.common import OrderType, PriceType, TradeType\nfrom hummingbot.core.data_type.limit_order import LimitOrder\nfrom hummingbot.core.data_type.order_book import OrderBook\nfrom hummingbot.core.data_type.order_book_query_result import ClientOrderBookQueryResult, OrderBookQueryResult\nfrom hummingbot.core.data_type.order_book_row import ClientOrderBookRow\nfrom hummingbot.core.data_type.order_book_tracker import OrderBookTracker\nfrom hummingbot.core.data_type.trade_fee import AddedToCostTradeFee\nfrom hummingbot.core.utils.async_utils import safe_gather\n\n\ns_float_NaN = float(\"nan\")\ns_decimal_NaN = Decimal(\"nan\")\ns_decimal_0 = Decimal(0)\n\n\ncdef class ExchangeBase(ConnectorBase):\n    \"\"\"\n    ExchangeBase provides common exchange (for both centralized and decentralized) connector functionality and\n    interface.\n    \"\"\"\n\n    def __init__(self,\n                 balance_asset_limit: Optional[Dict[str, Dict[str, Decimal]]] = None,\n                 rate_limits_share_pct: Decimal = Decimal(\"100\")):\n        super().__init__(balance_asset_limit)\n        self._order_book_tracker = None\n        self._budget_checker = BudgetChecker(exchange=self)\n        self._trading_pair_symbol_map: Optional[Mapping[str, str]] = None\n        self._mapping_initialization_lock = asyncio.Lock()\n\n    @staticmethod\n    def convert_from_exchange_trading_pair(exchange_trading_pair: str) -> Optional[str]:\n        return exchange_trading_pair\n\n    @staticmethod\n    def convert_to_exchange_trading_pair(hb_trading_pair: str) -> str:\n        return hb_trading_pair\n\n    @property\n    def order_books(self) -> Dict[str, OrderBook]:\n        raise NotImplementedError\n\n    @property\n    def limit_orders(self) -> List[LimitOrder]:\n        raise NotImplementedError\n\n    @property\n    def budget_checker(self) -> BudgetChecker:\n        return self._budget_checker\n\n    @property\n    def order_book_tracker(self) -> Optional[OrderBookTracker]:\n        return self._order_book_tracker\n\n    async def trading_pair_symbol_map(self):\n        if not self.trading_pair_symbol_map_ready():\n            async with self._mapping_initialization_lock:\n                if not self.trading_pair_symbol_map_ready():\n                    await self._initialize_trading_pair_symbol_map()\n        current_map = self._trading_pair_symbol_map or bidict()\n        return current_map\n\n    def trading_pair_symbol_map_ready(self):\n        \"\"\"\n        Checks if the mapping from exchange symbols to client trading pairs has been initialized\n\n        :return: True if the mapping has been initialized, False otherwise\n        \"\"\"\n        return self._trading_pair_symbol_map is not None and len(self._trading_pair_symbol_map) > 0\n\n    async def all_trading_pairs(self) -> List[str]:\n        \"\"\"\n        List of all trading pairs supported by the connector\n\n        :return: List of trading pair symbols in the Hummingbot format\n        \"\"\"\n        mapping = await self.trading_pair_symbol_map()\n        return list(mapping.values())\n\n    async def exchange_symbol_associated_to_pair(self, trading_pair: str) -> str:\n        \"\"\"\n        Used to translate a trading pair from the client notation to the exchange notation\n\n        :param trading_pair: trading pair in client notation\n\n        :return: trading pair in exchange notation\n        \"\"\"\n        symbol_map = await self.trading_pair_symbol_map()\n        return symbol_map.inverse[trading_pair]\n\n    async def trading_pair_associated_to_exchange_symbol(self, symbol: str,) -> str:\n        \"\"\"\n        Used to translate a trading pair from the exchange notation to the client notation\n\n        :param symbol: trading pair in exchange notation\n\n        :return: trading pair in client notation\n        \"\"\"\n        symbol_map = await self.trading_pair_symbol_map()\n        return symbol_map[symbol]\n\n    async def get_last_traded_prices(self, trading_pairs: List[str]) -> Dict[str, float]:\n        \"\"\"\n        Return a dictionary the trading_pair as key and the current price as value for each trading pair passed as\n        parameter\n\n        :param trading_pairs: list of trading pairs to get the prices for\n\n        :return: Dictionary of associations between token pair and its latest price\n        \"\"\"\n        tasks = [self._get_last_traded_price(trading_pair=trading_pair) for trading_pair in trading_pairs]\n        results = await safe_gather(*tasks)\n        return {t_pair: result for t_pair, result in zip(trading_pairs, results)}\n\n    def get_mid_price(self, trading_pair: str) -> Decimal:\n        return (self.get_price(trading_pair, True) + self.get_price(trading_pair, False)) / Decimal(\"2\")\n\n    cdef str c_buy(self, str trading_pair, object amount, object order_type=OrderType.MARKET,\n                   object price=s_decimal_NaN, dict kwargs={}):\n        return self.buy(trading_pair, amount, order_type, price, **kwargs)\n\n    cdef str c_sell(self, str trading_pair, object amount, object order_type=OrderType.MARKET,\n                    object price=s_decimal_NaN, dict kwargs={}):\n        return self.sell(trading_pair, amount, order_type, price, **kwargs)\n\n    cdef c_cancel(self, str trading_pair, str client_order_id):\n        return self.cancel(trading_pair, client_order_id)\n\n    cdef c_stop_tracking_order(self, str order_id):\n        raise NotImplementedError\n\n    cdef object c_get_fee(self,\n                          str base_currency,\n                          str quote_currency,\n                          object order_type,\n                          object order_side,\n                          object amount,\n                          object price,\n                          object is_maker = None):\n        return self.get_fee(base_currency, quote_currency, order_type, order_side, amount, price, is_maker)\n\n    cdef OrderBook c_get_order_book(self, str trading_pair):\n        return self.get_order_book(trading_pair)\n\n    cdef object c_get_price(self, str trading_pair, bint is_buy):\n        \"\"\"\n        :returns: Top bid/ask price for a specific trading pair\n        \"\"\"\n        cdef:\n            OrderBook order_book = self.c_get_order_book(trading_pair)\n            object top_price\n        try:\n            top_price = Decimal(str(order_book.c_get_price(is_buy)))\n        except EnvironmentError as e:\n            self.logger().warning(f\"{'Ask' if is_buy else 'Bid'} orderbook for {trading_pair} is empty.\")\n            return s_decimal_NaN\n        return self.c_quantize_order_price(trading_pair, top_price)\n\n    cdef ClientOrderBookQueryResult c_get_vwap_for_volume(self, str trading_pair, bint is_buy, object volume):\n        cdef:\n            OrderBook order_book = self.c_get_order_book(trading_pair)\n            OrderBookQueryResult result = order_book.c_get_vwap_for_volume(is_buy, float(volume))\n            object query_volume = Decimal(str(result.query_volume))\n            object result_price = Decimal(str(result.result_price))\n            object result_volume = Decimal(str(result.result_volume))\n        return ClientOrderBookQueryResult(s_decimal_NaN,\n                                          query_volume,\n                                          result_price,\n                                          result_volume)\n\n    cdef ClientOrderBookQueryResult c_get_price_for_quote_volume(self, str trading_pair, bint is_buy, double volume):\n        cdef:\n            OrderBook order_book = self.c_get_order_book(trading_pair)\n            OrderBookQueryResult result = order_book.c_get_price_for_quote_volume(is_buy, float(volume))\n            object query_volume = Decimal(str(result.query_volume))\n            object result_price = Decimal(str(result.result_price))\n            object result_volume = Decimal(str(result.result_volume))\n        return ClientOrderBookQueryResult(s_decimal_NaN,\n                                          query_volume,\n                                          result_price,\n                                          result_volume)\n\n    cdef ClientOrderBookQueryResult c_get_price_for_volume(self, str trading_pair, bint is_buy, object volume):\n        cdef:\n            OrderBook order_book = self.c_get_order_book(trading_pair)\n            OrderBookQueryResult result = order_book.c_get_price_for_volume(is_buy, float(volume))\n            object query_volume = Decimal(str(result.query_volume))\n            object result_price = Decimal(str(result.result_price))\n            object result_volume = Decimal(str(result.result_volume))\n        return ClientOrderBookQueryResult(s_decimal_NaN,\n                                          query_volume,\n                                          result_price,\n                                          result_volume)\n\n    cdef ClientOrderBookQueryResult c_get_quote_volume_for_base_amount(self, str trading_pair, bint is_buy,\n                                                                       object base_amount):\n        cdef:\n            OrderBook order_book = self.c_get_order_book(trading_pair)\n            OrderBookQueryResult result = order_book.c_get_quote_volume_for_base_amount(is_buy, float(base_amount))\n            object query_volume = Decimal(str(result.query_volume))\n            object result_volume = Decimal(str(result.result_volume))\n        return ClientOrderBookQueryResult(s_decimal_NaN,\n                                          query_volume,\n                                          s_decimal_NaN,\n                                          result_volume)\n\n    cdef ClientOrderBookQueryResult c_get_volume_for_price(self, str trading_pair, bint is_buy, object price):\n        cdef:\n            OrderBook order_book = self.c_get_order_book(trading_pair)\n            OrderBookQueryResult result = order_book.c_get_volume_for_price(is_buy, float(price))\n            object query_price = Decimal(str(result.query_price))\n            object result_price = Decimal(str(result.result_price))\n            object result_volume = Decimal(str(result.result_volume))\n        return ClientOrderBookQueryResult(query_price,\n                                          s_decimal_NaN,\n                                          result_price,\n                                          result_volume)\n\n    cdef ClientOrderBookQueryResult c_get_quote_volume_for_price(self, str trading_pair, bint is_buy, object price):\n        cdef:\n            OrderBook order_book = self.c_get_order_book(trading_pair)\n            OrderBookQueryResult result = order_book.c_get_volume_for_price(is_buy, float(price))\n            object query_price = Decimal(str(result.query_price))\n            object result_price = Decimal(str(result.result_price))\n            object result_volume = Decimal(str(result.result_volume))\n        return ClientOrderBookQueryResult(query_price,\n                                          s_decimal_NaN,\n                                          result_price,\n                                          result_volume)\n\n    def order_book_bid_entries(self, trading_pair) -> Iterator[ClientOrderBookRow]:\n        cdef:\n            OrderBook order_book = self.c_get_order_book(trading_pair)\n        for entry in order_book.bid_entries():\n            yield ClientOrderBookRow(Decimal(str(entry.price)),\n                                     Decimal(str(entry.amount)),\n                                     entry.update_id)\n\n    def order_book_ask_entries(self, trading_pair) -> Iterator[ClientOrderBookRow]:\n        cdef:\n            OrderBook order_book = self.c_get_order_book(trading_pair)\n        for entry in order_book.ask_entries():\n            yield ClientOrderBookRow(Decimal(str(entry.price)),\n                                     Decimal(str(entry.amount)),\n                                     entry.update_id)\n\n    def get_vwap_for_volume(self, trading_pair: str, is_buy: bool, volume: Decimal):\n        return self.c_get_vwap_for_volume(trading_pair, is_buy, volume)\n\n    def get_price_for_quote_volume(self, trading_pair: str, is_buy: bool, volume: Decimal):\n        return self.c_get_price_for_quote_volume(trading_pair, is_buy, volume)\n\n    def get_price_for_volume(self, trading_pair: str, is_buy: bool, volume: Decimal):\n        return self.c_get_price_for_volume(trading_pair, is_buy, volume)\n\n    def get_quote_volume_for_base_amount(self, trading_pair: str, is_buy: bool,\n                                         base_amount: Decimal) -> ClientOrderBookQueryResult:\n        return self.c_get_quote_volume_for_base_amount(trading_pair, is_buy, base_amount)\n\n    def get_volume_for_price(self, trading_pair: str, is_buy: bool, price: Decimal) -> ClientOrderBookQueryResult:\n        return self.c_get_volume_for_price(trading_pair, is_buy, price)\n\n    def get_quote_volume_for_price(self, trading_pair: str, is_buy: bool, price: Decimal) -> ClientOrderBookQueryResult:\n        return self.c_get_quote_volume_for_price(trading_pair, is_buy, price)\n\n    def get_price(self, trading_pair: str, is_buy: bool) -> Decimal:\n        return self.c_get_price(trading_pair, is_buy)\n\n    def buy(self, trading_pair: str, amount: Decimal, order_type=OrderType.MARKET,\n            price: Decimal = s_decimal_NaN, **kwargs) -> str:\n        raise NotImplementedError\n\n    def sell(self, trading_pair: str, amount: Decimal, order_type=OrderType.MARKET,\n             price: Decimal = s_decimal_NaN, **kwargs) -> str:\n        raise NotImplementedError\n\n    def cancel(self, trading_pair: str, client_order_id: str):\n        raise NotImplementedError\n\n    def get_order_book(self, trading_pair: str) -> OrderBook:\n        raise NotImplementedError\n\n    def get_fee(self,\n                base_currency: str,\n                quote_currency: str,\n                order_type: OrderType,\n                order_side: TradeType,\n                amount: Decimal,\n                price: Decimal = s_decimal_NaN,\n                is_maker: Optional[bool] = None) -> AddedToCostTradeFee:\n        raise NotImplementedError\n\n    def get_order_price_quantum(self, trading_pair: str, price: Decimal) -> Decimal:\n        return self.c_get_order_price_quantum(trading_pair, price)\n\n    def get_order_size_quantum(self, trading_pair: str, order_size: Decimal) -> Decimal:\n        return self.c_get_order_size_quantum(trading_pair, order_size)\n\n    def quantize_order_price(self, trading_pair: str, price: Decimal) -> Decimal:\n        return self.c_quantize_order_price(trading_pair, price)\n\n    def quantize_order_amount(self, trading_pair: str, amount: Decimal) -> Decimal:\n        return self.c_quantize_order_amount(trading_pair, amount)\n\n    def supported_order_types(self):\n        return [OrderType.LIMIT, OrderType.MARKET]\n\n    def get_maker_order_type(self):\n        \"\"\"\n        Return a maker order type depending what order types the connector supports.\n        \"\"\"\n        if OrderType.LIMIT_MAKER in self.supported_order_types():\n            return OrderType.LIMIT_MAKER\n        elif OrderType.LIMIT in self.supported_order_types():\n            return OrderType.LIMIT\n        else:\n            raise Exception(\"There is no maker order type supported by this exchange.\")\n\n    def get_taker_order_type(self):\n        \"\"\"\n        Return a taker order type depending what order types the connector supports.\n        \"\"\"\n        if OrderType.MARKET in self.supported_order_types():\n            return OrderType.MARKET\n        elif OrderType.LIMIT in self.supported_order_types():\n            return OrderType.LIMIT\n        else:\n            raise Exception(\"There is no taker order type supported by this exchange.\")\n\n    def get_price_by_type(self, trading_pair: str, price_type: PriceType) -> Decimal:\n        \"\"\"\n        Gets price by type (BestBid, BestAsk, MidPrice or LastTrade)\n        :param trading_pair: The market trading pair\n        :param price_type: The price type\n        :returns The price\n        \"\"\"\n        if price_type is PriceType.BestBid:\n            return self.c_get_price(trading_pair, False)\n        elif price_type is PriceType.BestAsk:\n            return self.c_get_price(trading_pair, True)\n        elif price_type is PriceType.MidPrice:\n            return (self.c_get_price(trading_pair, True) + self.c_get_price(trading_pair, False)) / Decimal(\"2\")\n        elif price_type is PriceType.LastTrade:\n            return Decimal(self.c_get_order_book(trading_pair).last_trade_price)\n\n    async def get_quote_price(self, trading_pair: str, is_buy: bool, amount: Decimal) -> Decimal:\n        \"\"\"\n        For an exchange type connector, the quote price is volume weighted average price.\n        \"\"\"\n        return Decimal(str(self.get_vwap_for_volume(trading_pair, is_buy, amount).result_price))\n\n    async def get_order_price(self, trading_pair: str, is_buy: bool, amount: Decimal) -> Decimal:\n        \"\"\"\n        For an exchange type connector, the price required for order submission is the price of the order book for\n        required volume.\n        \"\"\"\n        return Decimal(str(self.get_price_for_volume(trading_pair, is_buy, amount).result_price))\n\n    async def _initialize_trading_pair_symbol_map(self):\n        raise NotImplementedError\n\n    def _set_trading_pair_symbol_map(self, trading_pair_and_symbol_map: Optional[Mapping[str, str]]):\n        \"\"\"\n        Method added to allow the pure Python subclasses to set the value of the map\n        \"\"\"\n        self._trading_pair_symbol_map = trading_pair_and_symbol_map\n\n    def _set_order_book_tracker(self, order_book_tracker: Optional[OrderBookTracker]):\n        \"\"\"\n        Method added to allow the pure Python subclasses to store the tracker in the instance variable\n        \"\"\"\n        self._order_book_tracker = order_book_tracker\n\n    async def _get_last_traded_price(self, trading_pair: str) -> float:\n        raise NotImplementedError\n"
        },
        {
          "path": "hummingbot/core/event/event_forwarder.py",
          "url": "https://github.com/hummingbot/hummingbot/blob/master/hummingbot/core/event/event_forwarder.py",
          "lines": "1-24",
          "code": "#!/usr/bin/env python\n\nfrom typing import Callable\n\nfrom hummingbot.core.event.event_listener import EventListener\nfrom hummingbot.core.pubsub import PubSub\n\n\nclass EventForwarder(EventListener):\n    def __init__(self, to_function: Callable[[any], None]):\n        super().__init__()\n        self._to_function: Callable[[any], None] = to_function\n\n    def __call__(self, arg: any):\n        self._to_function(arg)\n\n\nclass SourceInfoEventForwarder(EventListener):\n    def __init__(self, to_function: Callable[[int, PubSub, any], None]):\n        super().__init__()\n        self._to_function: Callable[[int, PubSub, any], None] = to_function\n\n    def __call__(self, arg: any):\n        self._to_function(self.current_event_tag, self.current_event_caller, arg)\n"
        }
      ]
    },
    {
      "id": 5,
      "name": "ml_pipeline",
      "source_repo": "microsoft/qlib",
      "files": [
        {
          "path": "qlib/workflow/task/train.py",
          "url": "https://github.com/microsoft/qlib/blob/main/qlib/workflow/task/train.py",
          "lines": "1-1",
          "code": "[FILE_NOT_FOUND_IN_LOCAL_REPO]"
        },
        {
          "path": "qlib/data/dataset.py",
          "url": "https://github.com/microsoft/qlib/blob/main/qlib/data/dataset.py",
          "lines": "1-1",
          "code": "[FILE_NOT_FOUND_IN_LOCAL_REPO]"
        },
        {
          "path": "qlib/backtest/executor.py",
          "url": "https://github.com/microsoft/qlib/blob/main/qlib/backtest/executor.py",
          "lines": "1-628",
          "code": "from __future__ import annotations\n\nimport copy\nfrom abc import abstractmethod\nfrom collections import defaultdict\nfrom types import GeneratorType\nfrom typing import Any, Dict, Generator, List, Tuple, Union, cast\n\nimport pandas as pd\n\nfrom qlib.backtest.account import Account\nfrom qlib.backtest.position import BasePosition\nfrom qlib.log import get_module_logger\n\nfrom ..strategy.base import BaseStrategy\nfrom ..utils import init_instance_by_config\nfrom .decision import BaseTradeDecision, Order\nfrom .exchange import Exchange\nfrom .utils import CommonInfrastructure, LevelInfrastructure, TradeCalendarManager, get_start_end_idx\n\n\nclass BaseExecutor:\n    \"\"\"Base executor for trading\"\"\"\n\n    def __init__(\n        self,\n        time_per_step: str,\n        start_time: Union[str, pd.Timestamp] = None,\n        end_time: Union[str, pd.Timestamp] = None,\n        indicator_config: dict = {},\n        generate_portfolio_metrics: bool = False,\n        verbose: bool = False,\n        track_data: bool = False,\n        trade_exchange: Exchange | None = None,\n        common_infra: CommonInfrastructure | None = None,\n        settle_type: str = BasePosition.ST_NO,\n        **kwargs: Any,\n    ) -> None:\n        \"\"\"\n        Parameters\n        ----------\n        time_per_step : str\n            trade time per trading step, used for generate the trade calendar\n        show_indicator: bool, optional\n            whether to show indicators, :\n            - 'pa', the price advantage\n            - 'pos', the positive rate\n            - 'ffr', the fulfill rate\n        indicator_config: dict, optional\n            config for calculating trade indicator, including the following fields:\n            - 'show_indicator': whether to show indicators, optional, default by False. The indicators includes\n                - 'pa', the price advantage\n                - 'pos', the positive rate\n                - 'ffr', the fulfill rate\n            - 'pa_config': config for calculating price advantage(pa), optional\n                - 'base_price': the based price than which the trading price is advanced, Optional, default by 'twap'\n                    - If 'base_price' is 'twap', the based price is the time weighted average price\n                    - If 'base_price' is 'vwap', the based price is the volume weighted average price\n                - 'weight_method': weighted method when calculating total trading pa by different orders' pa in each\n                    step, optional, default by 'mean'\n                    - If 'weight_method' is 'mean', calculating mean value of different orders' pa\n                    - If 'weight_method' is 'amount_weighted', calculating amount weighted average value of different\n                        orders' pa\n                    - If 'weight_method' is 'value_weighted', calculating value weighted average value of different\n                        orders' pa\n            - 'ffr_config': config for calculating fulfill rate(ffr), optional\n                - 'weight_method': weighted method when calculating total trading ffr by different orders' ffr in each\n                    step, optional, default by 'mean'\n                    - If 'weight_method' is 'mean', calculating mean value of different orders' ffr\n                    - If 'weight_method' is 'amount_weighted', calculating amount weighted average value of different\n                        orders' ffr\n                    - If 'weight_method' is 'value_weighted', calculating value weighted average value of different\n                        orders' ffr\n            Example:\n                {\n                    'show_indicator': True,\n                    'pa_config': {\n                        \"agg\": \"twap\",  # \"vwap\"\n                        \"price\": \"$close\", # default to use deal price of the exchange\n                    },\n                    'ffr_config':{\n                        'weight_method': 'value_weighted',\n                    }\n                }\n        generate_portfolio_metrics : bool, optional\n            whether to generate portfolio_metrics, by default False\n        verbose : bool, optional\n            whether to print trading info, by default False\n        track_data : bool, optional\n            whether to generate trade_decision, will be used when training rl agent\n            - If `self.track_data` is true, when making data for training, the input `trade_decision` of `execute` will\n                be generated by `collect_data`\n            - Else,  `trade_decision` will not be generated\n\n        trade_exchange : Exchange\n            exchange that provides market info, used to generate portfolio_metrics\n            - If generate_portfolio_metrics is None, trade_exchange will be ignored\n            - Else If `trade_exchange` is None, self.trade_exchange will be set with common_infra\n\n        common_infra : CommonInfrastructure, optional:\n            common infrastructure for backtesting, may including:\n            - trade_account : Account, optional\n                trade account for trading\n            - trade_exchange : Exchange, optional\n                exchange that provides market info\n\n        settle_type : str\n            Please refer to the docs of BasePosition.settle_start\n        \"\"\"\n        self.time_per_step = time_per_step\n        self.indicator_config = indicator_config\n        self.generate_portfolio_metrics = generate_portfolio_metrics\n        self.verbose = verbose\n        self.track_data = track_data\n        self._trade_exchange = trade_exchange\n        self.level_infra = LevelInfrastructure()\n        self.level_infra.reset_infra(common_infra=common_infra, executor=self)\n        self._settle_type = settle_type\n        self.reset(start_time=start_time, end_time=end_time, common_infra=common_infra)\n        if common_infra is None:\n            get_module_logger(\"BaseExecutor\").warning(f\"`common_infra` is not set for {self}\")\n\n        # record deal order amount in one day\n        self.dealt_order_amount: Dict[str, float] = defaultdict(float)\n        self.deal_day = None\n\n    def reset_common_infra(self, common_infra: CommonInfrastructure, copy_trade_account: bool = False) -> None:\n        \"\"\"\n        reset infrastructure for trading\n            - reset trade_account\n        \"\"\"\n        if not hasattr(self, \"common_infra\"):\n            self.common_infra = common_infra\n        else:\n            self.common_infra.update(common_infra)\n\n        self.level_infra.reset_infra(common_infra=self.common_infra)\n\n        if common_infra.has(\"trade_account\"):\n            # NOTE: there is a trick in the code.\n            # shallow copy is used instead of deepcopy.\n            # 1. So positions are shared\n            # 2. Others are not shared, so each level has it own metrics (portfolio and trading metrics)\n            self.trade_account: Account = (\n                copy.copy(common_infra.get(\"trade_account\"))\n                if copy_trade_account\n                else common_infra.get(\"trade_account\")\n            )\n            self.trade_account.reset(freq=self.time_per_step, port_metr_enabled=self.generate_portfolio_metrics)\n\n    @property\n    def trade_exchange(self) -> Exchange:\n        \"\"\"get trade exchange in a prioritized order\"\"\"\n        return getattr(self, \"_trade_exchange\", None) or self.common_infra.get(\"trade_exchange\")\n\n    @property\n    def trade_calendar(self) -> TradeCalendarManager:\n        \"\"\"\n        Though trade calendar can be accessed from multiple sources, but managing in a centralized way will make the\n        code easier\n        \"\"\"\n        return self.level_infra.get(\"trade_calendar\")\n\n    def reset(self, common_infra: CommonInfrastructure | None = None, **kwargs: Any) -> None:\n        \"\"\"\n        - reset `start_time` and `end_time`, used in trade calendar\n        - reset `common_infra`, used to reset `trade_account`, `trade_exchange`, .etc\n        \"\"\"\n\n        if \"start_time\" in kwargs or \"end_time\" in kwargs:\n            start_time = kwargs.get(\"start_time\")\n            end_time = kwargs.get(\"end_time\")\n            self.level_infra.reset_cal(freq=self.time_per_step, start_time=start_time, end_time=end_time)\n        if common_infra is not None:\n            self.reset_common_infra(common_infra)\n\n    def get_level_infra(self) -> LevelInfrastructure:\n        return self.level_infra\n\n    def finished(self) -> bool:\n        return self.trade_calendar.finished()\n\n    def execute(self, trade_decision: BaseTradeDecision, level: int = 0) -> List[object]:\n        \"\"\"execute the trade decision and return the executed result\n\n        NOTE: this function is never used directly in the framework. Should we delete it?\n\n        Parameters\n        ----------\n        trade_decision : BaseTradeDecision\n\n        level : int\n            the level of current executor\n\n        Returns\n        ----------\n        execute_result : List[object]\n            the executed result for trade decision\n        \"\"\"\n        return_value: dict = {}\n        for _decision in self.collect_data(trade_decision, return_value=return_value, level=level):\n            pass\n        return cast(list, return_value.get(\"execute_result\"))\n\n    @abstractmethod\n    def _collect_data(\n        self,\n        trade_decision: BaseTradeDecision,\n        level: int = 0,\n    ) -> Union[Generator[Any, Any, Tuple[List[object], dict]], Tuple[List[object], dict]]:\n        \"\"\"\n        Please refer to the doc of collect_data\n        The only difference between `_collect_data` and `collect_data` is that some common steps are moved into\n        collect_data\n\n        Parameters\n        ----------\n        Please refer to the doc of collect_data\n\n\n        Returns\n        -------\n        Tuple[List[object], dict]:\n            (<the executed result for trade decision>, <the extra kwargs for `self.trade_account.update_bar_end`>)\n        \"\"\"\n\n    def collect_data(\n        self,\n        trade_decision: BaseTradeDecision,\n        return_value: dict | None = None,\n        level: int = 0,\n    ) -> Generator[Any, Any, List[object]]:\n        \"\"\"Generator for collecting the trade decision data for rl training\n\n        his function will make a step forward\n\n        Parameters\n        ----------\n        trade_decision : BaseTradeDecision\n\n        level : int\n            the level of current executor. 0 indicates the top level\n\n        return_value : dict\n            the mem address to return the value\n            e.g.  {\"return_value\": <the executed result>}\n\n        Returns\n        ----------\n        execute_result : List[object]\n            the executed result for trade decision.\n            ** NOTE!!!! **:\n            1) This is necessary,  The return value of generator will be used in NestedExecutor\n            2) Please note the executed results are not merged.\n\n        Yields\n        -------\n        object\n            trade decision\n        \"\"\"\n\n        if self.track_data:\n            yield trade_decision\n\n        atomic = not issubclass(self.__class__, NestedExecutor)  # issubclass(A, A) is True\n\n        if atomic and trade_decision.get_range_limit(default_value=None) is not None:\n            raise ValueError(\"atomic executor doesn't support specify `range_limit`\")\n\n        if self._settle_type != BasePosition.ST_NO:\n            self.trade_account.current_position.settle_start(self._settle_type)\n\n        obj = self._collect_data(trade_decision=trade_decision, level=level)\n\n        if isinstance(obj, GeneratorType):\n            yield_res = yield from obj\n            assert isinstance(yield_res, tuple) and len(yield_res) == 2\n            res, kwargs = yield_res\n        else:\n            # Some concrete executor don't have inner decisions\n            res, kwargs = obj\n\n        trade_start_time, trade_end_time = self.trade_calendar.get_step_time()\n        # Account will not be changed in this function\n        self.trade_account.update_bar_end(\n            trade_start_time,\n            trade_end_time,\n            self.trade_exchange,\n            atomic=atomic,\n            outer_trade_decision=trade_decision,\n            indicator_config=self.indicator_config,\n            **kwargs,\n        )\n\n        self.trade_calendar.step()\n\n        if self._settle_type != BasePosition.ST_NO:\n            self.trade_account.current_position.settle_commit()\n\n        if return_value is not None:\n            return_value.update({\"execute_result\": res})\n\n        return res\n\n    def get_all_executors(self) -> List[BaseExecutor]:\n        \"\"\"get all executors\"\"\"\n        return [self]\n\n\nclass NestedExecutor(BaseExecutor):\n    \"\"\"\n    Nested Executor with inner strategy and executor\n    - At each time `execute` is called, it will call the inner strategy and executor to execute the `trade_decision`\n        in a higher frequency env.\n    \"\"\"\n\n    def __init__(\n        self,\n        time_per_step: str,\n        inner_executor: Union[BaseExecutor, dict],\n        inner_strategy: Union[BaseStrategy, dict],\n        start_time: Union[str, pd.Timestamp] = None,\n        end_time: Union[str, pd.Timestamp] = None,\n        indicator_config: dict = {},\n        generate_portfolio_metrics: bool = False,\n        verbose: bool = False,\n        track_data: bool = False,\n        skip_empty_decision: bool = True,\n        align_range_limit: bool = True,\n        common_infra: CommonInfrastructure | None = None,\n        **kwargs: Any,\n    ) -> None:\n        \"\"\"\n        Parameters\n        ----------\n        inner_executor : BaseExecutor\n            trading env in each trading bar.\n        inner_strategy : BaseStrategy\n            trading strategy in each trading bar\n        skip_empty_decision: bool\n            Will the executor skip call inner loop when the decision is empty.\n            It should be False in following cases\n            - The decisions may be updated by steps\n            - The inner executor may not follow the decisions from the outer strategy\n        align_range_limit: bool\n            force to align the trade_range decision\n            It is only for nested executor, because range_limit is given by outer strategy\n        \"\"\"\n        self.inner_executor: BaseExecutor = init_instance_by_config(\n            inner_executor,\n            common_infra=common_infra,\n            accept_types=BaseExecutor,\n        )\n        self.inner_strategy: BaseStrategy = init_instance_by_config(\n            inner_strategy,\n            common_infra=common_infra,\n            accept_types=BaseStrategy,\n        )\n\n        self._skip_empty_decision = skip_empty_decision\n        self._align_range_limit = align_range_limit\n\n        super(NestedExecutor, self).__init__(\n            time_per_step=time_per_step,\n            start_time=start_time,\n            end_time=end_time,\n            indicator_config=indicator_config,\n            generate_portfolio_metrics=generate_portfolio_metrics,\n            verbose=verbose,\n            track_data=track_data,\n            common_infra=common_infra,\n            **kwargs,\n        )\n\n    def reset_common_infra(self, common_infra: CommonInfrastructure, copy_trade_account: bool = False) -> None:\n        \"\"\"\n        reset infrastructure for trading\n            - reset inner_strategy and inner_executor common infra\n        \"\"\"\n        # NOTE: please refer to the docs of BaseExecutor.reset_common_infra for the meaning of `copy_trade_account`\n\n        # The first level follow the `copy_trade_account` from the upper level\n        super(NestedExecutor, self).reset_common_infra(common_infra, copy_trade_account=copy_trade_account)\n\n        # The lower level have to copy the trade_account\n        self.inner_executor.reset_common_infra(common_infra, copy_trade_account=True)\n        self.inner_strategy.reset_common_infra(common_infra)\n\n    def _init_sub_trading(self, trade_decision: BaseTradeDecision) -> None:\n        trade_start_time, trade_end_time = self.trade_calendar.get_step_time()\n        self.inner_executor.reset(start_time=trade_start_time, end_time=trade_end_time)\n        sub_level_infra = self.inner_executor.get_level_infra()\n        self.level_infra.set_sub_level_infra(sub_level_infra)\n        self.inner_strategy.reset(level_infra=sub_level_infra, outer_trade_decision=trade_decision)\n\n    def _update_trade_decision(self, trade_decision: BaseTradeDecision) -> BaseTradeDecision:\n        # outer strategy have chance to update decision each iterator\n        updated_trade_decision = trade_decision.update(self.inner_executor.trade_calendar)\n        if updated_trade_decision is not None:  # TODO: always is None for now?\n            trade_decision = updated_trade_decision\n            # NEW UPDATE\n            # create a hook for inner strategy to update outer decision\n            trade_decision = self.inner_strategy.alter_outer_trade_decision(trade_decision)\n        return trade_decision\n\n    def _collect_data(\n        self,\n        trade_decision: BaseTradeDecision,\n        level: int = 0,\n    ) -> Generator[Any, Any, Tuple[List[object], dict]]:\n        execute_result = []\n        inner_order_indicators = []\n        decision_list = []\n        # NOTE:\n        # - this is necessary to calculating the steps in sub level\n        # - more detailed information will be set into trade decision\n        self._init_sub_trading(trade_decision)\n\n        _inner_execute_result = None\n        while not self.inner_executor.finished():\n            trade_decision = self._update_trade_decision(trade_decision)\n\n            if trade_decision.empty() and self._skip_empty_decision:\n                # give one chance for outer strategy to update the strategy\n                # - For updating some information in the sub executor (the strategy have no knowledge of the inner\n                #   executor when generating the decision)\n                break\n\n            sub_cal: TradeCalendarManager = self.inner_executor.trade_calendar\n\n            # NOTE: make sure get_start_end_idx is after `self._update_trade_decision`\n            start_idx, end_idx = get_start_end_idx(sub_cal, trade_decision)\n            if not self._align_range_limit or start_idx <= sub_cal.get_trade_step() <= end_idx:\n                # if force align the range limit, skip the steps outside the decision range limit\n\n                res = self.inner_strategy.generate_trade_decision(_inner_execute_result)\n\n                # NOTE: !!!!!\n                # the two lines below is for a special case in RL\n                # To solve the conflicts below\n                # - Normally, user will create a strategy and embed it into Qlib's executor and simulator interaction\n                #   loop For a _nested qlib example_, (Qlib Strategy) <=> (Qlib Executor[(inner Qlib Strategy) <=>\n                #   (inner Qlib Executor)])\n                # - However, RL-based framework has it's own script to run the loop\n                #   For an _RL learning example_, (RL Policy) <=> (RL Env[(inner Qlib Executor)])\n                # To make it possible to run  _nested qlib example_ and _RL learning example_ together, the solution\n                # below is proposed\n                # - The entry script follow the example of  _RL learning example_ to be compatible with all kinds of\n                #   RL Framework\n                # - Each step of (RL Env) will make (inner Qlib Executor) one step forward\n                #     - (inner Qlib Strategy) is a proxy strategy, it will give the program control right to (RL Env)\n                #       by `yield from` and wait for the action from the policy\n                # So the two lines below is the implementation of yielding control rights\n                if isinstance(res, GeneratorType):\n                    res = yield from res\n\n                _inner_trade_decision: BaseTradeDecision = res\n\n                trade_decision.mod_inner_decision(_inner_trade_decision)  # propagate part of decision information\n\n                # NOTE sub_cal.get_step_time() must be called before collect_data in case of step shifting\n                decision_list.append((_inner_trade_decision, *sub_cal.get_step_time()))\n\n                # NOTE: Trade Calendar will step forward in the follow line\n                _inner_execute_result = yield from self.inner_executor.collect_data(\n                    trade_decision=_inner_trade_decision,\n                    level=level + 1,\n                )\n                assert isinstance(_inner_execute_result, list)\n                self.post_inner_exe_step(_inner_execute_result)\n                execute_result.extend(_inner_execute_result)\n\n                inner_order_indicators.append(\n                    self.inner_executor.trade_account.get_trade_indicator().get_order_indicator(raw=True),\n                )\n            else:\n                # do nothing and just step forward\n                sub_cal.step()\n\n        # Let inner strategy know that the outer level execution is done.\n        self.inner_strategy.post_upper_level_exe_step()\n\n        return execute_result, {\"inner_order_indicators\": inner_order_indicators, \"decision_list\": decision_list}\n\n    def post_inner_exe_step(self, inner_exe_res: List[object]) -> None:\n        \"\"\"\n        A hook for doing sth after each step of inner strategy\n\n        Parameters\n        ----------\n        inner_exe_res :\n            the execution result of inner task\n        \"\"\"\n        self.inner_strategy.post_exe_step(inner_exe_res)\n\n    def get_all_executors(self) -> List[BaseExecutor]:\n        \"\"\"get all executors, including self and inner_executor.get_all_executors()\"\"\"\n        return [self, *self.inner_executor.get_all_executors()]\n\n\ndef _retrieve_orders_from_decision(trade_decision: BaseTradeDecision) -> List[Order]:\n    \"\"\"\n    IDE-friendly helper function.\n    \"\"\"\n    decisions = trade_decision.get_decision()\n    orders: List[Order] = []\n    for decision in decisions:\n        assert isinstance(decision, Order)\n        orders.append(decision)\n    return orders\n\n\nclass SimulatorExecutor(BaseExecutor):\n    \"\"\"Executor that simulate the true market\"\"\"\n\n    # TODO: TT_SERIAL & TT_PARAL will be replaced by feature fix_pos now.\n    # Please remove them in the future.\n\n    # available trade_types\n    TT_SERIAL = \"serial\"\n    # The orders will be executed serially in a sequence\n    # In each trading step, it is possible that users sell instruments first and use the money to buy new instruments\n    TT_PARAL = \"parallel\"\n    # The orders will be executed in parallel\n    # In each trading step, if users try to sell instruments first and buy new instruments with money, failure will\n    # occur\n\n    def __init__(\n        self,\n        time_per_step: str,\n        start_time: Union[str, pd.Timestamp] = None,\n        end_time: Union[str, pd.Timestamp] = None,\n        indicator_config: dict = {},\n        generate_portfolio_metrics: bool = False,\n        verbose: bool = False,\n        track_data: bool = False,\n        common_infra: CommonInfrastructure | None = None,\n        trade_type: str = TT_SERIAL,\n        **kwargs: Any,\n    ) -> None:\n        \"\"\"\n        Parameters\n        ----------\n        trade_type: str\n            please refer to the doc of `TT_SERIAL` & `TT_PARAL`\n        \"\"\"\n        super(SimulatorExecutor, self).__init__(\n            time_per_step=time_per_step,\n            start_time=start_time,\n            end_time=end_time,\n            indicator_config=indicator_config,\n            generate_portfolio_metrics=generate_portfolio_metrics,\n            verbose=verbose,\n            track_data=track_data,\n            common_infra=common_infra,\n            **kwargs,\n        )\n\n        self.trade_type = trade_type\n\n    def _get_order_iterator(self, trade_decision: BaseTradeDecision) -> List[Order]:\n        \"\"\"\n\n        Parameters\n        ----------\n        trade_decision : BaseTradeDecision\n            the trade decision given by the strategy\n\n        Returns\n        -------\n        List[Order]:\n            get a list orders according to `self.trade_type`\n        \"\"\"\n        orders = _retrieve_orders_from_decision(trade_decision)\n\n        if self.trade_type == self.TT_SERIAL:\n            # Orders will be traded in a parallel way\n            order_it = orders\n        elif self.trade_type == self.TT_PARAL:\n            # NOTE: !!!!!!!\n            # Assumption: there will not be orders in different trading direction in a single step of a strategy !!!!\n            # The parallel trading failure will be caused only by the conflicts of money\n            # Therefore, make the buying go first will make sure the conflicts happen.\n            # It equals to parallel trading after sorting the order by direction\n            order_it = sorted(orders, key=lambda order: -order.direction)\n        else:\n            raise NotImplementedError(f\"This type of input is not supported\")\n        return order_it\n\n    def _collect_data(self, trade_decision: BaseTradeDecision, level: int = 0) -> Tuple[List[object], dict]:\n        trade_start_time, _ = self.trade_calendar.get_step_time()\n        execute_result: list = []\n\n        for order in self._get_order_iterator(trade_decision):\n            # Each time we move into a new date, clear `self.dealt_order_amount` since it only maintains intraday\n            # information.\n            now_deal_day = self.trade_calendar.get_step_time()[0].floor(freq=\"D\")\n            if self.deal_day is None or now_deal_day > self.deal_day:\n                self.dealt_order_amount = defaultdict(float)\n                self.deal_day = now_deal_day\n\n            # execute the order.\n            # NOTE: The trade_account will be changed in this function\n            trade_val, trade_cost, trade_price = self.trade_exchange.deal_order(\n                order,\n                trade_account=self.trade_account,\n                dealt_order_amount=self.dealt_order_amount,\n            )\n            execute_result.append((order, trade_val, trade_cost, trade_price))\n\n            self.dealt_order_amount[order.stock_id] += order.deal_amount\n\n            if self.verbose:\n                print(\n                    \"[I {:%Y-%m-%d %H:%M:%S}]: {} {}, price {:.2f}, amount {}, deal_amount {}, factor {}, \"\n                    \"value {:.2f}, cash {:.2f}.\".format(\n                        trade_start_time,\n                        \"sell\" if order.direction == Order.SELL else \"buy\",\n                        order.stock_id,\n                        trade_price,\n                        order.amount,\n                        order.deal_amount,\n                        order.factor,\n                        trade_val,\n                        self.trade_account.get_cash(),\n                    ),\n                )\n        return execute_result, {\"trade_info\": execute_result}\n"
        },
        {
          "path": "qlib/contrib/strategy/signal_strategy.py",
          "url": "https://github.com/microsoft/qlib/blob/main/qlib/contrib/strategy/signal_strategy.py",
          "lines": "1-522",
          "code": "# Copyright (c) Microsoft Corporation.\n# Licensed under the MIT License.\nimport os\nimport copy\nimport warnings\nimport numpy as np\nimport pandas as pd\n\nfrom typing import Dict, List, Text, Tuple, Union\nfrom abc import ABC\n\nfrom qlib.data import D\nfrom qlib.data.dataset import Dataset\nfrom qlib.model.base import BaseModel\nfrom qlib.strategy.base import BaseStrategy\nfrom qlib.backtest.position import Position\nfrom qlib.backtest.signal import Signal, create_signal_from\nfrom qlib.backtest.decision import Order, OrderDir, TradeDecisionWO\nfrom qlib.log import get_module_logger\nfrom qlib.utils import get_pre_trading_date, load_dataset\nfrom qlib.contrib.strategy.order_generator import OrderGenerator, OrderGenWOInteract\nfrom qlib.contrib.strategy.optimizer import EnhancedIndexingOptimizer\n\n\nclass BaseSignalStrategy(BaseStrategy, ABC):\n    def __init__(\n        self,\n        *,\n        signal: Union[Signal, Tuple[BaseModel, Dataset], List, Dict, Text, pd.Series, pd.DataFrame] = None,\n        model=None,\n        dataset=None,\n        risk_degree: float = 0.95,\n        trade_exchange=None,\n        level_infra=None,\n        common_infra=None,\n        **kwargs,\n    ):\n        \"\"\"\n        Parameters\n        -----------\n        signal :\n            the information to describe a signal. Please refer to the docs of `qlib.backtest.signal.create_signal_from`\n            the decision of the strategy will base on the given signal\n        risk_degree : float\n            position percentage of total value.\n        trade_exchange : Exchange\n            exchange that provides market info, used to deal order and generate report\n            - If `trade_exchange` is None, self.trade_exchange will be set with common_infra\n            - It allowes different trade_exchanges is used in different executions.\n            - For example:\n                - In daily execution, both daily exchange and minutely are usable, but the daily exchange is recommended because it runs faster.\n                - In minutely execution, the daily exchange is not usable, only the minutely exchange is recommended.\n\n        \"\"\"\n        super().__init__(level_infra=level_infra, common_infra=common_infra, trade_exchange=trade_exchange, **kwargs)\n\n        self.risk_degree = risk_degree\n\n        # This is trying to be compatible with previous version of qlib task config\n        if model is not None and dataset is not None:\n            warnings.warn(\"`model` `dataset` is deprecated; use `signal`.\", DeprecationWarning)\n            signal = model, dataset\n\n        self.signal: Signal = create_signal_from(signal)\n\n    def get_risk_degree(self, trade_step=None):\n        \"\"\"get_risk_degree\n        Return the proportion of your total value you will use in investment.\n        Dynamically risk_degree will result in Market timing.\n        \"\"\"\n        # It will use 95% amount of your total value by default\n        return self.risk_degree\n\n\nclass TopkDropoutStrategy(BaseSignalStrategy):\n    # TODO:\n    # 1. Supporting leverage the get_range_limit result from the decision\n    # 2. Supporting alter_outer_trade_decision\n    # 3. Supporting checking the availability of trade decision\n    # 4. Regenerate results with forbid_all_trade_at_limit set to false and flip the default to false, as it is consistent with reality.\n    def __init__(\n        self,\n        *,\n        topk,\n        n_drop,\n        method_sell=\"bottom\",\n        method_buy=\"top\",\n        hold_thresh=1,\n        only_tradable=False,\n        forbid_all_trade_at_limit=True,\n        **kwargs,\n    ):\n        \"\"\"\n        Parameters\n        -----------\n        topk : int\n            the number of stocks in the portfolio.\n        n_drop : int\n            number of stocks to be replaced in each trading date.\n        method_sell : str\n            dropout method_sell, random/bottom.\n        method_buy : str\n            dropout method_buy, random/top.\n        hold_thresh : int\n            minimum holding days\n            before sell stock , will check current.get_stock_count(order.stock_id) >= self.hold_thresh.\n        only_tradable : bool\n            will the strategy only consider the tradable stock when buying and selling.\n\n            if only_tradable:\n\n                strategy will make decision with the tradable state of the stock info and avoid buy and sell them.\n\n            else:\n\n                strategy will make buy sell decision without checking the tradable state of the stock.\n        forbid_all_trade_at_limit : bool\n            if forbid all trades when limit_up or limit_down reached.\n\n            if forbid_all_trade_at_limit:\n\n                strategy will not do any trade when price reaches limit up/down, even not sell at limit up nor buy at\n                limit down, though allowed in reality.\n\n            else:\n\n                strategy will sell at limit up and buy ad limit down.\n        \"\"\"\n        super().__init__(**kwargs)\n        self.topk = topk\n        self.n_drop = n_drop\n        self.method_sell = method_sell\n        self.method_buy = method_buy\n        self.hold_thresh = hold_thresh\n        self.only_tradable = only_tradable\n        self.forbid_all_trade_at_limit = forbid_all_trade_at_limit\n\n    def generate_trade_decision(self, execute_result=None):\n        # get the number of trading step finished, trade_step can be [0, 1, 2, ..., trade_len - 1]\n        trade_step = self.trade_calendar.get_trade_step()\n        trade_start_time, trade_end_time = self.trade_calendar.get_step_time(trade_step)\n        pred_start_time, pred_end_time = self.trade_calendar.get_step_time(trade_step, shift=1)\n        pred_score = self.signal.get_signal(start_time=pred_start_time, end_time=pred_end_time)\n        # NOTE: the current version of topk dropout strategy can't handle pd.DataFrame(multiple signal)\n        # So it only leverage the first col of signal\n        if isinstance(pred_score, pd.DataFrame):\n            pred_score = pred_score.iloc[:, 0]\n        if pred_score is None:\n            return TradeDecisionWO([], self)\n        if self.only_tradable:\n            # If The strategy only consider tradable stock when make decision\n            # It needs following actions to filter stocks\n            def get_first_n(li, n, reverse=False):\n                cur_n = 0\n                res = []\n                for si in reversed(li) if reverse else li:\n                    if self.trade_exchange.is_stock_tradable(\n                        stock_id=si, start_time=trade_start_time, end_time=trade_end_time\n                    ):\n                        res.append(si)\n                        cur_n += 1\n                        if cur_n >= n:\n                            break\n                return res[::-1] if reverse else res\n\n            def get_last_n(li, n):\n                return get_first_n(li, n, reverse=True)\n\n            def filter_stock(li):\n                return [\n                    si\n                    for si in li\n                    if self.trade_exchange.is_stock_tradable(\n                        stock_id=si, start_time=trade_start_time, end_time=trade_end_time\n                    )\n                ]\n\n        else:\n            # Otherwise, the stock will make decision without the stock tradable info\n            def get_first_n(li, n):\n                return list(li)[:n]\n\n            def get_last_n(li, n):\n                return list(li)[-n:]\n\n            def filter_stock(li):\n                return li\n\n        current_temp: Position = copy.deepcopy(self.trade_position)\n        # generate order list for this adjust date\n        sell_order_list = []\n        buy_order_list = []\n        # load score\n        cash = current_temp.get_cash()\n        current_stock_list = current_temp.get_stock_list()\n        # last position (sorted by score)\n        last = pred_score.reindex(current_stock_list).sort_values(ascending=False).index\n        # The new stocks today want to buy **at most**\n        if self.method_buy == \"top\":\n            today = get_first_n(\n                pred_score[~pred_score.index.isin(last)].sort_values(ascending=False).index,\n                self.n_drop + self.topk - len(last),\n            )\n        elif self.method_buy == \"random\":\n            topk_candi = get_first_n(pred_score.sort_values(ascending=False).index, self.topk)\n            candi = list(filter(lambda x: x not in last, topk_candi))\n            n = self.n_drop + self.topk - len(last)\n            try:\n                today = np.random.choice(candi, n, replace=False)\n            except ValueError:\n                today = candi\n        else:\n            raise NotImplementedError(f\"This type of input is not supported\")\n        # combine(new stocks + last stocks),  we will drop stocks from this list\n        # In case of dropping higher score stock and buying lower score stock.\n        comb = pred_score.reindex(last.union(pd.Index(today))).sort_values(ascending=False).index\n\n        # Get the stock list we really want to sell (After filtering the case that we sell high and buy low)\n        if self.method_sell == \"bottom\":\n            sell = last[last.isin(get_last_n(comb, self.n_drop))]\n        elif self.method_sell == \"random\":\n            candi = filter_stock(last)\n            try:\n                sell = pd.Index(np.random.choice(candi, self.n_drop, replace=False) if len(last) else [])\n            except ValueError:  # No enough candidates\n                sell = candi\n        else:\n            raise NotImplementedError(f\"This type of input is not supported\")\n\n        # Get the stock list we really want to buy\n        buy = today[: len(sell) + self.topk - len(last)]\n        for code in current_stock_list:\n            if not self.trade_exchange.is_stock_tradable(\n                stock_id=code,\n                start_time=trade_start_time,\n                end_time=trade_end_time,\n                direction=None if self.forbid_all_trade_at_limit else OrderDir.SELL,\n            ):\n                continue\n            if code in sell:\n                # check hold limit\n                time_per_step = self.trade_calendar.get_freq()\n                if current_temp.get_stock_count(code, bar=time_per_step) < self.hold_thresh:\n                    continue\n                # sell order\n                sell_amount = current_temp.get_stock_amount(code=code)\n                # sell_amount = self.trade_exchange.round_amount_by_trade_unit(sell_amount, factor)\n                sell_order = Order(\n                    stock_id=code,\n                    amount=sell_amount,\n                    start_time=trade_start_time,\n                    end_time=trade_end_time,\n                    direction=Order.SELL,  # 0 for sell, 1 for buy\n                )\n                # is order executable\n                if self.trade_exchange.check_order(sell_order):\n                    sell_order_list.append(sell_order)\n                    trade_val, trade_cost, trade_price = self.trade_exchange.deal_order(\n                        sell_order, position=current_temp\n                    )\n                    # update cash\n                    cash += trade_val - trade_cost\n        # buy new stock\n        # note the current has been changed\n        # current_stock_list = current_temp.get_stock_list()\n        value = cash * self.risk_degree / len(buy) if len(buy) > 0 else 0\n\n        # open_cost should be considered in the real trading environment, while the backtest in evaluate.py does not\n        # consider it as the aim of demo is to accomplish same strategy as evaluate.py, so comment out this line\n        # value = value / (1+self.trade_exchange.open_cost) # set open_cost limit\n        for code in buy:\n            # check is stock suspended\n            if not self.trade_exchange.is_stock_tradable(\n                stock_id=code,\n                start_time=trade_start_time,\n                end_time=trade_end_time,\n                direction=None if self.forbid_all_trade_at_limit else OrderDir.BUY,\n            ):\n                continue\n            # buy order\n            buy_price = self.trade_exchange.get_deal_price(\n                stock_id=code, start_time=trade_start_time, end_time=trade_end_time, direction=OrderDir.BUY\n            )\n            buy_amount = value / buy_price\n            factor = self.trade_exchange.get_factor(stock_id=code, start_time=trade_start_time, end_time=trade_end_time)\n            buy_amount = self.trade_exchange.round_amount_by_trade_unit(buy_amount, factor)\n            buy_order = Order(\n                stock_id=code,\n                amount=buy_amount,\n                start_time=trade_start_time,\n                end_time=trade_end_time,\n                direction=Order.BUY,  # 1 for buy\n            )\n            buy_order_list.append(buy_order)\n        return TradeDecisionWO(sell_order_list + buy_order_list, self)\n\n\nclass WeightStrategyBase(BaseSignalStrategy):\n    # TODO:\n    # 1. Supporting leverage the get_range_limit result from the decision\n    # 2. Supporting alter_outer_trade_decision\n    # 3. Supporting checking the availability of trade decision\n    def __init__(\n        self,\n        *,\n        order_generator_cls_or_obj=OrderGenWOInteract,\n        **kwargs,\n    ):\n        \"\"\"\n        signal :\n            the information to describe a signal. Please refer to the docs of `qlib.backtest.signal.create_signal_from`\n            the decision of the strategy will base on the given signal\n        trade_exchange : Exchange\n            exchange that provides market info, used to deal order and generate report\n\n            - If `trade_exchange` is None, self.trade_exchange will be set with common_infra\n            - It allowes different trade_exchanges is used in different executions.\n            - For example:\n\n                - In daily execution, both daily exchange and minutely are usable, but the daily exchange is recommended because it runs faster.\n                - In minutely execution, the daily exchange is not usable, only the minutely exchange is recommended.\n        \"\"\"\n        super().__init__(**kwargs)\n\n        if isinstance(order_generator_cls_or_obj, type):\n            self.order_generator: OrderGenerator = order_generator_cls_or_obj()\n        else:\n            self.order_generator: OrderGenerator = order_generator_cls_or_obj\n\n    def generate_target_weight_position(self, score, current, trade_start_time, trade_end_time):\n        \"\"\"\n        Generate target position from score for this date and the current position.The cash is not considered in the position\n\n        Parameters\n        -----------\n        score : pd.Series\n            pred score for this trade date, index is stock_id, contain 'score' column.\n        current : Position()\n            current position.\n        trade_start_time: pd.Timestamp\n        trade_end_time: pd.Timestamp\n        \"\"\"\n        raise NotImplementedError()\n\n    def generate_trade_decision(self, execute_result=None):\n        # generate_trade_decision\n        # generate_target_weight_position() and generate_order_list_from_target_weight_position() to generate order_list\n\n        # get the number of trading step finished, trade_step can be [0, 1, 2, ..., trade_len - 1]\n        trade_step = self.trade_calendar.get_trade_step()\n        trade_start_time, trade_end_time = self.trade_calendar.get_step_time(trade_step)\n        pred_start_time, pred_end_time = self.trade_calendar.get_step_time(trade_step, shift=1)\n        pred_score = self.signal.get_signal(start_time=pred_start_time, end_time=pred_end_time)\n        if pred_score is None:\n            return TradeDecisionWO([], self)\n        current_temp = copy.deepcopy(self.trade_position)\n        assert isinstance(current_temp, Position)  # Avoid InfPosition\n\n        target_weight_position = self.generate_target_weight_position(\n            score=pred_score, current=current_temp, trade_start_time=trade_start_time, trade_end_time=trade_end_time\n        )\n        order_list = self.order_generator.generate_order_list_from_target_weight_position(\n            current=current_temp,\n            trade_exchange=self.trade_exchange,\n            risk_degree=self.get_risk_degree(trade_step),\n            target_weight_position=target_weight_position,\n            pred_start_time=pred_start_time,\n            pred_end_time=pred_end_time,\n            trade_start_time=trade_start_time,\n            trade_end_time=trade_end_time,\n        )\n        return TradeDecisionWO(order_list, self)\n\n\nclass EnhancedIndexingStrategy(WeightStrategyBase):\n    \"\"\"Enhanced Indexing Strategy\n\n    Enhanced indexing combines the arts of active management and passive management,\n    with the aim of outperforming a benchmark index (e.g., S&P 500) in terms of\n    portfolio return while controlling the risk exposure (a.k.a. tracking error).\n\n    Users need to prepare their risk model data like below:\n\n    .. code-block:: text\n\n         /path/to/riskmodel\n         20210101\n         factor_exp.{csv|pkl|h5}\n         factor_cov.{csv|pkl|h5}\n         specific_risk.{csv|pkl|h5}\n         blacklist.{csv|pkl|h5}  # optional\n\n    The risk model data can be obtained from risk data provider. You can also use\n    `qlib.model.riskmodel.structured.StructuredCovEstimator` to prepare these data.\n\n    Args:\n        riskmodel_path (str): risk model path\n        name_mapping (dict): alternative file names\n    \"\"\"\n\n    FACTOR_EXP_NAME = \"factor_exp.pkl\"\n    FACTOR_COV_NAME = \"factor_cov.pkl\"\n    SPECIFIC_RISK_NAME = \"specific_risk.pkl\"\n    BLACKLIST_NAME = \"blacklist.pkl\"\n\n    def __init__(\n        self,\n        *,\n        riskmodel_root,\n        market=\"csi500\",\n        turn_limit=None,\n        name_mapping={},\n        optimizer_kwargs={},\n        verbose=False,\n        **kwargs,\n    ):\n        super().__init__(**kwargs)\n\n        self.logger = get_module_logger(\"EnhancedIndexingStrategy\")\n\n        self.riskmodel_root = riskmodel_root\n        self.market = market\n        self.turn_limit = turn_limit\n\n        self.factor_exp_path = name_mapping.get(\"factor_exp\", self.FACTOR_EXP_NAME)\n        self.factor_cov_path = name_mapping.get(\"factor_cov\", self.FACTOR_COV_NAME)\n        self.specific_risk_path = name_mapping.get(\"specific_risk\", self.SPECIFIC_RISK_NAME)\n        self.blacklist_path = name_mapping.get(\"blacklist\", self.BLACKLIST_NAME)\n\n        self.optimizer = EnhancedIndexingOptimizer(**optimizer_kwargs)\n\n        self.verbose = verbose\n\n        self._riskdata_cache = {}\n\n    def get_risk_data(self, date):\n        if date in self._riskdata_cache:\n            return self._riskdata_cache[date]\n\n        root = self.riskmodel_root + \"/\" + date.strftime(\"%Y%m%d\")\n        if not os.path.exists(root):\n            return None\n\n        factor_exp = load_dataset(root + \"/\" + self.factor_exp_path, index_col=[0])\n        factor_cov = load_dataset(root + \"/\" + self.factor_cov_path, index_col=[0])\n        specific_risk = load_dataset(root + \"/\" + self.specific_risk_path, index_col=[0])\n\n        if not factor_exp.index.equals(specific_risk.index):\n            # NOTE: for stocks missing specific_risk, we always assume it has the highest volatility\n            specific_risk = specific_risk.reindex(factor_exp.index, fill_value=specific_risk.max())\n\n        universe = factor_exp.index.tolist()\n\n        blacklist = []\n        if os.path.exists(root + \"/\" + self.blacklist_path):\n            blacklist = load_dataset(root + \"/\" + self.blacklist_path).index.tolist()\n\n        self._riskdata_cache[date] = factor_exp.values, factor_cov.values, specific_risk.values, universe, blacklist\n\n        return self._riskdata_cache[date]\n\n    def generate_target_weight_position(self, score, current, trade_start_time, trade_end_time):\n        trade_date = trade_start_time\n        pre_date = get_pre_trading_date(trade_date, future=True)  # previous trade date\n\n        # load risk data\n        outs = self.get_risk_data(pre_date)\n        if outs is None:\n            self.logger.warning(f\"no risk data for {pre_date:%Y-%m-%d}, skip optimization\")\n            return None\n        factor_exp, factor_cov, specific_risk, universe, blacklist = outs\n\n        # transform score\n        # NOTE: for stocks missing score, we always assume they have the lowest score\n        score = score.reindex(universe).fillna(score.min()).values\n\n        # get current weight\n        # NOTE: if a stock is not in universe, its current weight will be zero\n        cur_weight = current.get_stock_weight_dict(only_stock=False)\n        cur_weight = np.array([cur_weight.get(stock, 0) for stock in universe])\n        assert all(cur_weight >= 0), \"current weight has negative values\"\n        cur_weight = cur_weight / self.get_risk_degree(trade_date)  # sum of weight should be risk_degree\n        if cur_weight.sum() > 1 and self.verbose:\n            self.logger.warning(f\"previous total holdings excess risk degree (current: {cur_weight.sum()})\")\n\n        # load bench weight\n        bench_weight = D.features(\n            D.instruments(\"all\"), [f\"${self.market}_weight\"], start_time=pre_date, end_time=pre_date\n        ).squeeze()\n        bench_weight.index = bench_weight.index.droplevel(level=\"datetime\")\n        bench_weight = bench_weight.reindex(universe).fillna(0).values\n\n        # whether stock tradable\n        # NOTE: currently we use last day volume to check whether tradable\n        tradable = D.features(D.instruments(\"all\"), [\"$volume\"], start_time=pre_date, end_time=pre_date).squeeze()\n        tradable.index = tradable.index.droplevel(level=\"datetime\")\n        tradable = tradable.reindex(universe).gt(0).values\n        mask_force_hold = ~tradable\n\n        # mask force sell\n        mask_force_sell = np.array([stock in blacklist for stock in universe], dtype=bool)\n\n        # optimize\n        weight = self.optimizer(\n            r=score,\n            F=factor_exp,\n            cov_b=factor_cov,\n            var_u=specific_risk**2,\n            w0=cur_weight,\n            wb=bench_weight,\n            mfh=mask_force_hold,\n            mfs=mask_force_sell,\n        )\n\n        target_weight_position = {stock: weight for stock, weight in zip(universe, weight) if weight > 0}\n\n        if self.verbose:\n            self.logger.info(\"trade date: {:%Y-%m-%d}\".format(trade_date))\n            self.logger.info(\"number of holding stocks: {}\".format(len(target_weight_position)))\n            self.logger.info(\"total holding weight: {:.6f}\".format(weight.sum()))\n\n        return target_weight_position\n"
        }
      ]
    },
    {
      "id": 6,
      "name": "strategy_plugin_system",
      "source_repo": "freqtrade/freqtrade",
      "files": [
        {
          "path": "freqtrade/strategy/interface.py",
          "url": "https://github.com/freqtrade/freqtrade/blob/develop/freqtrade/strategy/interface.py",
          "lines": "1-1883",
          "code": "\"\"\"\nIStrategy interface\nThis module defines the interface to apply for strategies\n\"\"\"\n\nimport logging\nfrom abc import ABC, abstractmethod\nfrom datetime import UTC, datetime, timedelta\nfrom math import isinf, isnan\n\nfrom pandas import DataFrame\nfrom pydantic import ValidationError\n\nfrom freqtrade.configuration import TimeRange\nfrom freqtrade.constants import CUSTOM_TAG_MAX_LENGTH, Config, IntOrInf, ListPairsWithTimeframes\nfrom freqtrade.data.converter import populate_dataframe_with_trades\nfrom freqtrade.data.converter.converter import reduce_dataframe_footprint\nfrom freqtrade.data.dataprovider import DataProvider\nfrom freqtrade.enums import (\n    CandleType,\n    ExitCheckTuple,\n    ExitType,\n    MarketDirection,\n    RunMode,\n    SignalDirection,\n    SignalTagType,\n    SignalType,\n    TradingMode,\n)\nfrom freqtrade.exceptions import OperationalException, StrategyError\nfrom freqtrade.exchange import timeframe_to_minutes, timeframe_to_next_date, timeframe_to_seconds\nfrom freqtrade.ft_types import AnnotationType\nfrom freqtrade.misc import remove_entry_exit_signals\nfrom freqtrade.persistence import Order, PairLocks, Trade\nfrom freqtrade.strategy.hyper import HyperStrategyMixin\nfrom freqtrade.strategy.informative_decorator import (\n    InformativeData,\n    PopulateIndicators,\n    _create_and_merge_informative_pair,\n    _format_pair_name,\n)\nfrom freqtrade.strategy.strategy_validation import StrategyResultValidator\nfrom freqtrade.strategy.strategy_wrapper import strategy_safe_wrapper\nfrom freqtrade.util import dt_now, dt_ts\nfrom freqtrade.wallets import Wallets\n\n\nlogger = logging.getLogger(__name__)\n\n\nclass IStrategy(ABC, HyperStrategyMixin):\n    \"\"\"\n    Interface for freqtrade strategies\n    Defines the mandatory structure must follow any custom strategies\n\n    Attributes you can use:\n        minimal_roi -> Dict: Minimal ROI designed for the strategy\n        stoploss -> float: optimal stoploss designed for the strategy\n        timeframe -> str: value of the timeframe to use with the strategy\n    \"\"\"\n\n    # Strategy interface version\n    # Default to version 2\n    # Version 1 is the initial interface without metadata dict - deprecated and no longer supported.\n    # Version 2 populate_* include metadata dict\n    # Version 3 - First version with short and leverage support\n    INTERFACE_VERSION: int = 3\n\n    _ft_params_from_file: dict\n    # associated minimal roi\n    minimal_roi: dict = {}\n    use_custom_roi: bool = False\n\n    # associated stoploss\n    stoploss: float\n\n    # max open trades for the strategy\n    max_open_trades: IntOrInf\n\n    # trailing stoploss\n    trailing_stop: bool = False\n    trailing_stop_positive: float | None = None\n    trailing_stop_positive_offset: float = 0.0\n    trailing_only_offset_is_reached = False\n    use_custom_stoploss: bool = False\n\n    # Can this strategy go short?\n    can_short: bool = False\n\n    # associated timeframe\n    timeframe: str\n\n    # Optional order types\n    order_types: dict = {\n        \"entry\": \"limit\",\n        \"exit\": \"limit\",\n        \"stoploss\": \"limit\",\n        \"stoploss_on_exchange\": False,\n        \"stoploss_on_exchange_interval\": 60,\n    }\n\n    # Optional time in force\n    order_time_in_force: dict = {\n        \"entry\": \"GTC\",\n        \"exit\": \"GTC\",\n    }\n\n    # run \"populate_indicators\" only for new candle\n    process_only_new_candles: bool = True\n\n    use_exit_signal: bool\n    exit_profit_only: bool\n    exit_profit_offset: float\n    ignore_roi_if_entry_signal: bool\n\n    # Position adjustment is disabled by default\n    position_adjustment_enable: bool = False\n    max_entry_position_adjustment: int = -1\n\n    # Number of seconds after which the candle will no longer result in a buy on expired candles\n    ignore_buying_expired_candle_after: int = 0\n\n    # Disable checking the dataframe (converts the error into a warning message)\n    disable_dataframe_checks: bool = False\n\n    # Count of candles the strategy requires before producing valid signals\n    startup_candle_count: int = 0\n\n    # Protections\n    protections: list = []\n\n    # Class level variables (intentional) containing\n    # the dataprovider (dp) (access to other candles, historic data, ...)\n    # and wallets - access to the current balance.\n    dp: DataProvider\n    wallets: Wallets | None = None\n    # Filled from configuration\n    stake_currency: str\n    # container variable for strategy source code\n    __source__: str = \"\"\n    __file__: str = \"\"\n\n    # Definition of plot_config. See plotting documentation for more details.\n    plot_config: dict = {}\n\n    # A self set parameter that represents the market direction. filled from configuration\n    market_direction: MarketDirection = MarketDirection.NONE\n\n    # Global cache dictionary\n    _cached_grouped_trades_per_pair: dict[str, DataFrame] = {}\n\n    def __init__(self, config: Config) -> None:\n        self.config = config\n        # Dict to determine if analysis is necessary\n        self.__last_candle_seen_per_pair: dict[str, datetime] = {}\n        super().__init__(config)\n\n        # Gather informative pairs from @informative-decorated methods.\n        self._ft_informative: list[tuple[InformativeData, PopulateIndicators]] = []\n        for attr_name in dir(self.__class__):\n            cls_method = getattr(self.__class__, attr_name)\n            if not callable(cls_method):\n                continue\n            informative_data_list = getattr(cls_method, \"_ft_informative\", None)\n            if not isinstance(informative_data_list, list):\n                # Type check is required because mocker would return a mock object that evaluates to\n                # True, confusing this code.\n                continue\n            strategy_timeframe_minutes = timeframe_to_minutes(self.timeframe)\n            for informative_data in informative_data_list:\n                if timeframe_to_minutes(informative_data.timeframe) < strategy_timeframe_minutes:\n                    raise OperationalException(\n                        \"Informative timeframe must be equal or higher than strategy timeframe!\"\n                    )\n                if not informative_data.candle_type:\n                    informative_data.candle_type = config[\"candle_type_def\"]\n                self._ft_informative.append((informative_data, cls_method))\n\n    def load_freqAI_model(self) -> None:\n        if self.config.get(\"freqai\", {}).get(\"enabled\", False):\n            # Import here to avoid importing this if freqAI is disabled\n            from freqtrade.freqai.utils import download_all_data_for_training\n            from freqtrade.resolvers.freqaimodel_resolver import FreqaiModelResolver\n\n            self.freqai = FreqaiModelResolver.load_freqaimodel(self.config)\n            self.freqai_info = self.config[\"freqai\"]\n\n            # download the desired data in dry/live\n            if self.config.get(\"runmode\") in (RunMode.DRY_RUN, RunMode.LIVE):\n                logger.info(\n                    \"Downloading all training data for all pairs in whitelist and \"\n                    \"corr_pairlist, this may take a while if the data is not \"\n                    \"already on disk.\"\n                )\n                download_all_data_for_training(self.dp, self.config)\n        else:\n            # Gracious failures if freqAI is disabled but \"start\" is called.\n            class DummyClass:\n                def start(self, *args, **kwargs):\n                    raise OperationalException(\n                        \"freqAI is not enabled. \"\n                        \"Please enable it in your config to use this strategy.\"\n                    )\n\n                def shutdown(self, *args, **kwargs):\n                    pass\n\n            self.freqai = DummyClass()  # type: ignore\n\n    def ft_bot_start(self, **kwargs) -> None:\n        \"\"\"\n        Strategy init - runs after dataprovider has been added.\n        Must call bot_start()\n        \"\"\"\n        self.load_freqAI_model()\n\n        strategy_safe_wrapper(self.bot_start)()\n\n        self.ft_load_hyper_params(self.config.get(\"runmode\") == RunMode.HYPEROPT)\n\n    def ft_bot_cleanup(self) -> None:\n        \"\"\"\n        Clean up FreqAI and child threads\n        \"\"\"\n        self.freqai.shutdown()\n\n    @abstractmethod\n    def populate_indicators(self, dataframe: DataFrame, metadata: dict) -> DataFrame:\n        \"\"\"\n        Populate indicators that will be used in the Buy, Sell, Short, Exit_short strategy\n        :param dataframe: DataFrame with data from the exchange\n        :param metadata: Additional information, like the currently traded pair\n        :return: a Dataframe with all mandatory indicators for the strategies\n        \"\"\"\n        return dataframe\n\n    def populate_buy_trend(self, dataframe: DataFrame, metadata: dict) -> DataFrame:\n        \"\"\"\n        DEPRECATED - please migrate to populate_entry_trend\n        :param dataframe: DataFrame\n        :param metadata: Additional information, like the currently traded pair\n        :return: DataFrame with buy column\n        \"\"\"\n        return dataframe\n\n    def populate_entry_trend(self, dataframe: DataFrame, metadata: dict) -> DataFrame:\n        \"\"\"\n        Based on TA indicators, populates the entry signal for the given dataframe\n        :param dataframe: DataFrame\n        :param metadata: Additional information, like the currently traded pair\n        :return: DataFrame with entry columns populated\n        \"\"\"\n        return self.populate_buy_trend(dataframe, metadata)\n\n    def populate_sell_trend(self, dataframe: DataFrame, metadata: dict) -> DataFrame:\n        \"\"\"\n        DEPRECATED - please migrate to populate_exit_trend\n        Based on TA indicators, populates the sell signal for the given dataframe\n        :param dataframe: DataFrame\n        :param metadata: Additional information, like the currently traded pair\n        :return: DataFrame with sell column\n        \"\"\"\n        return dataframe\n\n    def populate_exit_trend(self, dataframe: DataFrame, metadata: dict) -> DataFrame:\n        \"\"\"\n        Based on TA indicators, populates the exit signal for the given dataframe\n        :param dataframe: DataFrame\n        :param metadata: Additional information, like the currently traded pair\n        :return: DataFrame with exit columns populated\n        \"\"\"\n        return self.populate_sell_trend(dataframe, metadata)\n\n    def bot_start(self, **kwargs) -> None:\n        \"\"\"\n        Called only once after bot instantiation.\n        :param **kwargs: Ensure to keep this here so updates to this won't break your strategy.\n        \"\"\"\n        pass\n\n    def bot_loop_start(self, current_time: datetime, **kwargs) -> None:\n        \"\"\"\n        Called at the start of the bot iteration (one loop).\n        Might be used to perform pair-independent tasks\n        (e.g. gather some remote resource for comparison)\n        :param current_time: datetime object, containing the current datetime\n        :param **kwargs: Ensure to keep this here so updates to this won't break your strategy.\n        \"\"\"\n        pass\n\n    def check_buy_timeout(\n        self, pair: str, trade: Trade, order: Order, current_time: datetime, **kwargs\n    ) -> bool:\n        \"\"\"\n        DEPRECATED: Please use `check_entry_timeout` instead.\n        \"\"\"\n        return False\n\n    def check_entry_timeout(\n        self, pair: str, trade: Trade, order: Order, current_time: datetime, **kwargs\n    ) -> bool:\n        \"\"\"\n        Check entry timeout function callback.\n        This method can be used to override the entry-timeout.\n        It is called whenever a limit entry order has been created,\n        and is not yet fully filled.\n        Configuration options in `unfilledtimeout` will be verified before this,\n        so ensure to set these timeouts high enough.\n\n        When not implemented by a strategy, this simply returns False.\n        :param pair: Pair the trade is for\n        :param trade: Trade object.\n        :param order: Order object.\n        :param current_time: datetime object, containing the current datetime\n        :param **kwargs: Ensure to keep this here so updates to this won't break your strategy.\n        :return bool: When True is returned, then the entry order is cancelled.\n        \"\"\"\n        return self.check_buy_timeout(\n            pair=pair, trade=trade, order=order, current_time=current_time\n        )\n\n    def check_sell_timeout(\n        self, pair: str, trade: Trade, order: Order, current_time: datetime, **kwargs\n    ) -> bool:\n        \"\"\"\n        DEPRECATED: Please use `check_exit_timeout` instead.\n        \"\"\"\n        return False\n\n    def check_exit_timeout(\n        self, pair: str, trade: Trade, order: Order, current_time: datetime, **kwargs\n    ) -> bool:\n        \"\"\"\n        Check exit timeout function callback.\n        This method can be used to override the exit-timeout.\n        It is called whenever a limit exit order has been created,\n        and is not yet fully filled.\n        Configuration options in `unfilledtimeout` will be verified before this,\n        so ensure to set these timeouts high enough.\n\n        When not implemented by a strategy, this simply returns False.\n        :param pair: Pair the trade is for\n        :param trade: Trade object.\n        :param order: Order object\n        :param current_time: datetime object, containing the current datetime\n        :param **kwargs: Ensure to keep this here so updates to this won't break your strategy.\n        :return bool: When True is returned, then the exit-order is cancelled.\n        \"\"\"\n        return self.check_sell_timeout(\n            pair=pair, trade=trade, order=order, current_time=current_time\n        )\n\n    def confirm_trade_entry(\n        self,\n        pair: str,\n        order_type: str,\n        amount: float,\n        rate: float,\n        time_in_force: str,\n        current_time: datetime,\n        entry_tag: str | None,\n        side: str,\n        **kwargs,\n    ) -> bool:\n        \"\"\"\n        Called right before placing a entry order.\n        Timing for this function is critical, so avoid doing heavy computations or\n        network requests in this method.\n\n        For full documentation please go to https://www.freqtrade.io/en/latest/strategy-advanced/\n\n        When not implemented by a strategy, returns True (always confirming).\n\n        :param pair: Pair that's about to be bought/shorted.\n        :param order_type: Order type (as configured in order_types). usually limit or market.\n        :param amount: Amount in target (base) currency that's going to be traded.\n        :param rate: Rate that's going to be used when using limit orders\n                     or current rate for market orders.\n        :param time_in_force: Time in force. Defaults to GTC (Good-til-cancelled).\n        :param current_time: datetime object, containing the current datetime\n        :param entry_tag: Optional entry_tag (buy_tag) if provided with the buy signal.\n        :param side: 'long' or 'short' - indicating the direction of the proposed trade\n        :param **kwargs: Ensure to keep this here so updates to this won't break your strategy.\n        :return bool: When True is returned, then the buy-order is placed on the exchange.\n            False aborts the process\n        \"\"\"\n        return True\n\n    def confirm_trade_exit(\n        self,\n        pair: str,\n        trade: Trade,\n        order_type: str,\n        amount: float,\n        rate: float,\n        time_in_force: str,\n        exit_reason: str,\n        current_time: datetime,\n        **kwargs,\n    ) -> bool:\n        \"\"\"\n        Called right before placing a regular exit order.\n        Timing for this function is critical, so avoid doing heavy computations or\n        network requests in this method.\n\n        For full documentation please go to https://www.freqtrade.io/en/latest/strategy-advanced/\n\n        When not implemented by a strategy, returns True (always confirming).\n\n        :param pair: Pair for trade that's about to be exited.\n        :param trade: trade object.\n        :param order_type: Order type (as configured in order_types). usually limit or market.\n        :param amount: Amount in base currency.\n        :param rate: Rate that's going to be used when using limit orders\n                     or current rate for market orders.\n        :param time_in_force: Time in force. Defaults to GTC (Good-til-cancelled).\n        :param exit_reason: Exit reason.\n            Can be any of ['roi', 'stop_loss', 'stoploss_on_exchange', 'trailing_stop_loss',\n                           'exit_signal', 'force_exit', 'emergency_exit']\n        :param current_time: datetime object, containing the current datetime\n        :param **kwargs: Ensure to keep this here so updates to this won't break your strategy.\n        :return bool: When True, then the exit-order is placed on the exchange.\n            False aborts the process\n        \"\"\"\n        return True\n\n    def order_filled(\n        self, pair: str, trade: Trade, order: Order, current_time: datetime, **kwargs\n    ) -> None:\n        \"\"\"\n        Called right after an order fills.\n        Will be called for all order types (entry, exit, stoploss, position adjustment).\n        :param pair: Pair for trade\n        :param trade: trade object.\n        :param order: Order object.\n        :param current_time: datetime object, containing the current datetime\n        :param **kwargs: Ensure to keep this here so updates to this won't break your strategy.\n        \"\"\"\n        pass\n\n    def custom_stoploss(\n        self,\n        pair: str,\n        trade: Trade,\n        current_time: datetime,\n        current_rate: float,\n        current_profit: float,\n        after_fill: bool,\n        **kwargs,\n    ) -> float | None:\n        \"\"\"\n        Custom stoploss logic, returning the new distance relative to current_rate (as ratio).\n        e.g. returning -0.05 would create a stoploss 5% below current_rate.\n        The custom stoploss can never be below self.stoploss, which serves as a hard maximum loss.\n\n        For full documentation please go to https://www.freqtrade.io/en/latest/strategy-advanced/\n\n        When not implemented by a strategy, returns the initial stoploss value.\n        Only called when use_custom_stoploss is set to True.\n\n        :param pair: Pair that's currently analyzed\n        :param trade: trade object.\n        :param current_time: datetime object, containing the current datetime\n        :param current_rate: Rate, calculated based on pricing settings in exit_pricing.\n        :param current_profit: Current profit (as ratio), calculated based on current_rate.\n        :param after_fill: True if the stoploss is called after the order was filled.\n        :param **kwargs: Ensure to keep this here so updates to this won't break your strategy.\n        :return float: New stoploss value, relative to the current_rate\n        \"\"\"\n        return self.stoploss\n\n    def custom_roi(\n        self,\n        pair: str,\n        trade: Trade,\n        current_time: datetime,\n        trade_duration: int,\n        entry_tag: str | None,\n        side: str,\n        **kwargs,\n    ) -> float | None:\n        \"\"\"\n        Custom ROI logic, returns a new minimum ROI threshold (as a ratio, e.g., 0.05 for +5%).\n        Only called when use_custom_roi is set to True.\n\n        If used at the same time as minimal_roi, an exit will be triggered when the lower\n        threshold is reached. Example: If minimal_roi = {\"0\": 0.01} and custom_roi returns 0.05,\n        an exit will be triggered if profit reaches 5%.\n\n        :param pair: Pair that's currently analyzed.\n        :param trade: trade object.\n        :param current_time: datetime object, containing the current datetime.\n        :param trade_duration: Current trade duration in minutes.\n        :param entry_tag: Optional entry_tag (buy_tag) if provided with the buy signal.\n        :param side: 'long' or 'short' - indicating the direction of the current trade.\n        :param **kwargs: Ensure to keep this here so updates to this won't break your strategy.\n        :return float: New ROI value as a ratio, or None to fall back to minimal_roi logic.\n        \"\"\"\n        return None\n\n    def custom_entry_price(\n        self,\n        pair: str,\n        trade: Trade | None,\n        current_time: datetime,\n        proposed_rate: float,\n        entry_tag: str | None,\n        side: str,\n        **kwargs,\n    ) -> float:\n        \"\"\"\n        Custom entry price logic, returning the new entry price.\n\n        For full documentation please go to https://www.freqtrade.io/en/latest/strategy-advanced/\n\n        When not implemented by a strategy, returns None, orderbook is used to set entry price\n\n        :param pair: Pair that's currently analyzed\n        :param trade: trade object (None for initial entries).\n        :param current_time: datetime object, containing the current datetime\n        :param proposed_rate: Rate, calculated based on pricing settings in exit_pricing.\n        :param entry_tag: Optional entry_tag (buy_tag) if provided with the buy signal.\n        :param side: 'long' or 'short' - indicating the direction of the proposed trade\n        :param **kwargs: Ensure to keep this here so updates to this won't break your strategy.\n        :return float: New entry price value if provided\n        \"\"\"\n        return proposed_rate\n\n    def custom_exit_price(\n        self,\n        pair: str,\n        trade: Trade,\n        current_time: datetime,\n        proposed_rate: float,\n        current_profit: float,\n        exit_tag: str | None,\n        **kwargs,\n    ) -> float:\n        \"\"\"\n        Custom exit price logic, returning the new exit price.\n\n        For full documentation please go to https://www.freqtrade.io/en/latest/strategy-advanced/\n\n        When not implemented by a strategy, returns None, orderbook is used to set exit price\n\n        :param pair: Pair that's currently analyzed\n        :param trade: trade object.\n        :param current_time: datetime object, containing the current datetime\n        :param proposed_rate: Rate, calculated based on pricing settings in exit_pricing.\n        :param current_profit: Current profit (as ratio), calculated based on current_rate.\n        :param exit_tag: Exit reason.\n        :param **kwargs: Ensure to keep this here so updates to this won't break your strategy.\n        :return float: New exit price value if provided\n        \"\"\"\n        return proposed_rate\n\n    def custom_sell(\n        self,\n        pair: str,\n        trade: Trade,\n        current_time: datetime,\n        current_rate: float,\n        current_profit: float,\n        **kwargs,\n    ) -> str | bool | None:\n        \"\"\"\n        DEPRECATED - please use custom_exit instead.\n        Custom exit signal logic indicating that specified position should be sold. Returning a\n        string or True from this method is equal to setting exit signal on a candle at specified\n        time. This method is not called when exit signal is set.\n\n        This method should be overridden to create exit signals that depend on trade parameters. For\n        example you could implement an exit relative to the candle when the trade was opened,\n        or a custom 1:2 risk-reward ROI.\n\n        Custom exit reason max length is 64. Exceeding characters will be removed.\n\n        :param pair: Pair that's currently analyzed\n        :param trade: trade object.\n        :param current_time: datetime object, containing the current datetime\n        :param current_rate: Rate, calculated based on pricing settings in exit_pricing.\n        :param current_profit: Current profit (as ratio), calculated based on current_rate.\n        :param **kwargs: Ensure to keep this here so updates to this won't break your strategy.\n        :return: To execute exit, return a string with custom exit reason or True. Otherwise return\n        None or False.\n        \"\"\"\n        return None\n\n    def custom_exit(\n        self,\n        pair: str,\n        trade: Trade,\n        current_time: datetime,\n        current_rate: float,\n        current_profit: float,\n        **kwargs,\n    ) -> str | bool | None:\n        \"\"\"\n        Custom exit signal logic indicating that specified position should be sold. Returning a\n        string or True from this method is equal to setting exit signal on a candle at specified\n        time. This method is not called when exit signal is set.\n\n        This method should be overridden to create exit signals that depend on trade parameters. For\n        example you could implement an exit relative to the candle when the trade was opened,\n        or a custom 1:2 risk-reward ROI.\n\n        Custom exit reason max length is 64. Exceeding characters will be removed.\n\n        :param pair: Pair that's currently analyzed\n        :param trade: trade object.\n        :param current_time: datetime object, containing the current datetime\n        :param current_rate: Rate, calculated based on pricing settings in exit_pricing.\n        :param current_profit: Current profit (as ratio), calculated based on current_rate.\n        :param **kwargs: Ensure to keep this here so updates to this won't break your strategy.\n        :return: To execute exit, return a string with custom exit reason or True. Otherwise return\n        None or False.\n        \"\"\"\n        return self.custom_sell(pair, trade, current_time, current_rate, current_profit, **kwargs)\n\n    def custom_stake_amount(\n        self,\n        pair: str,\n        current_time: datetime,\n        current_rate: float,\n        proposed_stake: float,\n        min_stake: float | None,\n        max_stake: float,\n        leverage: float,\n        entry_tag: str | None,\n        side: str,\n        **kwargs,\n    ) -> float:\n        \"\"\"\n        Customize stake size for each new trade.\n\n        :param pair: Pair that's currently analyzed\n        :param current_time: datetime object, containing the current datetime\n        :param current_rate: Rate, calculated based on pricing settings in exit_pricing.\n        :param proposed_stake: A stake amount proposed by the bot.\n        :param min_stake: Minimal stake size allowed by exchange.\n        :param max_stake: Balance available for trading.\n        :param leverage: Leverage selected for this trade.\n        :param entry_tag: Optional entry_tag (buy_tag) if provided with the buy signal.\n        :param side: 'long' or 'short' - indicating the direction of the proposed trade\n        :return: A stake size, which is between min_stake and max_stake.\n        \"\"\"\n        return proposed_stake\n\n    def adjust_trade_position(\n        self,\n        trade: Trade,\n        current_time: datetime,\n        current_rate: float,\n        current_profit: float,\n        min_stake: float | None,\n        max_stake: float,\n        current_entry_rate: float,\n        current_exit_rate: float,\n        current_entry_profit: float,\n        current_exit_profit: float,\n        **kwargs,\n    ) -> float | None | tuple[float | None, str | None]:\n        \"\"\"\n        Custom trade adjustment logic, returning the stake amount that a trade should be\n        increased or decreased.\n        This means extra entry or exit orders with additional fees.\n        Only called when `position_adjustment_enable` is set to True.\n\n        For full documentation please go to https://www.freqtrade.io/en/latest/strategy-advanced/\n\n        When not implemented by a strategy, returns None\n\n        :param trade: trade object.\n        :param current_time: datetime object, containing the current datetime\n        :param current_rate: Current entry rate (same as current_entry_profit)\n        :param current_profit: Current profit (as ratio), calculated based on current_rate\n                               (same as current_entry_profit).\n        :param min_stake: Minimal stake size allowed by exchange (for both entries and exits)\n        :param max_stake: Maximum stake allowed (either through balance, or by exchange limits).\n        :param current_entry_rate: Current rate using entry pricing.\n        :param current_exit_rate: Current rate using exit pricing.\n        :param current_entry_profit: Current profit using entry pricing.\n        :param current_exit_profit: Current profit using exit pricing.\n        :param **kwargs: Ensure to keep this here so updates to this won't break your strategy.\n        :return float: Stake amount to adjust your trade,\n                       Positive values to increase position, Negative values to decrease position.\n                       Return None for no action.\n                       Optionally, return a tuple with a 2nd element with an order reason\n        \"\"\"\n        return None\n\n    def adjust_entry_price(\n        self,\n        trade: Trade,\n        order: Order | None,\n        pair: str,\n        current_time: datetime,\n        proposed_rate: float,\n        current_order_rate: float,\n        entry_tag: str | None,\n        side: str,\n        **kwargs,\n    ) -> float | None:\n        \"\"\"\n        Entry price re-adjustment logic, returning the user desired limit price.\n        This only executes when a order was already placed, still open (unfilled fully or partially)\n        and not timed out on subsequent candles after entry trigger.\n\n        For full documentation please go to https://www.freqtrade.io/en/latest/strategy-callbacks/\n\n        When not implemented by a strategy, returns current_order_rate as default.\n        If current_order_rate is returned then the existing order is maintained.\n        If None is returned then order gets canceled but not replaced by a new one.\n\n        :param pair: Pair that's currently analyzed\n        :param trade: Trade object.\n        :param order: Order object\n        :param current_time: datetime object, containing the current datetime\n        :param proposed_rate: Rate, calculated based on pricing settings in entry_pricing.\n        :param current_order_rate: Rate of the existing order in place.\n        :param entry_tag: Optional entry_tag (buy_tag) if provided with the buy signal.\n        :param side: 'long' or 'short' - indicating the direction of the proposed trade\n        :param **kwargs: Ensure to keep this here so updates to this won't break your strategy.\n        :return float or None: New entry price value if provided\n\n        \"\"\"\n        return current_order_rate\n\n    def adjust_exit_price(\n        self,\n        trade: Trade,\n        order: Order | None,\n        pair: str,\n        current_time: datetime,\n        proposed_rate: float,\n        current_order_rate: float,\n        entry_tag: str | None,\n        side: str,\n        **kwargs,\n    ) -> float | None:\n        \"\"\"\n        Exit price re-adjustment logic, returning the user desired limit price.\n        This only executes when a order was already placed, still open (unfilled fully or partially)\n        and not timed out on subsequent candles after entry trigger.\n\n        For full documentation please go to https://www.freqtrade.io/en/latest/strategy-callbacks/\n\n        When not implemented by a strategy, returns current_order_rate as default.\n        If current_order_rate is returned then the existing order is maintained.\n        If None is returned then order gets canceled but not replaced by a new one.\n\n        :param pair: Pair that's currently analyzed\n        :param trade: Trade object.\n        :param order: Order object\n        :param current_time: datetime object, containing the current datetime\n        :param proposed_rate: Rate, calculated based on pricing settings in entry_pricing.\n        :param current_order_rate: Rate of the existing order in place.\n        :param entry_tag: Optional entry_tag (buy_tag) if provided with the buy signal.\n        :param side: 'long' or 'short' - indicating the direction of the proposed trade\n        :param **kwargs: Ensure to keep this here so updates to this won't break your strategy.\n        :return float or None: New exit price value if provided\n\n        \"\"\"\n        return current_order_rate\n\n    def adjust_order_price(\n        self,\n        trade: Trade,\n        order: Order | None,\n        pair: str,\n        current_time: datetime,\n        proposed_rate: float,\n        current_order_rate: float,\n        entry_tag: str | None,\n        side: str,\n        is_entry: bool,\n        **kwargs,\n    ) -> float | None:\n        \"\"\"\n        Exit and entry order price re-adjustment logic, returning the user desired limit price.\n        This only executes when a order was already placed, still open (unfilled fully or partially)\n        and not timed out on subsequent candles after entry trigger.\n\n        For full documentation please go to https://www.freqtrade.io/en/latest/strategy-callbacks/\n\n        When not implemented by a strategy, returns current_order_rate as default.\n        If current_order_rate is returned then the existing order is maintained.\n        If None is returned then order gets canceled but not replaced by a new one.\n\n        :param pair: Pair that's currently analyzed\n        :param trade: Trade object.\n        :param order: Order object\n        :param current_time: datetime object, containing the current datetime\n        :param proposed_rate: Rate, calculated based on pricing settings in entry_pricing.\n        :param current_order_rate: Rate of the existing order in place.\n        :param entry_tag: Optional entry_tag (buy_tag) if provided with the buy signal.\n        :param side: 'long' or 'short' - indicating the direction of the proposed trade\n        :param is_entry: True if the order is an entry order, False if it's an exit order.\n        :param **kwargs: Ensure to keep this here so updates to this won't break your strategy.\n        :return float or None: New entry price value if provided\n        \"\"\"\n        if is_entry:\n            return self.adjust_entry_price(\n                trade=trade,\n                order=order,\n                pair=pair,\n                current_time=current_time,\n                proposed_rate=proposed_rate,\n                current_order_rate=current_order_rate,\n                entry_tag=entry_tag,\n                side=side,\n                **kwargs,\n            )\n        else:\n            return self.adjust_exit_price(\n                trade=trade,\n                order=order,\n                pair=pair,\n                current_time=current_time,\n                proposed_rate=proposed_rate,\n                current_order_rate=current_order_rate,\n                entry_tag=entry_tag,\n                side=side,\n                **kwargs,\n            )\n\n    def leverage(\n        self,\n        pair: str,\n        current_time: datetime,\n        current_rate: float,\n        proposed_leverage: float,\n        max_leverage: float,\n        entry_tag: str | None,\n        side: str,\n        **kwargs,\n    ) -> float:\n        \"\"\"\n        Customize leverage for each new trade. This method is only called in futures mode.\n\n        :param pair: Pair that's currently analyzed\n        :param current_time: datetime object, containing the current datetime\n        :param current_rate: Rate, calculated based on pricing settings in exit_pricing.\n        :param proposed_leverage: A leverage proposed by the bot.\n        :param max_leverage: Max leverage allowed on this pair\n        :param entry_tag: Optional entry_tag (buy_tag) if provided with the buy signal.\n        :param side: 'long' or 'short' - indicating the direction of the proposed trade\n        :return: A leverage amount, which is between 1.0 and max_leverage.\n        \"\"\"\n        return 1.0\n\n    def informative_pairs(self) -> ListPairsWithTimeframes:\n        \"\"\"\n        Define additional, informative pair/interval combinations to be cached from the exchange.\n        These pair/interval combinations are non-tradable, unless they are part\n        of the whitelist as well.\n        For more information, please consult the documentation\n        :return: List of tuples in the format (pair, interval)\n            Sample: return [(\"ETH/USDT\", \"5m\"),\n                            (\"BTC/USDT\", \"15m\"),\n                            ]\n        \"\"\"\n        return []\n\n    def version(self) -> str | None:\n        \"\"\"\n        Returns version of the strategy.\n        \"\"\"\n        return None\n\n    def plot_annotations(\n        self, pair: str, start_date: datetime, end_date: datetime, dataframe: DataFrame, **kwargs\n    ) -> list[AnnotationType]:\n        \"\"\"\n        Retrieve area annotations for a chart.\n        Must be returned as array, with type, label, color, start, end, y_start, y_end.\n        All settings except for type are optional - though it usually makes sense to include either\n        \"start and end\" or \"y_start and y_end\" for either horizontal or vertical plots\n        (or all 4 for boxes).\n        :param pair: Pair that's currently analyzed\n        :param start_date: Start date of the chart data being requested\n        :param end_date: End date of the chart data being requested\n        :param dataframe: DataFrame with the analyzed data for the chart\n        :param **kwargs: Ensure to keep this here so updates to this won't break your strategy.\n        :return: List of AnnotationType objects\n        \"\"\"\n        return []\n\n    def populate_any_indicators(\n        self,\n        pair: str,\n        df: DataFrame,\n        tf: str,\n        informative: DataFrame | None = None,\n        set_generalized_indicators: bool = False,\n    ) -> DataFrame:\n        \"\"\"\n        DEPRECATED - USE FEATURE ENGINEERING FUNCTIONS INSTEAD\n        Function designed to automatically generate, name and merge features\n        from user indicated timeframes in the configuration file. User can add\n        additional features here, but must follow the naming convention.\n        This method is *only* used in FreqaiDataKitchen class and therefore\n        it is only called if FreqAI is active.\n        :param pair: pair to be used as informative\n        :param df: strategy dataframe which will receive merges from informatives\n        :param tf: timeframe of the dataframe which will modify the feature names\n        :param informative: the dataframe associated with the informative pair\n        \"\"\"\n        return df\n\n    def feature_engineering_expand_all(\n        self, dataframe: DataFrame, period: int, metadata: dict, **kwargs\n    ) -> DataFrame:\n        \"\"\"\n        *Only functional with FreqAI enabled strategies*\n        This function will automatically expand the defined features on the config defined\n        `indicator_periods_candles`, `include_timeframes`, `include_shifted_candles`, and\n        `include_corr_pairs`. In other words, a single feature defined in this function\n        will automatically expand to a total of\n        `indicator_periods_candles` * `include_timeframes` * `include_shifted_candles` *\n        `include_corr_pairs` numbers of features added to the model.\n\n        All features must be prepended with `%` to be recognized by FreqAI internals.\n\n        More details on how these config defined parameters accelerate feature engineering\n        in the documentation at:\n\n        https://www.freqtrade.io/en/latest/freqai-parameter-table/#feature-parameters\n\n        https://www.freqtrade.io/en/latest/freqai-feature-engineering/#defining-the-features\n\n        :param dataframe: strategy dataframe which will receive the features\n        :param period: period of the indicator - usage example:\n        :param metadata: metadata of current pair\n        dataframe[\"%-ema-period\"] = ta.EMA(dataframe, timeperiod=period)\n        \"\"\"\n        return dataframe\n\n    def feature_engineering_expand_basic(\n        self, dataframe: DataFrame, metadata: dict, **kwargs\n    ) -> DataFrame:\n        \"\"\"\n        *Only functional with FreqAI enabled strategies*\n        This function will automatically expand the defined features on the config defined\n        `include_timeframes`, `include_shifted_candles`, and `include_corr_pairs`.\n        In other words, a single feature defined in this function\n        will automatically expand to a total of\n        `include_timeframes` * `include_shifted_candles` * `include_corr_pairs`\n        numbers of features added to the model.\n\n        Features defined here will *not* be automatically duplicated on user defined\n        `indicator_periods_candles`\n\n        All features must be prepended with `%` to be recognized by FreqAI internals.\n\n        More details on how these config defined parameters accelerate feature engineering\n        in the documentation at:\n\n        https://www.freqtrade.io/en/latest/freqai-parameter-table/#feature-parameters\n\n        https://www.freqtrade.io/en/latest/freqai-feature-engineering/#defining-the-features\n\n        :param dataframe: strategy dataframe which will receive the features\n        :param metadata: metadata of current pair\n        dataframe[\"%-pct-change\"] = dataframe[\"close\"].pct_change()\n        dataframe[\"%-ema-200\"] = ta.EMA(dataframe, timeperiod=200)\n        \"\"\"\n        return dataframe\n\n    def feature_engineering_standard(\n        self, dataframe: DataFrame, metadata: dict, **kwargs\n    ) -> DataFrame:\n        \"\"\"\n        *Only functional with FreqAI enabled strategies*\n        This optional function will be called once with the dataframe of the base timeframe.\n        This is the final function to be called, which means that the dataframe entering this\n        function will contain all the features and columns created by all other\n        freqai_feature_engineering_* functions.\n\n        This function is a good place to do custom exotic feature extractions (e.g. tsfresh).\n        This function is a good place for any feature that should not be auto-expanded upon\n        (e.g. day of the week).\n\n        All features must be prepended with `%` to be recognized by FreqAI internals.\n\n        More details about feature engineering available:\n\n        https://www.freqtrade.io/en/latest/freqai-feature-engineering\n\n        :param dataframe: strategy dataframe which will receive the features\n        :param metadata: metadata of current pair\n        usage example: dataframe[\"%-day_of_week\"] = (dataframe[\"date\"].dt.dayofweek + 1) / 7\n        \"\"\"\n        return dataframe\n\n    def set_freqai_targets(self, dataframe: DataFrame, metadata: dict, **kwargs) -> DataFrame:\n        \"\"\"\n        *Only functional with FreqAI enabled strategies*\n        Required function to set the targets for the model.\n        All targets must be prepended with `&` to be recognized by the FreqAI internals.\n\n        More details about feature engineering available:\n\n        https://www.freqtrade.io/en/latest/freqai-feature-engineering\n\n        :param dataframe: strategy dataframe which will receive the targets\n        :param metadata: metadata of current pair\n        usage example: dataframe[\"&-target\"] = dataframe[\"close\"].shift(-1) / dataframe[\"close\"]\n        \"\"\"\n        return dataframe\n\n    ###\n    # END - Intended to be overridden by strategy\n    ###\n\n    _ft_stop_uses_after_fill = False\n\n    def _adjust_trade_position_internal(\n        self,\n        trade: Trade,\n        current_time: datetime,\n        current_rate: float,\n        current_profit: float,\n        min_stake: float | None,\n        max_stake: float,\n        current_entry_rate: float,\n        current_exit_rate: float,\n        current_entry_profit: float,\n        current_exit_profit: float,\n        **kwargs,\n    ) -> tuple[float | None, str]:\n        \"\"\"\n        wrapper around adjust_trade_position to handle the return value\n        \"\"\"\n        resp = strategy_safe_wrapper(\n            self.adjust_trade_position, default_retval=(None, \"\"), supress_error=True\n        )(\n            trade=trade,\n            current_time=current_time,\n            current_rate=current_rate,\n            current_profit=current_profit,\n            min_stake=min_stake,\n            max_stake=max_stake,\n            current_entry_rate=current_entry_rate,\n            current_exit_rate=current_exit_rate,\n            current_entry_profit=current_entry_profit,\n            current_exit_profit=current_exit_profit,\n            **kwargs,\n        )\n        order_tag = \"\"\n        if isinstance(resp, tuple):\n            if len(resp) >= 1:\n                stake_amount = resp[0]\n            if len(resp) > 1:\n                order_tag = resp[1] or \"\"\n        else:\n            stake_amount = resp\n        return stake_amount, order_tag\n\n    def __informative_pairs_freqai(self) -> ListPairsWithTimeframes:\n        \"\"\"\n        Create informative-pairs needed for FreqAI\n        \"\"\"\n        if self.config.get(\"freqai\", {}).get(\"enabled\", False):\n            whitelist_pairs = self.dp.current_whitelist()\n            candle_type = self.config.get(\"candle_type_def\", CandleType.SPOT)\n            corr_pairs = self.config[\"freqai\"][\"feature_parameters\"][\"include_corr_pairlist\"]\n            informative_pairs = []\n            for tf in self.config[\"freqai\"][\"feature_parameters\"][\"include_timeframes\"]:\n                for pair in set(whitelist_pairs + corr_pairs):\n                    informative_pairs.append((pair, tf, candle_type))\n            return informative_pairs\n\n        return []\n\n    def gather_informative_pairs(self) -> ListPairsWithTimeframes:\n        \"\"\"\n        Internal method which gathers all informative pairs (user or automatically defined).\n        \"\"\"\n        informative_pairs = self.informative_pairs()\n        # Compatibility code for 2 tuple informative pairs\n        informative_pairs = [\n            (\n                p[0],\n                p[1],\n                (\n                    CandleType.from_string(p[2])\n                    if len(p) > 2 and p[2] != \"\"\n                    else self.config.get(\"candle_type_def\", CandleType.SPOT)\n                ),\n            )\n            for p in informative_pairs\n        ]\n        for inf_data, _ in self._ft_informative:\n            # Get default candle type if not provided explicitly.\n            candle_type = (\n                inf_data.candle_type\n                if inf_data.candle_type\n                else self.config.get(\"candle_type_def\", CandleType.SPOT)\n            )\n            if inf_data.asset:\n                if any(s in inf_data.asset for s in (\"{BASE}\", \"{base}\")):\n                    for pair in self.dp.current_whitelist():\n                        pair_tf = (\n                            _format_pair_name(self.config, inf_data.asset, self.dp.market(pair)),\n                            inf_data.timeframe,\n                            candle_type,\n                        )\n                        informative_pairs.append(pair_tf)\n\n                else:\n                    pair_tf = (\n                        _format_pair_name(self.config, inf_data.asset),\n                        inf_data.timeframe,\n                        candle_type,\n                    )\n                    informative_pairs.append(pair_tf)\n            else:\n                for pair in self.dp.current_whitelist():\n                    informative_pairs.append((pair, inf_data.timeframe, candle_type))\n        informative_pairs.extend(self.__informative_pairs_freqai())\n        return list(set(informative_pairs))\n\n    def get_strategy_name(self) -> str:\n        \"\"\"\n        Returns strategy class name\n        \"\"\"\n        return self.__class__.__name__\n\n    def lock_pair(\n        self, pair: str, until: datetime, reason: str | None = None, side: str = \"*\"\n    ) -> None:\n        \"\"\"\n        Locks pair until a given timestamp happens.\n        Locked pairs are not analyzed, and are prevented from opening new trades.\n        Locks can only count up (allowing users to lock pairs for a longer period of time).\n        To remove a lock from a pair, use `unlock_pair()`\n        :param pair: Pair to lock\n        :param until: datetime in UTC until the pair should be blocked from opening new trades.\n                Needs to be timezone aware `datetime.now(timezone.utc)`\n        :param reason: Optional string explaining why the pair was locked.\n        :param side: Side to check, can be long, short or '*'\n        \"\"\"\n        PairLocks.lock_pair(pair, until, reason, side=side)\n\n    def unlock_pair(self, pair: str) -> None:\n        \"\"\"\n        Unlocks a pair previously locked using lock_pair.\n        Not used by freqtrade itself, but intended to be used if users lock pairs\n        manually from within the strategy, to allow an easy way to unlock pairs.\n        :param pair: Unlock pair to allow trading again\n        \"\"\"\n        PairLocks.unlock_pair(pair, datetime.now(UTC))\n\n    def unlock_reason(self, reason: str) -> None:\n        \"\"\"\n        Unlocks all pairs previously locked using lock_pair with specified reason.\n        Not used by freqtrade itself, but intended to be used if users lock pairs\n        manually from within the strategy, to allow an easy way to unlock pairs.\n        :param reason: Unlock pairs to allow trading again\n        \"\"\"\n        PairLocks.unlock_reason(reason, datetime.now(UTC))\n\n    def is_pair_locked(\n        self, pair: str, *, candle_date: datetime | None = None, side: str = \"*\"\n    ) -> bool:\n        \"\"\"\n        Checks if a pair is currently locked\n        The 2nd, optional parameter ensures that locks are applied until the new candle arrives,\n        and not stop at 14:00:00 - while the next candle arrives at 14:00:02 leaving a gap\n        of 2 seconds for an entry order to happen on an old signal.\n        :param pair: \"Pair to check\"\n        :param candle_date: Date of the last candle. Optional, defaults to current date\n        :param side: Side to check, can be long, short or '*'\n        :returns: locking state of the pair in question.\n        \"\"\"\n\n        if not candle_date:\n            # Simple call ...\n            return PairLocks.is_pair_locked(pair, side=side)\n        else:\n            lock_time = timeframe_to_next_date(self.timeframe, candle_date)\n            return PairLocks.is_pair_locked(pair, lock_time, side=side)\n\n    def analyze_ticker(self, dataframe: DataFrame, metadata: dict) -> DataFrame:\n        \"\"\"\n        Parses the given candle (OHLCV) data and returns a populated DataFrame\n        add several TA indicators and entry order signal to it\n        Should only be used in live.\n        :param dataframe: Dataframe containing data from exchange\n        :param metadata: Metadata dictionary with additional data (e.g. 'pair')\n        :return: DataFrame of candle (OHLCV) data with indicator data and signals added\n        \"\"\"\n        logger.debug(\"TA Analysis Launched\")\n        dataframe = self.advise_indicators(dataframe, metadata)\n        dataframe = self.advise_entry(dataframe, metadata)\n        dataframe = self.advise_exit(dataframe, metadata)\n        logger.debug(\"TA Analysis Ended\")\n        return dataframe\n\n    def _analyze_ticker_internal(self, dataframe: DataFrame, metadata: dict) -> DataFrame:\n        \"\"\"\n        Parses the given candle (OHLCV) data and returns a populated DataFrame\n        add several TA indicators and buy signal to it\n        WARNING: Used internally only, may skip analysis if `process_only_new_candles` is set.\n        :param dataframe: Dataframe containing data from exchange\n        :param metadata: Metadata dictionary with additional data (e.g. 'pair')\n        :return: DataFrame of candle (OHLCV) data with indicator data and signals added\n        \"\"\"\n        pair = str(metadata.get(\"pair\"))\n\n        new_candle = self.__last_candle_seen_per_pair.get(pair, None) != dataframe.iloc[-1][\"date\"]\n        # Test if seen this pair and last candle before.\n        # always run if process_only_new_candles is set to false\n        if not self.process_only_new_candles or new_candle:\n            # Defs that only make change on new candle data.\n            dataframe = self.analyze_ticker(dataframe, metadata)\n\n            self.__last_candle_seen_per_pair[pair] = dataframe.iloc[-1][\"date\"]\n\n            candle_type = self.config.get(\"candle_type_def\", CandleType.SPOT)\n            self.dp._set_cached_df(pair, self.timeframe, dataframe, candle_type=candle_type)\n            self.dp._emit_df((pair, self.timeframe, candle_type), dataframe, new_candle)\n\n        else:\n            logger.debug(\"Skipping TA Analysis for already analyzed candle\")\n            dataframe = remove_entry_exit_signals(dataframe)\n\n        logger.debug(\"Loop Analysis Launched\")\n\n        return dataframe\n\n    def analyze_pair(self, pair: str) -> None:\n        \"\"\"\n        Fetch data for this pair from dataprovider and analyze.\n        Stores the dataframe into the dataprovider.\n        The analyzed dataframe is then accessible via `dp.get_analyzed_dataframe()`.\n        :param pair: Pair to analyze.\n        \"\"\"\n        dataframe = self.dp.ohlcv(\n            pair, self.timeframe, candle_type=self.config.get(\"candle_type_def\", CandleType.SPOT)\n        )\n        if not isinstance(dataframe, DataFrame) or dataframe.empty:\n            logger.warning(\"Empty candle (OHLCV) data for pair %s\", pair)\n            return\n\n        try:\n            validator = StrategyResultValidator(\n                dataframe, warn_only=not self.disable_dataframe_checks\n            )\n\n            dataframe = strategy_safe_wrapper(self._analyze_ticker_internal, message=\"\")(\n                dataframe, {\"pair\": pair}\n            )\n\n            validator.assert_df(dataframe)\n        except StrategyError as error:\n            logger.warning(f\"Unable to analyze candle (OHLCV) data for pair {pair}: {error}\")\n            return\n\n        if dataframe.empty:\n            logger.warning(\"Empty dataframe for pair %s\", pair)\n            return\n\n    def analyze(self, pairs: list[str]) -> None:\n        \"\"\"\n        Analyze all pairs using analyze_pair().\n        :param pairs: List of pairs to analyze\n        \"\"\"\n        for pair in pairs:\n            self.analyze_pair(pair)\n\n    def get_latest_candle(\n        self,\n        pair: str,\n        timeframe: str,\n        dataframe: DataFrame,\n    ) -> tuple[DataFrame | None, datetime | None]:\n        \"\"\"\n        Calculates current signal based based on the entry order or exit order\n        columns of the dataframe.\n        Used by Bot to get the signal to enter, or exit\n        :param pair: pair in format ANT/BTC\n        :param timeframe: timeframe to use\n        :param dataframe: Analyzed dataframe to get signal from.\n        :return: (None, None) or (Dataframe, latest_date) - corresponding to the last candle\n        \"\"\"\n        if not isinstance(dataframe, DataFrame) or dataframe.empty:\n            logger.warning(f\"Empty candle (OHLCV) data for pair {pair}\")\n            return None, None\n\n        try:\n            latest_date_pd = dataframe[\"date\"].max()\n            latest = dataframe.loc[dataframe[\"date\"] == latest_date_pd].iloc[-1]\n        except Exception as e:\n            logger.warning(f\"Unable to get latest candle (OHLCV) data for pair {pair} - {e}\")\n            return None, None\n        # Explicitly convert to datetime object to ensure the below comparison does not fail\n        latest_date: datetime = latest_date_pd.to_pydatetime()\n\n        # Check if dataframe is out of date\n        timeframe_minutes = timeframe_to_minutes(timeframe)\n        offset = self.config.get(\"exchange\", {}).get(\"outdated_offset\", 5)\n        if latest_date < (dt_now() - timedelta(minutes=timeframe_minutes * 2 + offset)):\n            logger.warning(\n                \"Outdated history for pair %s. Last tick is %s minutes old\",\n                pair,\n                int((dt_now() - latest_date).total_seconds() // 60),\n            )\n            return None, None\n        return latest, latest_date\n\n    def get_exit_signal(\n        self, pair: str, timeframe: str, dataframe: DataFrame, is_short: bool | None = None\n    ) -> tuple[bool, bool, str | None]:\n        \"\"\"\n        Calculates current exit signal based based on the dataframe\n        columns of the dataframe.\n        Used by Bot to get the signal to exit.\n        depending on is_short, looks at \"short\" or \"long\" columns.\n        :param pair: pair in format ANT/BTC\n        :param timeframe: timeframe to use\n        :param dataframe: Analyzed dataframe to get signal from.\n        :param is_short: Indicating existing trade direction.\n        :return: (enter, exit) A bool-tuple with enter / exit values.\n        \"\"\"\n        latest, _latest_date = self.get_latest_candle(pair, timeframe, dataframe)\n        if latest is None:\n            return False, False, None\n\n        if is_short:\n            enter = latest.get(SignalType.ENTER_SHORT.value, 0) == 1\n            exit_ = latest.get(SignalType.EXIT_SHORT.value, 0) == 1\n\n        else:\n            enter = latest.get(SignalType.ENTER_LONG.value, 0) == 1\n            exit_ = latest.get(SignalType.EXIT_LONG.value, 0) == 1\n        exit_tag = latest.get(SignalTagType.EXIT_TAG.value, None)\n        # Tags can be None, which does not resolve to False.\n        exit_tag = exit_tag if isinstance(exit_tag, str) and exit_tag != \"nan\" else None\n\n        logger.debug(f\"exit-trigger: {latest['date']} (pair={pair}) enter={enter} exit={exit_}\")\n\n        return enter, exit_, exit_tag\n\n    def get_entry_signal(\n        self,\n        pair: str,\n        timeframe: str,\n        dataframe: DataFrame,\n    ) -> tuple[SignalDirection | None, str | None]:\n        \"\"\"\n        Calculates current entry signal based based on the dataframe signals\n        columns of the dataframe.\n        Used by Bot to get the signal to enter trades.\n        :param pair: pair in format ANT/BTC\n        :param timeframe: timeframe to use\n        :param dataframe: Analyzed dataframe to get signal from.\n        :return: (SignalDirection, entry_tag)\n        \"\"\"\n        latest, latest_date = self.get_latest_candle(pair, timeframe, dataframe)\n        if latest is None or latest_date is None:\n            return None, None\n\n        enter_long = latest.get(SignalType.ENTER_LONG.value, 0) == 1\n        exit_long = latest.get(SignalType.EXIT_LONG.value, 0) == 1\n        enter_short = latest.get(SignalType.ENTER_SHORT.value, 0) == 1\n        exit_short = latest.get(SignalType.EXIT_SHORT.value, 0) == 1\n\n        enter_signal: SignalDirection | None = None\n        enter_tag: str | None = None\n        if enter_long == 1 and not any([exit_long, enter_short]):\n            enter_signal = SignalDirection.LONG\n            enter_tag = latest.get(SignalTagType.ENTER_TAG.value, None)\n        if (\n            self.config.get(\"trading_mode\", TradingMode.SPOT) != TradingMode.SPOT\n            and self.can_short\n            and enter_short == 1\n            and not any([exit_short, enter_long])\n        ):\n            enter_signal = SignalDirection.SHORT\n            enter_tag = latest.get(SignalTagType.ENTER_TAG.value, None)\n\n        enter_tag = enter_tag if isinstance(enter_tag, str) and enter_tag != \"nan\" else None\n\n        timeframe_seconds = timeframe_to_seconds(timeframe)\n\n        if self.ignore_expired_candle(\n            latest_date=latest_date,\n            current_time=dt_now(),\n            timeframe_seconds=timeframe_seconds,\n            enter=bool(enter_signal),\n        ):\n            return None, enter_tag\n\n        logger.debug(\n            f\"entry trigger: {latest['date']} (pair={pair}) \"\n            f\"enter={enter_long} enter_tag_value={enter_tag}\"\n        )\n        return enter_signal, enter_tag\n\n    def ignore_expired_candle(\n        self, latest_date: datetime, current_time: datetime, timeframe_seconds: int, enter: bool\n    ):\n        if self.ignore_buying_expired_candle_after and enter:\n            time_delta = current_time - (latest_date + timedelta(seconds=timeframe_seconds))\n            return time_delta.total_seconds() > self.ignore_buying_expired_candle_after\n        else:\n            return False\n\n    def should_exit(\n        self,\n        trade: Trade,\n        rate: float,\n        current_time: datetime,\n        *,\n        enter: bool,\n        exit_: bool,\n        low: float | None = None,\n        high: float | None = None,\n        force_stoploss: float = 0,\n    ) -> list[ExitCheckTuple]:\n        \"\"\"\n        This function evaluates if one of the conditions required to trigger an exit order\n        has been reached, which can either be a stop-loss, ROI or exit-signal.\n        :param low: Only used during backtesting to simulate (long)stoploss/(short)ROI\n        :param high: Only used during backtesting, to simulate (short)stoploss/(long)ROI\n        :param force_stoploss: Externally provided stoploss\n        :return: List of exit reasons - or empty list.\n        \"\"\"\n        exits: list[ExitCheckTuple] = []\n        current_rate = rate\n        current_profit = trade.calc_profit_ratio(current_rate)\n        current_profit_best = current_profit\n        if low is not None or high is not None:\n            # Set current rate to high for backtesting ROI exits\n            current_rate_best = (low if trade.is_short else high) or rate\n            current_profit_best = trade.calc_profit_ratio(current_rate_best)\n\n        trade.adjust_min_max_rates(high or current_rate, low or current_rate)\n\n        stoplossflag = self.ft_stoploss_reached(\n            current_rate=current_rate,\n            trade=trade,\n            current_time=current_time,\n            current_profit=current_profit,\n            force_stoploss=force_stoploss,\n            low=low,\n            high=high,\n        )\n\n        # if enter signal and ignore_roi is set, we don't need to evaluate min_roi.\n        roi_reached = not (enter and self.ignore_roi_if_entry_signal) and self.min_roi_reached(\n            trade=trade, current_profit=current_profit_best, current_time=current_time\n        )\n\n        exit_signal = ExitType.NONE\n        custom_reason = \"\"\n\n        if self.use_exit_signal:\n            if exit_ and not enter:\n                exit_signal = ExitType.EXIT_SIGNAL\n            else:\n                reason_cust = strategy_safe_wrapper(self.custom_exit, default_retval=False)(\n                    pair=trade.pair,\n                    trade=trade,\n                    current_time=current_time,\n                    current_rate=current_rate,\n                    current_profit=current_profit,\n                )\n                if reason_cust:\n                    exit_signal = ExitType.CUSTOM_EXIT\n                    if isinstance(reason_cust, str):\n                        custom_reason = reason_cust\n                        if len(reason_cust) > CUSTOM_TAG_MAX_LENGTH:\n                            logger.warning(\n                                f\"Custom exit reason returned from \"\n                                f\"custom_exit is too long and was trimmed\"\n                                f\"to {CUSTOM_TAG_MAX_LENGTH} characters.\"\n                            )\n                            custom_reason = reason_cust[:CUSTOM_TAG_MAX_LENGTH]\n                    else:\n                        custom_reason = \"\"\n            if exit_signal == ExitType.CUSTOM_EXIT or (\n                exit_signal == ExitType.EXIT_SIGNAL\n                and (not self.exit_profit_only or current_profit > self.exit_profit_offset)\n            ):\n                logger.debug(\n                    f\"{trade.pair} - Sell signal received. \"\n                    f\"exit_type=ExitType.{exit_signal.name}\"\n                    + (f\", custom_reason={custom_reason}\" if custom_reason else \"\")\n                )\n                exits.append(ExitCheckTuple(exit_type=exit_signal, exit_reason=custom_reason))\n\n        # Sequence:\n        # Exit-signal\n        # Stoploss\n        # ROI\n        # Trailing stoploss\n\n        if stoplossflag.exit_type in (ExitType.STOP_LOSS, ExitType.LIQUIDATION):\n            logger.debug(f\"{trade.pair} - Stoploss hit. exit_type={stoplossflag.exit_type}\")\n            exits.append(stoplossflag)\n\n        if roi_reached:\n            logger.debug(f\"{trade.pair} - Required profit reached. exit_type=ExitType.ROI\")\n            exits.append(ExitCheckTuple(exit_type=ExitType.ROI))\n\n        if stoplossflag.exit_type == ExitType.TRAILING_STOP_LOSS:\n            logger.debug(f\"{trade.pair} - Trailing stoploss hit.\")\n            exits.append(stoplossflag)\n\n        return exits\n\n    def ft_stoploss_adjust(\n        self,\n        current_rate: float,\n        trade: Trade,\n        current_time: datetime,\n        current_profit: float,\n        force_stoploss: float,\n        low: float | None = None,\n        high: float | None = None,\n        after_fill: bool = False,\n    ) -> None:\n        \"\"\"\n        Adjust stop-loss dynamically if configured to do so.\n        :param current_profit: current profit as ratio\n        :param low: Low value of this candle, only set in backtesting\n        :param high: High value of this candle, only set in backtesting\n        \"\"\"\n        if after_fill and not self._ft_stop_uses_after_fill:\n            # Skip if the strategy doesn't support after fill.\n            return\n\n        stop_loss_value = force_stoploss if force_stoploss else self.stoploss\n\n        # Initiate stoploss with open_rate. Does nothing if stoploss is already set.\n        trade.adjust_stop_loss(trade.open_rate, stop_loss_value, initial=True)\n\n        dir_correct = (\n            trade.stop_loss < (low or current_rate)\n            if not trade.is_short\n            else trade.stop_loss > (high or current_rate)\n        )\n\n        # Make sure current_profit is calculated using high for backtesting.\n        bound = low if trade.is_short else high\n        bound_profit = current_profit if not bound else trade.calc_profit_ratio(bound)\n        if self.use_custom_stoploss and dir_correct:\n            stop_loss_value_custom = strategy_safe_wrapper(\n                self.custom_stoploss, default_retval=None, supress_error=True\n            )(\n                pair=trade.pair,\n                trade=trade,\n                current_time=current_time,\n                current_rate=(bound or current_rate),\n                current_profit=bound_profit,\n                after_fill=after_fill,\n            )\n            # Sanity check - error cases will return None\n            if stop_loss_value_custom and not (\n                isnan(stop_loss_value_custom) or isinf(stop_loss_value_custom)\n            ):\n                stop_loss_value = stop_loss_value_custom\n                trade.adjust_stop_loss(\n                    bound or current_rate, stop_loss_value, allow_refresh=after_fill\n                )\n            else:\n                logger.debug(\"CustomStoploss function did not return valid stoploss\")\n\n        if self.trailing_stop and dir_correct:\n            # trailing stoploss handling\n            sl_offset = self.trailing_stop_positive_offset\n            # Make sure current_profit is calculated using high for backtesting.\n\n            # Don't update stoploss if trailing_only_offset_is_reached is true.\n            if not (self.trailing_only_offset_is_reached and bound_profit < sl_offset):\n                # Specific handling for trailing_stop_positive\n                if self.trailing_stop_positive is not None and bound_profit > sl_offset:\n                    stop_loss_value = self.trailing_stop_positive\n                    logger.debug(\n                        f\"{trade.pair} - Using positive stoploss: {stop_loss_value} \"\n                        f\"offset: {sl_offset:.4g} profit: {bound_profit:.2%}\"\n                    )\n\n                trade.adjust_stop_loss(bound or current_rate, stop_loss_value)\n\n    def ft_stoploss_reached(\n        self,\n        current_rate: float,\n        trade: Trade,\n        current_time: datetime,\n        current_profit: float,\n        force_stoploss: float,\n        low: float | None = None,\n        high: float | None = None,\n    ) -> ExitCheckTuple:\n        \"\"\"\n        Based on current profit of the trade and configured (trailing) stoploss,\n        decides to exit or not\n        :param current_profit: current profit as ratio\n        :param low: Low value of this candle, only set in backtesting\n        :param high: High value of this candle, only set in backtesting\n        \"\"\"\n        self.ft_stoploss_adjust(\n            current_rate, trade, current_time, current_profit, force_stoploss, low, high\n        )\n\n        sl_higher_long = trade.stop_loss >= (low or current_rate) and not trade.is_short\n        sl_lower_short = trade.stop_loss <= (high or current_rate) and trade.is_short\n        liq_higher_long = (\n            trade.liquidation_price\n            and trade.liquidation_price >= (low or current_rate)\n            and not trade.is_short\n        )\n        liq_lower_short = (\n            trade.liquidation_price\n            and trade.liquidation_price <= (high or current_rate)\n            and trade.is_short\n        )\n\n        # evaluate if the stoploss was hit if stoploss is not on exchange\n        # in Dry-Run, this handles stoploss logic as well, as the logic will not be different to\n        # regular stoploss handling.\n        if (sl_higher_long or sl_lower_short) and (\n            not self.order_types.get(\"stoploss_on_exchange\") or self.config[\"dry_run\"]\n        ):\n            exit_type = ExitType.STOP_LOSS\n\n            # If initial stoploss is not the same as current one then it is trailing.\n            if trade.is_stop_loss_trailing:\n                exit_type = ExitType.TRAILING_STOP_LOSS\n                logger.debug(\n                    f\"{trade.pair} - HIT STOP: current price at \"\n                    f\"{((high if trade.is_short else low) or current_rate):.6f}, \"\n                    f\"stoploss is {trade.stop_loss:.6f}, \"\n                    f\"initial stoploss was at {trade.initial_stop_loss:.6f}, \"\n                    f\"trade opened at {trade.open_rate:.6f}\"\n                )\n\n            return ExitCheckTuple(exit_type=exit_type)\n\n        if liq_higher_long or liq_lower_short:\n            logger.debug(f\"{trade.pair} - Liquidation price hit. exit_type=ExitType.LIQUIDATION\")\n            return ExitCheckTuple(exit_type=ExitType.LIQUIDATION)\n\n        return ExitCheckTuple(exit_type=ExitType.NONE)\n\n    def min_roi_reached_entry(\n        self,\n        trade: Trade,\n        trade_dur: int,\n        current_time: datetime,\n    ) -> tuple[int | None, float | None]:\n        \"\"\"\n        Based on trade duration defines the ROI entry that may have been reached.\n        :param trade_dur: trade duration in minutes\n        :return: minimal ROI entry value or None if none proper ROI entry was found.\n        \"\"\"\n\n        # Get custom ROI if use_custom_roi is set to True\n        custom_roi = None\n        if self.use_custom_roi:\n            custom_roi = strategy_safe_wrapper(\n                self.custom_roi, default_retval=None, supress_error=True\n            )(\n                pair=trade.pair,\n                trade=trade,\n                current_time=current_time,\n                trade_duration=trade_dur,\n                entry_tag=trade.enter_tag,\n                side=trade.trade_direction,\n            )\n            if custom_roi is None or isnan(custom_roi) or isinf(custom_roi):\n                custom_roi = None\n                logger.debug(f\"Custom ROI function did not return a valid ROI for {trade.pair}\")\n\n        # Get highest entry in ROI dict where key <= trade-duration\n        roi_list = [x for x in self.minimal_roi.keys() if x <= trade_dur]\n        if roi_list:\n            roi_entry = max(roi_list)\n            min_roi = self.minimal_roi[roi_entry]\n        else:\n            roi_entry = None\n            min_roi = None\n\n        # The lowest available value is used to trigger an exit.\n        if custom_roi is not None and (min_roi is None or custom_roi < min_roi):\n            return trade_dur, custom_roi\n        else:\n            return roi_entry, min_roi\n\n    def min_roi_reached(self, trade: Trade, current_profit: float, current_time: datetime) -> bool:\n        \"\"\"\n        Based on trade duration, current profit of the trade and ROI configuration,\n        decides whether bot should exit.\n        :param current_profit: current profit as ratio\n        :return: True if bot should exit at current rate\n        \"\"\"\n        # Check if time matches and current rate is above threshold\n        trade_dur = int((current_time.timestamp() - trade.open_date_utc.timestamp()) // 60)\n        _, roi = self.min_roi_reached_entry(trade, trade_dur, current_time)\n        if roi is None:\n            return False\n        else:\n            return current_profit > roi\n\n    def ft_check_timed_out(self, trade: Trade, order: Order, current_time: datetime) -> bool:\n        \"\"\"\n        FT Internal method.\n        Check if timeout is active, and if the order is still open and timed out\n        \"\"\"\n        side = \"entry\" if order.ft_order_side == trade.entry_side else \"exit\"\n\n        timeout = self.config.get(\"unfilledtimeout\", {}).get(side)\n        if timeout is not None:\n            timeout_unit = self.config.get(\"unfilledtimeout\", {}).get(\"unit\", \"minutes\")\n            timeout_kwargs = {timeout_unit: -timeout}\n            timeout_threshold = current_time + timedelta(**timeout_kwargs)\n            timedout = order.status == \"open\" and order.order_date_utc <= timeout_threshold\n            if timedout:\n                return True\n        time_method = (\n            self.check_exit_timeout\n            if order.ft_order_side == trade.exit_side\n            else self.check_entry_timeout\n        )\n\n        return strategy_safe_wrapper(time_method, default_retval=False)(\n            pair=trade.pair, trade=trade, order=order, current_time=current_time\n        )\n\n    def advise_all_indicators(self, data: dict[str, DataFrame]) -> dict[str, DataFrame]:\n        \"\"\"\n        Populates indicators for given candle (OHLCV) data (for multiple pairs)\n        Does not run advise_entry or advise_exit!\n        Used by optimize operations only, not during dry / live runs.\n        Using .copy() to get a fresh copy of the dataframe for every strategy run.\n        Also copy on output to avoid PerformanceWarnings pandas 1.3.0 started to show.\n        Has positive effects on memory usage for whatever reason - also when\n        using only one strategy.\n        \"\"\"\n        res = {}\n        for pair, pair_data in data.items():\n            validator = StrategyResultValidator(\n                pair_data, warn_only=not self.disable_dataframe_checks\n            )\n            res[pair] = self.advise_indicators(pair_data.copy(), {\"pair\": pair}).copy()\n            validator.assert_df(res[pair])\n        return res\n\n    def ft_advise_signals(self, dataframe: DataFrame, metadata: dict) -> DataFrame:\n        \"\"\"\n        Call advise_entry and advise_exit and return the resulting dataframe.\n        :param dataframe: Dataframe containing data from exchange, as well as pre-calculated\n                          indicators\n        :param metadata: Metadata dictionary with additional data (e.g. 'pair')\n        :return: DataFrame of candle (OHLCV) data with indicator data and signals added\n\n        \"\"\"\n\n        dataframe = self.advise_entry(dataframe, metadata)\n        dataframe = self.advise_exit(dataframe, metadata)\n        return dataframe\n\n    def _if_enabled_populate_trades(self, dataframe: DataFrame, metadata: dict) -> DataFrame:\n        use_public_trades = self.config.get(\"exchange\", {}).get(\"use_public_trades\", False)\n        if use_public_trades:\n            pair = metadata[\"pair\"]\n            # Build timerange from dataframe date column\n            if not dataframe.empty:\n                start_ts = dt_ts(dataframe[\"date\"].iloc[0])\n                end_ts = dt_ts(dataframe[\"date\"].iloc[-1])\n                timerange = TimeRange(\"date\", \"date\", startts=start_ts, stopts=end_ts)\n            else:\n                timerange = None\n\n            trades = self.dp.trades(pair=pair, copy=False, timerange=timerange)\n\n            cached_grouped_trades: DataFrame | None = self._cached_grouped_trades_per_pair.get(pair)\n            dataframe, cached_grouped_trades = populate_dataframe_with_trades(\n                cached_grouped_trades, self.config, dataframe, trades\n            )\n\n            # dereference old cache\n            if pair in self._cached_grouped_trades_per_pair:\n                del self._cached_grouped_trades_per_pair[pair]\n            self._cached_grouped_trades_per_pair[pair] = cached_grouped_trades\n\n            logger.debug(\"Populated dataframe with trades.\")\n        return dataframe\n\n    def advise_indicators(self, dataframe: DataFrame, metadata: dict) -> DataFrame:\n        \"\"\"\n        Populate indicators that will be used in the Buy, Sell, short, exit_short strategy\n        This method should not be overridden.\n        :param dataframe: Dataframe with data from the exchange\n        :param metadata: Additional information, like the currently traded pair\n        :return: a Dataframe with all mandatory indicators for the strategies\n        \"\"\"\n        logger.debug(f\"Populating indicators for pair {metadata.get('pair')}.\")\n\n        # call populate_indicators_Nm() which were tagged with @informative decorator.\n        for inf_data, populate_fn in self._ft_informative:\n            dataframe = _create_and_merge_informative_pair(\n                self, dataframe, metadata, inf_data, populate_fn\n            )\n\n        dataframe = self._if_enabled_populate_trades(dataframe, metadata)\n        dataframe = self.populate_indicators(dataframe, metadata)\n        if self.config.get(\"reduce_df_footprint\", False) and self.config.get(\"runmode\") not in [\n            RunMode.DRY_RUN,\n            RunMode.LIVE,\n        ]:\n            dataframe = reduce_dataframe_footprint(dataframe)\n        return dataframe\n\n    def advise_entry(self, dataframe: DataFrame, metadata: dict) -> DataFrame:\n        \"\"\"\n        Based on TA indicators, populates the entry order signal for the given dataframe\n        This method should not be overridden.\n        :param dataframe: DataFrame\n        :param metadata: Additional information dictionary, with details like the\n            currently traded pair\n        :return: DataFrame with buy column\n        \"\"\"\n\n        logger.debug(f\"Populating enter signals for pair {metadata.get('pair')}.\")\n        # Initialize column to work around Pandas bug #56503.\n        dataframe.loc[:, \"enter_tag\"] = \"\"\n        df = self.populate_entry_trend(dataframe, metadata)\n        if \"enter_long\" not in df.columns:\n            df = df.rename({\"buy\": \"enter_long\", \"buy_tag\": \"enter_tag\"}, axis=\"columns\")\n\n        return df\n\n    def advise_exit(self, dataframe: DataFrame, metadata: dict) -> DataFrame:\n        \"\"\"\n        Based on TA indicators, populates the exit order signal for the given dataframe\n        This method should not be overridden.\n        :param dataframe: DataFrame\n        :param metadata: Additional information dictionary, with details like the\n            currently traded pair\n        :return: DataFrame with exit column\n        \"\"\"\n        # Initialize column to work around Pandas bug #56503.\n        dataframe.loc[:, \"exit_tag\"] = \"\"\n        logger.debug(f\"Populating exit signals for pair {metadata.get('pair')}.\")\n        df = self.populate_exit_trend(dataframe, metadata)\n        if \"exit_long\" not in df.columns:\n            df = df.rename({\"sell\": \"exit_long\"}, axis=\"columns\")\n        return df\n\n    def ft_plot_annotations(self, pair: str, dataframe: DataFrame) -> list[AnnotationType]:\n        \"\"\"\n        Internal wrapper around plot_dataframe\n        \"\"\"\n        if len(dataframe) > 0:\n            annotations = strategy_safe_wrapper(self.plot_annotations)(\n                pair=pair,\n                dataframe=dataframe,\n                start_date=dataframe.iloc[0][\"date\"].to_pydatetime(),\n                end_date=dataframe.iloc[-1][\"date\"].to_pydatetime(),\n            )\n\n            from freqtrade.ft_types.plot_annotation_type import AnnotationTypeTA\n\n            annotations_new: list[AnnotationType] = []\n            for annotation in annotations:\n                if isinstance(annotation, dict):\n                    # Convert to AnnotationType\n                    try:\n                        AnnotationTypeTA.validate_python(annotation)\n                        annotations_new.append(annotation)\n                    except ValidationError as e:\n                        logger.error(f\"Invalid annotation data: {annotation}. Error: {e}\")\n                else:\n                    # Already an AnnotationType\n                    annotations_new.append(annotation)\n\n            return annotations_new\n        return []\n"
        },
        {
          "path": "freqtrade/resolvers/strategy_resolver.py",
          "url": "https://github.com/freqtrade/freqtrade/blob/develop/freqtrade/resolvers/strategy_resolver.py",
          "lines": "1-327",
          "code": "# pragma pylint: disable=attribute-defined-outside-init\n\n\"\"\"\nThis module load custom strategies\n\"\"\"\n\nimport logging\nimport tempfile\nfrom base64 import urlsafe_b64decode\nfrom inspect import getfullargspec\nfrom os import walk\nfrom pathlib import Path\nfrom typing import Any\n\nfrom freqtrade.configuration.config_validation import validate_migrated_strategy_settings\nfrom freqtrade.constants import REQUIRED_ORDERTIF, REQUIRED_ORDERTYPES, USERPATH_STRATEGIES, Config\nfrom freqtrade.enums import TradingMode\nfrom freqtrade.exceptions import OperationalException\nfrom freqtrade.resolvers.iresolver import IResolver\nfrom freqtrade.strategy.interface import IStrategy\n\n\nlogger = logging.getLogger(__name__)\n\n\nclass StrategyResolver(IResolver):\n    \"\"\"\n    This class contains the logic to load custom strategy class\n    \"\"\"\n\n    object_type = IStrategy\n    object_type_str = \"Strategy\"\n    user_subdir = USERPATH_STRATEGIES\n    initial_search_path = None\n    extra_path = \"strategy_path\"\n\n    @staticmethod\n    def load_strategy(config: Config | None = None) -> IStrategy:\n        \"\"\"\n        Load the custom class from config parameter\n        :param config: configuration dictionary or None\n        \"\"\"\n        config = config or {}\n\n        if not config.get(\"strategy\"):\n            raise OperationalException(\n                \"No strategy set. Please use `--strategy` to specify the strategy class to use.\"\n            )\n\n        strategy_name = config[\"strategy\"]\n        strategy: IStrategy = StrategyResolver._load_strategy(\n            strategy_name, config=config, extra_dir=config.get(\"strategy_path\")\n        )\n        strategy.ft_load_params_from_file()\n        # Set attributes\n        # Check if we need to override configuration\n        # (Attribute name, default, subkey)\n        attributes = [\n            (\"minimal_roi\", {\"0\": 10.0}),\n            (\"timeframe\", None),\n            (\"stoploss\", None),\n            (\"trailing_stop\", None),\n            (\"trailing_stop_positive\", None),\n            (\"trailing_stop_positive_offset\", 0.0),\n            (\"trailing_only_offset_is_reached\", None),\n            (\"use_custom_stoploss\", None),\n            (\"process_only_new_candles\", None),\n            (\"order_types\", None),\n            (\"order_time_in_force\", None),\n            (\"stake_currency\", None),\n            (\"stake_amount\", None),\n            (\"startup_candle_count\", None),\n            (\"unfilledtimeout\", None),\n            (\"use_exit_signal\", True),\n            (\"exit_profit_only\", False),\n            (\"ignore_roi_if_entry_signal\", False),\n            (\"exit_profit_offset\", 0.0),\n            (\"disable_dataframe_checks\", False),\n            (\"ignore_buying_expired_candle_after\", 0),\n            (\"position_adjustment_enable\", False),\n            (\"max_entry_position_adjustment\", -1),\n            (\"max_open_trades\", float(\"inf\")),\n        ]\n        for attribute, default in attributes:\n            StrategyResolver._override_attribute_helper(strategy, config, attribute, default)\n\n        # Loop this list again to have output combined\n        for attribute, _ in attributes:\n            if attribute in config:\n                logger.info(f\"Strategy using {attribute}: {config[attribute]}\")\n\n        StrategyResolver._normalize_attributes(strategy)\n\n        StrategyResolver._strategy_sanity_validations(strategy)\n        return strategy\n\n    @staticmethod\n    def _override_attribute_helper(strategy, config: Config, attribute: str, default: Any):\n        \"\"\"\n        Override attributes in the strategy.\n        Prevalence:\n        - Configuration\n        - Strategy\n        - default (if not None)\n        \"\"\"\n        if attribute in config and not isinstance(\n            getattr(type(strategy), attribute, None), property\n        ):\n            # Ensure Properties are not overwritten\n            setattr(strategy, attribute, config[attribute])\n            logger.info(\n                f\"Override strategy '{attribute}' with value from the configuration: \"\n                f\"{config[attribute]}.\",\n            )\n        elif hasattr(strategy, attribute):\n            val = getattr(strategy, attribute)\n            # None's cannot exist in the config, so do not copy them\n            if val is not None:\n                # max_open_trades set to -1 in the strategy will be copied as infinity in the config\n                if attribute == \"max_open_trades\" and val == -1:\n                    config[attribute] = float(\"inf\")\n                else:\n                    config[attribute] = val\n        # Explicitly check for None here as other \"falsy\" values are possible\n        elif default is not None:\n            setattr(strategy, attribute, default)\n            config[attribute] = default\n\n    @staticmethod\n    def _normalize_attributes(strategy: IStrategy) -> IStrategy:\n        \"\"\"\n        Normalize attributes to have the correct type.\n        \"\"\"\n        # Sort and apply type conversions\n        if hasattr(strategy, \"minimal_roi\"):\n            strategy.minimal_roi = dict(\n                sorted(\n                    {int(key): value for (key, value) in strategy.minimal_roi.items()}.items(),\n                    key=lambda t: t[0],\n                )\n            )\n        if hasattr(strategy, \"stoploss\"):\n            strategy.stoploss = float(strategy.stoploss)\n        if hasattr(strategy, \"max_open_trades\") and strategy.max_open_trades < 0:\n            strategy.max_open_trades = float(\"inf\")\n        return strategy\n\n    @staticmethod\n    def _strategy_sanity_validations(strategy: IStrategy):\n        # Ensure necessary migrations are performed first.\n        validate_migrated_strategy_settings(strategy.config)\n\n        if not strategy.order_types or not all(\n            k in strategy.order_types for k in REQUIRED_ORDERTYPES\n        ):\n            raise ImportError(\n                f\"Impossible to load Strategy '{strategy.__class__.__name__}'. \"\n                f\"Order-types mapping is incomplete.\"\n            )\n        if not all(k in strategy.order_time_in_force for k in REQUIRED_ORDERTIF):\n            raise ImportError(\n                f\"Impossible to load Strategy '{strategy.__class__.__name__}'. \"\n                f\"Order-time-in-force mapping is incomplete.\"\n            )\n        trading_mode = strategy.config.get(\"trading_mode\", TradingMode.SPOT)\n\n        if strategy.can_short and trading_mode == TradingMode.SPOT:\n            raise ImportError(\n                \"Short strategies cannot run in spot markets. Please make sure that this \"\n                \"is the correct strategy and that your trading mode configuration is correct. \"\n                \"You can run this strategy in spot markets by setting `can_short=False`\"\n                \" in your strategy. Please note that short signals will be ignored in that case.\"\n            )\n\n    @staticmethod\n    def validate_strategy(strategy: IStrategy) -> IStrategy:\n        if strategy.config.get(\"trading_mode\", TradingMode.SPOT) != TradingMode.SPOT:\n            # Require new method\n            warn_deprecated_setting(strategy, \"sell_profit_only\", \"exit_profit_only\", True)\n            warn_deprecated_setting(strategy, \"sell_profit_offset\", \"exit_profit_offset\", True)\n            warn_deprecated_setting(strategy, \"use_sell_signal\", \"use_exit_signal\", True)\n            warn_deprecated_setting(\n                strategy, \"ignore_roi_if_buy_signal\", \"ignore_roi_if_entry_signal\", True\n            )\n\n            if not check_override(strategy, IStrategy, \"populate_entry_trend\"):\n                raise OperationalException(\"`populate_entry_trend` must be implemented.\")\n            if not check_override(strategy, IStrategy, \"populate_exit_trend\"):\n                raise OperationalException(\"`populate_exit_trend` must be implemented.\")\n            if check_override(strategy, IStrategy, \"check_buy_timeout\"):\n                raise OperationalException(\n                    \"Please migrate your implementation \"\n                    \"of `check_buy_timeout` to `check_entry_timeout`.\"\n                )\n            if check_override(strategy, IStrategy, \"check_sell_timeout\"):\n                raise OperationalException(\n                    \"Please migrate your implementation \"\n                    \"of `check_sell_timeout` to `check_exit_timeout`.\"\n                )\n\n            if check_override(strategy, IStrategy, \"custom_sell\"):\n                raise OperationalException(\n                    \"Please migrate your implementation of `custom_sell` to `custom_exit`.\"\n                )\n\n        else:\n            # TODO: Implementing one of the following methods should show a deprecation warning\n            #  buy_trend and sell_trend, custom_sell\n            warn_deprecated_setting(strategy, \"sell_profit_only\", \"exit_profit_only\")\n            warn_deprecated_setting(strategy, \"sell_profit_offset\", \"exit_profit_offset\")\n            warn_deprecated_setting(strategy, \"use_sell_signal\", \"use_exit_signal\")\n            warn_deprecated_setting(\n                strategy, \"ignore_roi_if_buy_signal\", \"ignore_roi_if_entry_signal\"\n            )\n\n            if not check_override(strategy, IStrategy, \"populate_buy_trend\") and not check_override(\n                strategy, IStrategy, \"populate_entry_trend\"\n            ):\n                raise OperationalException(\n                    \"`populate_entry_trend` or `populate_buy_trend` must be implemented.\"\n                )\n            if not check_override(\n                strategy, IStrategy, \"populate_sell_trend\"\n            ) and not check_override(strategy, IStrategy, \"populate_exit_trend\"):\n                raise OperationalException(\n                    \"`populate_exit_trend` or `populate_sell_trend` must be implemented.\"\n                )\n\n            _populate_fun_len = len(getfullargspec(strategy.populate_indicators).args)\n            _buy_fun_len = len(getfullargspec(strategy.populate_buy_trend).args)\n            _sell_fun_len = len(getfullargspec(strategy.populate_sell_trend).args)\n            if any(x == 2 for x in [_populate_fun_len, _buy_fun_len, _sell_fun_len]):\n                raise OperationalException(\n                    \"Strategy Interface v1 is no longer supported. \"\n                    \"Please update your strategy to implement \"\n                    \"`populate_indicators`, `populate_entry_trend` and `populate_exit_trend` \"\n                    \"with the metadata argument. \"\n                )\n\n        has_after_fill = \"after_fill\" in getfullargspec(\n            strategy.custom_stoploss\n        ).args and check_override(strategy, IStrategy, \"custom_stoploss\")\n        if has_after_fill:\n            strategy._ft_stop_uses_after_fill = True\n\n        if check_override(strategy, IStrategy, \"adjust_order_price\") and (\n            check_override(strategy, IStrategy, \"adjust_entry_price\")\n            or check_override(strategy, IStrategy, \"adjust_exit_price\")\n        ):\n            raise OperationalException(\n                \"If you implement `adjust_order_price`, `adjust_entry_price` and \"\n                \"`adjust_exit_price` will not be used. Please pick one approach for your strategy.\"\n            )\n        return strategy\n\n    @staticmethod\n    def _load_strategy(\n        strategy_name: str, config: Config, extra_dir: str | None = None\n    ) -> IStrategy:\n        \"\"\"\n        Search and loads the specified strategy.\n        :param strategy_name: name of the module to import\n        :param config: configuration for the strategy\n        :param extra_dir: additional directory to search for the given strategy\n        :return: Strategy instance or None\n        \"\"\"\n        if config.get(\"recursive_strategy_search\", False):\n            extra_dirs: list[str] = [\n                path[0] for path in walk(f\"{config['user_data_dir']}/{USERPATH_STRATEGIES}\")\n            ]  # sub-directories\n        else:\n            extra_dirs = []\n\n        if extra_dir:\n            extra_dirs.append(extra_dir)\n\n        abs_paths = StrategyResolver.build_search_paths(\n            config, user_subdir=USERPATH_STRATEGIES, extra_dirs=extra_dirs\n        )\n\n        if \":\" in strategy_name:\n            logger.info(\"loading base64 encoded strategy\")\n            strat = strategy_name.split(\":\")\n\n            if len(strat) == 2:\n                temp = Path(tempfile.mkdtemp(\"freq\", \"strategy\"))\n                name = strat[0] + \".py\"\n\n                temp.joinpath(name).write_text(urlsafe_b64decode(strat[1]).decode(\"utf-8\"))\n                temp.joinpath(\"__init__.py\").touch()\n\n                strategy_name = strat[0]\n\n                # register temp path with the bot\n                abs_paths.insert(0, temp.resolve())\n\n        strategy = StrategyResolver._load_object(\n            paths=abs_paths,\n            object_name=strategy_name,\n            add_source=True,\n            kwargs={\"config\": config},\n        )\n\n        if strategy:\n            return StrategyResolver.validate_strategy(strategy)\n\n        raise OperationalException(\n            f\"Impossible to load Strategy '{strategy_name}'. This class does not exist \"\n            \"or contains Python code errors.\"\n        )\n\n\ndef warn_deprecated_setting(strategy: IStrategy, old: str, new: str, error=False):\n    if hasattr(strategy, old):\n        errormsg = f\"DEPRECATED: Using '{old}' moved to '{new}'.\"\n        if error:\n            raise OperationalException(errormsg)\n        logger.warning(errormsg)\n        setattr(strategy, new, getattr(strategy, f\"{old}\"))\n\n\ndef check_override(obj, parentclass, attribute: str):\n    \"\"\"\n    Checks if a object overrides the parent class attribute.\n    :returns: True if the object is overridden.\n    \"\"\"\n    return getattr(type(obj), attribute) != getattr(parentclass, attribute)\n"
        }
      ]
    },
    {
      "id": 7,
      "name": "hyperparameter_optimization",
      "source_repo": "freqtrade/freqtrade",
      "files": [
        {
          "path": "freqtrade/optimize/hyperopt.py",
          "url": "https://github.com/freqtrade/freqtrade/blob/develop/freqtrade/optimize/hyperopt.py",
          "lines": "1-1",
          "code": "[FILE_NOT_FOUND_IN_LOCAL_REPO]"
        }
      ]
    }
  ],
  "metadata": {
    "total_files_extracted": 19,
    "total_lines_of_code": 12037,
    "extraction_method": "github_api",
    "verification_status": "complete"
  }
}